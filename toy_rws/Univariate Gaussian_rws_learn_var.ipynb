{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import logsumexp\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20000\n",
    "p_mu = 0.0\n",
    "# q_sigma = torch.tensor([1.0])\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "log_Z = np.log(np.sqrt((2*np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_samples, q_mu, q_sigma, lr):\n",
    "    EUBOs = []\n",
    "    ELBOs = []\n",
    "    Mus = []\n",
    "    Sigmas = []\n",
    "    for i in range(iterations):\n",
    "        proposal = Normal(q_mu, q_sigma)\n",
    "        xs = proposal.sample((num_samples,))\n",
    "        log_gammas = (-1.0 / 2.0) * ((xs - p_mu) ** 2)\n",
    "        log_q = proposal.log_prob(xs)\n",
    "\n",
    "        log_weights = log_gammas - log_q\n",
    "        weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "        eubo = torch.mul(weights, log_weights).sum()\n",
    "        elbo = log_weights.mean()\n",
    "        grads = torch.autograd.grad(eubo, [q_mu, q_sigma])\n",
    "        q_mu = q_mu - lr * grads[0]\n",
    "        q_sigma =  q_sigma - lr * grads[1]\n",
    "        EUBOs.append(eubo.item())\n",
    "        ELBOs.append(elbo.item())\n",
    "        Mus.append(q_mu.item())\n",
    "        Sigmas.append(q_sigma.item())\n",
    "    return EUBOs, ELBOs, Mus, Sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mu = np.array([6, 8, 10])\n",
    "init_sigma = np.array([1.0, 2.0, 4.0, 6.0])\n",
    "NUM_SAMPLES = np.array([100, 1000])\n",
    "\n",
    "for i in range(init_mu.shape[0]):\n",
    "    fig = plt.figure(figsize=(30, 40))\n",
    "    for j in range(init_sigma.shape[0]):\n",
    "        for k in range(NUM_SAMPLES.shape[0]):\n",
    "            time_start = time.time()\n",
    "            q_mu = torch.tensor([1.0], requires_grad=True) * init_mu[i]\n",
    "            q_sigma = torch.tensor([1.0], requires_grad=True) * init_sigma[j]\n",
    "            EUBOs, ELBOs, Mus, Sigmas = train(NUM_SAMPLES[k], q_mu, q_sigma, lr)\n",
    "            time_end = time.time()\n",
    "            print('init_mu=%.1f, init_sigma : %.1f, samples : %d (%ds)' % (init_mu[i], init_sigma[j], NUM_SAMPLES[k], time_end - time_start))\n",
    "            ax = fig.add_subplot(init_sigma.shape[0] * 2, NUM_SAMPLES.shape[0], (2*j) * NUM_SAMPLES.shape[0]+ k + 1)\n",
    "            ax.plot(EUBOs, 'r', label='EUBOs')\n",
    "            ax.plot(ELBOs, 'b', label='ELBOs')\n",
    "\n",
    "            ax.plot(np.ones(iterations) * log_Z, 'k', label='log_Z')\n",
    "            ax.tick_params(labelsize=18)\n",
    "            ax.set_ylim([-50, 20])\n",
    "            \n",
    "            ax2 = fig.add_subplot(init_sigma.shape[0] * 2, NUM_SAMPLES.shape[0], (2*j+1) * NUM_SAMPLES.shape[0]+ k + 1)\n",
    "#             ax2.plot(Mus, 'r', label='Mus')\n",
    "            ax2.plot(Sigmas, 'b', label='Sigmas')\n",
    "            ax2.tick_params(labelsize=18)\n",
    "            ax2.set_ylim([0, 6.5])\n",
    "            \n",
    "            if j == 0 and k == 0:\n",
    "                ax.legend()\n",
    "                ax2.legend()\n",
    "            ax.set_title('mu=%d, sigma=%d, samples=%d' % (init_mu[i], init_sigma[j], NUM_SAMPLES[k]), fontsize=18)\n",
    "    plt.savefig('univariate_gaussian_rws_mu=%d.svg' % (q_mu.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "# plt.plot(ELBOs)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(EUBOs, 'r', label='EUBOs')\n",
    "ax.plot(ELBOs, 'b', label='ELBOs')\n",
    "ax.plot(np.ones(iterations) * log_Z, 'k', label='log_Z')\n",
    "ax.legend()\n",
    "plt.savefig('rws-univariate-samples=%d-prior=2.png' % num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
