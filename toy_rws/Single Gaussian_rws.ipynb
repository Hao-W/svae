{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import logsumexp\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "p_mu = 0.0\n",
    "q_sigma = torch.tensor([1.0])\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "log_Z = np.log(np.sqrt((2*np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_samples, q_mu, lr):\n",
    "    EUBOs = []\n",
    "    ELBOs = []\n",
    "    for i in range(iterations):\n",
    "        proposal = Normal(q_mu, q_sigma)\n",
    "        xs = proposal.sample((num_samples,))\n",
    "        log_gammas = (-1.0 / 2.0) * ((xs - p_mu) ** 2)\n",
    "        log_q = proposal.log_prob(xs)\n",
    "\n",
    "        log_weights = log_gammas - log_q\n",
    "        weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "        eubo = torch.mul(weights, log_weights).sum()\n",
    "        elbo = log_weights.mean()\n",
    "        gradient = torch.autograd.grad(eubo, q_mu)\n",
    "        q_mu = q_mu - lr * gradient[0]\n",
    "        EUBOs.append(eubo.item())\n",
    "        ELBOs.append(elbo.item())\n",
    "    return EUBOs, ELBOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_q = np.array([2, 4, 6, 8, 10])\n",
    "NUM_SAMPLES = np.array([100, 1000, 10000])\n",
    "# NUM_SAMPLES = np.array([10, 10, 10, 10, 10])\n",
    "fig = plt.figure(figsize=(40, 30))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        time_start = time.time()\n",
    "        q_mu = torch.tensor([1.0], requires_grad=True) * init_q[i]\n",
    "        EUBOs, ELBOs = train(NUM_SAMPLES[j], q_mu, lr)\n",
    "        time_end = time.time()\n",
    "        print('prior : %f, samples : %d (%ds)' % (init_q[i], NUM_SAMPLES[j], time_end - time_start))\n",
    "        ax = fig.add_subplot(5, 5, i*5 + j + 1)\n",
    "        ax.plot(EUBOs, 'r', label='EUBOs')\n",
    "        ax.plot(ELBOs, 'b', label='ELBOs')\n",
    "        ax.plot(np.ones(iterations) * log_Z, 'k', label='log_Z')\n",
    "        ax.set_ylim([-50, 50])\n",
    "        if i == 0 and j == 0:\n",
    "            ax.legend()\n",
    "        ax.set_title('a bit of time editing the draft before heading to clasprior=%d, samples=%d' % (init_q[i], NUM_SAMPLES[j]))\n",
    "plt.savefig('results_single gaussian_rws.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "# plt.plot(ELBOs)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(EUBOs, 'r', label='EUBOs')\n",
    "ax.plot(ELBOs, 'b', label='ELBOs')\n",
    "ax.plot(np.ones(iterations) * log_Z, 'k', label='log_Z')\n",
    "ax.legend()\n",
    "plt.savefig('rws-univariate-samples=%d-prior=2.png' % num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
