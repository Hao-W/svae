{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import logsumexp\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20000\n",
    "num_samples = 1000\n",
    "p_mu = 0.0\n",
    "# q_sigma = torch.tensor([1.0])\n",
    "\n",
    "lr = 5*1e-3\n",
    "\n",
    "log_Z = np.log(np.sqrt((2*np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rws(num_samples, q_mu, q_sigma, lr):\n",
    "    EUBO = []\n",
    "    ELBO = []\n",
    "    Mu = []\n",
    "    Sigma = []\n",
    "    Grad_mu = []\n",
    "    Grad_sigma = []\n",
    "    for i in range(iterations):\n",
    "        proposal = Normal(q_mu, q_sigma)\n",
    "        xs = proposal.sample((num_samples,))\n",
    "        log_gammas = (-1.0 / 2.0) * ((xs - p_mu) ** 2)\n",
    "        log_q = proposal.log_prob(xs)\n",
    "\n",
    "        log_weights = log_gammas - log_q\n",
    "        weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "        eubo = torch.mul(weights, log_weights).sum()\n",
    "        elbo = log_weights.mean()\n",
    "        grads = torch.autograd.grad(eubo, [q_mu, q_sigma])\n",
    "        q_mu = q_mu - lr * grads[0]\n",
    "        q_sigma =  q_sigma - lr * grads[1]\n",
    "        EUBO.append(eubo.item())\n",
    "        ELBO.append(elbo.item())\n",
    "        Mu.append(q_mu.item())\n",
    "        Sigma.append(q_sigma.item())\n",
    "        Grad_mu.append(grads[0].item())\n",
    "        Grad_sigma.append(grads[1].item())\n",
    "    return EUBO, ELBO, Mu, Sigma, Grad_mu, Grad_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mu, init_sigmas, num_samples, lr):\n",
    "    num_sigmas = init_sigmas.shape[0]\n",
    "    EUBOs = []\n",
    "    ELBOs = []\n",
    "    Grad_mus = []\n",
    "    Grad_sigmas = []\n",
    "    Mus = []\n",
    "    Sigmas = []\n",
    "    for j in range(num_sigmas):\n",
    "        time_start = time.time()\n",
    "        q_mu = torch.tensor([1.0], requires_grad=True) * mu\n",
    "        q_sigma = torch.tensor([1.0], requires_grad=True) * init_sigmas[j]\n",
    "        EUBO, ELBO, Mu, Sigma, Grad_mu, Grad_sigma = rws(num_samples, q_mu, q_sigma, lr)\n",
    "        EUBOs.append(EUBO)\n",
    "        ELBOs.append(ELBO)\n",
    "        Grad_mus.append(Grad_mu)\n",
    "        Grad_sigmas.append(Grad_sigma)\n",
    "        Mus.append(Mu)\n",
    "        Sigmas.append(Sigma)\n",
    "        time_end = time.time()\n",
    "        print('init_mu=%d, init_sigma=%d, samples : %d (%ds)' % (mu, init_sigmas[j], num_samples, time_end - time_start))    \n",
    "    return EUBOs, ELBOs, Mus, Sigmas, Grad_mus, Grad_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, Mus, Sigmas, Grad_mus, Grad_sigmas, mu, init_sigmas, num_samples):\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 40))\n",
    "    for j in range(num_sigmas):\n",
    "        fig.tight_layout()\n",
    "        ax1 = fig.add_subplot(num_sigmas, 3, j*3 + 1)\n",
    "        ax2 = fig.add_subplot(num_sigmas, 3, j*3 + 2)\n",
    "        ax3 = fig.add_subplot(num_sigmas, 3, j*3 + 3)\n",
    "        ax1.plot(EUBOs[j], 'r', label='EUBOs')\n",
    "        ax1.plot(ELBOs[j], 'b', label='ELBOs')\n",
    "        ax1.plot(np.ones(iterations) * log_Z, 'k', label='log_Z')\n",
    "        ax1.set_ylim([-50, 20])\n",
    "        ax1.tick_params(labelsize=14)\n",
    "        \n",
    "        ax2.plot(Mus[j], 'm', label='mu')\n",
    "        ax2.plot(Sigmas[j], 'gray', label='sigma')\n",
    "        ax2.tick_params(labelsize=14)\n",
    "        ax3.plot(Grad_mus[j], 'g', label='grad mu')\n",
    "        ax3.plot(Grad_sigmas[j], 'orange', label='grad sigma')\n",
    "        ax3.tick_params(labelsize=14)\n",
    "        ax3.set_ylim([-8, 3])\n",
    "\n",
    "        ax1.set_title('mu=%d, sigma=%d, samples=%d' % (mu, init_sigmas[j], num_samples), fontsize=14)\n",
    "        if j == 0:\n",
    "            ax1.legend()\n",
    "            ax2.legend()\n",
    "            ax3.legend()\n",
    "    plt.savefig('univariate_gaussian_rws_learn_both_mu=%d_samples=%d.svg' % (mu, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_mu=6, init_sigma=1, samples : 1000 (508s)\n",
      "init_mu=6, init_sigma=2, samples : 1000 (468s)\n",
      "init_mu=6, init_sigma=4, samples : 1000 (456s)\n"
     ]
    }
   ],
   "source": [
    "init_mus = np.array([6, 8, 10])\n",
    "init_sigmas = np.array([1.0, 2.0, 4.0, 6.0])\n",
    "num_mus = init_mus.shape[0]\n",
    "\n",
    "for i in range(num_mus):\n",
    "    EUBOs, ELBOs, Mus, Sigmas, Grad_mus, Grad_sigmas = train(init_mus[i], init_sigmas, num_samples, lr)\n",
    "    plot_results(EUBOs, ELBOs, Mus, Sigmas, Grad_mus, Grad_sigmas, init_mus[i], init_sigmas, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
