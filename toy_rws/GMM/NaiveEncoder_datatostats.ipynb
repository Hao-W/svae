{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 100\n",
    "NUM_HIDDEN = 128\n",
    "NUM_STATS = K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS = D + K\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-3\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset/sequences.npy')).float()\n",
    "Zs = torch.from_numpy(np.load('gmm_dataset/states.npy')).float()\n",
    "# mus_true = torch.from_numpy(np.load('gmm_dataset/means.npy')).float()\n",
    "covs = torch.from_numpy(np.load('gmm_dataset/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset/init.npy')).float()\n",
    "num_seqs = Zs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatsGMM(Xs, Zs, K, D):\n",
    "    \"\"\"\n",
    "    Xs is B * N * D\n",
    "    Zs is B * N * K\n",
    "    return B * (K+D*K)\n",
    "    \"\"\"\n",
    "    stat1 = Zs.sum(1)\n",
    "    stat2 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    return stat1, stat2, torch.cat((stat1, stat2.view(-1, D*K)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "        self.enc_hidden = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.ReLU())\n",
    "        self.mean = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.log_std = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        hidden = self.enc_hidden(stats)\n",
    "        mean = self.mean(hidden).view(-1, K, D)\n",
    "        std = torch.exp(self.log_std(hidden).view(-1, K, D))\n",
    "        mus = Normal(mean, std).sample((num_samples, )) ## S * B * K * D\n",
    "        return mean, std, mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters()),lr=LEARNING_RATE)    \n",
    "    return enc, optimizer\n",
    "enc, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_joints_gmm(Z, Pi, mus, covs, Xs, N, D, K, num_samples, batch_size):\n",
    "    log_probs = torch.zeros((num_samples, batch_size)).float()\n",
    "    ## S * B\n",
    "    log_probs = log_probs + Normal(torch.zeros((batch_size, K, D)), torch.ones((batch_size, K, D))).log_prob(mus).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "    log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    covs_expand = covs.unsqueeze(0).unsqueeze(0).repeat(num_samples, batch_size, 1, 1, 1)\n",
    "    log_probs = log_probs + mvn(mus[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D), covs_expand[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D, D)).log_prob(Xs).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "def conjugate_posterior(stat1, stat2, covs, K, D, batch_size):\n",
    "    prior_covs_inv = torch.ones(K, D)\n",
    "    covs_flat = torch.diagonal(covs, 0, -2, -1).unsqueeze(0).repeat(BATCH_SIZE, 1, 1) #B * K * D\n",
    "    posterior_covs = 1. / (prior_covs_inv + torch.mul(stat1.unsqueeze(-1).repeat(1, 1, D), 1. / covs_flat))\n",
    "    posterior_mean = torch.mul(posterior_covs, torch.mul(stat2, 1. / covs_flat))\n",
    "    return posterior_mean, posterior_covs\n",
    "\n",
    "def kl_normal_normal(p_mean, p_std, q_mean, q_std):\n",
    "    var_ratio = (p_std / q_std).pow(2)\n",
    "    t1 = ((p_mean - q_mean) / q_std).pow(2)\n",
    "    return 0.5 * (var_ratio + t1 - 1 - var_ratio.log())\n",
    "\n",
    "def kls_gaussians(mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D):\n",
    "    log_q = Normal(mus_mean, mus_std).log_prob(mus).sum(-1).sum(-1)\n",
    "    log_p = Normal(posterior_mean, torch.sqrt(posterior_covs)).log_prob(mus).sum(-1).sum(-1)\n",
    "    MCKl = (log_q - log_p).mean(0).mean()\n",
    "    TrueKl = kl_normal_normal(mus_mean, mus_std, posterior_mean, torch.sqrt(posterior_covs)).mean()\n",
    "    return MCKl, TrueKl\n",
    "    \n",
    "def rws(Xs, Zs, Pi, covs, N, K, D, num_samples, batch_size):\n",
    "    stat1, stat2, stats = StatsGMM(Xs, Zs, K, D)\n",
    "    data = torch.cat((Xs, Zs), dim=-1).view(batch_size*N, -1)\n",
    "    mus_mean, mus_std, mus = enc(data, K, D, num_samples, batch_size)\n",
    "    log_q = Normal(mus_mean, mus_std).log_prob(mus).sum(-1).sum(-1) ## S * B\n",
    "    log_p = log_joints_gmm(Zs, Pi, mus, covs, Xs, N, D, K, num_samples, batch_size)\n",
    "    log_weights = log_p - log_q\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "    eubo = torch.mul(weights, log_weights).sum(0).mean()\n",
    "    elbo = log_weights.mean(0).mean()\n",
    "    ess = (1. / (weights ** 2).sum(0)).mean()\n",
    "    posterior_mean, posterior_covs = conjugate_posterior(stat1, stat2, covs, K, D, batch_size)\n",
    "    MCKl, TrueKl = kls_gaussians(mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D)\n",
    "    return eubo, elbo, ess, MCKl, TrueKl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-177.403854, ELBO=-370.303625, ESS=1.123, MCKL=256.114752, TKL=42.486810 (10s)\n",
      "epoch=1, EUBO=-133.156198, ELBO=-442.028790, ESS=1.195, MCKL=327.839951, TKL=54.432954 (10s)\n",
      "epoch=2, EUBO=-114.576050, ELBO=-184.284698, ESS=1.924, MCKL=70.095840, TKL=11.679213 (10s)\n",
      "epoch=3, EUBO=-113.238106, ELBO=-129.235562, ESS=4.444, MCKL=15.046702, TKL=2.509401 (10s)\n",
      "epoch=4, EUBO=-112.438470, ELBO=-123.694724, ESS=6.407, MCKL=9.505855, TKL=1.586047 (10s)\n",
      "epoch=5, EUBO=-112.259877, ELBO=-120.612958, ESS=8.662, MCKL=6.424096, TKL=1.071118 (10s)\n",
      "epoch=6, EUBO=-112.295560, ELBO=-119.722981, ESS=9.128, MCKL=5.534119, TKL=0.922273 (10s)\n",
      "epoch=7, EUBO=-112.580875, ELBO=-118.039452, ESS=12.821, MCKL=3.850584, TKL=0.635341 (10s)\n",
      "epoch=8, EUBO=-112.666298, ELBO=-117.658817, ESS=14.093, MCKL=3.469942, TKL=0.578683 (10s)\n",
      "epoch=9, EUBO=-112.715749, ELBO=-117.200119, ESS=15.416, MCKL=3.011256, TKL=0.503529 (10s)\n",
      "epoch=10, EUBO=-112.727887, ELBO=-117.118146, ESS=15.543, MCKL=2.929283, TKL=0.489533 (10s)\n",
      "epoch=11, EUBO=-112.770551, ELBO=-116.878059, ESS=17.275, MCKL=2.689193, TKL=0.447954 (10s)\n",
      "epoch=12, EUBO=-112.890938, ELBO=-116.657086, ESS=18.788, MCKL=2.468230, TKL=0.412586 (10s)\n",
      "epoch=13, EUBO=-112.971376, ELBO=-116.402591, ESS=20.598, MCKL=2.213733, TKL=0.372607 (10s)\n",
      "epoch=14, EUBO=-113.014661, ELBO=-116.361176, ESS=21.343, MCKL=2.172311, TKL=0.359526 (10s)\n",
      "epoch=15, EUBO=-112.972112, ELBO=-116.270398, ESS=21.650, MCKL=2.081528, TKL=0.348249 (10s)\n",
      "epoch=16, EUBO=-113.062241, ELBO=-116.202921, ESS=22.301, MCKL=2.014059, TKL=0.335848 (10s)\n",
      "epoch=17, EUBO=-113.039018, ELBO=-116.129445, ESS=22.737, MCKL=1.940581, TKL=0.322504 (10s)\n",
      "epoch=18, EUBO=-113.063408, ELBO=-116.095499, ESS=23.679, MCKL=1.906636, TKL=0.317428 (10s)\n",
      "epoch=19, EUBO=-113.153685, ELBO=-115.997935, ESS=25.251, MCKL=1.809075, TKL=0.300781 (10s)\n",
      "epoch=20, EUBO=-113.138683, ELBO=-115.917868, ESS=25.149, MCKL=1.729006, TKL=0.288750 (10s)\n",
      "epoch=21, EUBO=-113.107614, ELBO=-115.937688, ESS=25.181, MCKL=1.748827, TKL=0.294446 (10s)\n",
      "epoch=22, EUBO=-113.116846, ELBO=-115.856857, ESS=25.872, MCKL=1.667992, TKL=0.281564 (10s)\n",
      "epoch=23, EUBO=-113.179723, ELBO=-115.831374, ESS=26.370, MCKL=1.642509, TKL=0.274254 (10s)\n",
      "epoch=24, EUBO=-113.233987, ELBO=-115.800049, ESS=27.801, MCKL=1.611184, TKL=0.268806 (10s)\n",
      "epoch=25, EUBO=-113.235733, ELBO=-115.697417, ESS=28.337, MCKL=1.508544, TKL=0.254136 (10s)\n",
      "epoch=26, EUBO=-113.240590, ELBO=-115.681560, ESS=28.410, MCKL=1.492694, TKL=0.250470 (10s)\n",
      "epoch=27, EUBO=-113.243356, ELBO=-115.723021, ESS=28.607, MCKL=1.534156, TKL=0.255769 (10s)\n",
      "epoch=28, EUBO=-113.278534, ELBO=-115.643469, ESS=29.572, MCKL=1.454601, TKL=0.243314 (10s)\n",
      "epoch=29, EUBO=-113.237477, ELBO=-115.652988, ESS=29.074, MCKL=1.464128, TKL=0.244209 (10s)\n",
      "epoch=30, EUBO=-113.256786, ELBO=-115.666240, ESS=29.683, MCKL=1.477380, TKL=0.247079 (10s)\n",
      "epoch=31, EUBO=-113.277579, ELBO=-115.575887, ESS=30.280, MCKL=1.387031, TKL=0.231531 (10s)\n",
      "epoch=32, EUBO=-113.275327, ELBO=-115.573680, ESS=31.217, MCKL=1.384812, TKL=0.229921 (10s)\n",
      "epoch=33, EUBO=-113.283655, ELBO=-115.534790, ESS=31.573, MCKL=1.345929, TKL=0.226376 (10s)\n",
      "epoch=34, EUBO=-113.349744, ELBO=-115.491806, ESS=32.314, MCKL=1.302943, TKL=0.217004 (10s)\n",
      "epoch=35, EUBO=-113.326346, ELBO=-115.543788, ESS=31.824, MCKL=1.354920, TKL=0.223884 (10s)\n",
      "epoch=36, EUBO=-113.325563, ELBO=-115.488280, ESS=32.105, MCKL=1.299414, TKL=0.216718 (11s)\n",
      "epoch=37, EUBO=-113.359378, ELBO=-115.484663, ESS=32.534, MCKL=1.295800, TKL=0.218114 (10s)\n",
      "epoch=38, EUBO=-113.357932, ELBO=-115.451144, ESS=33.368, MCKL=1.262277, TKL=0.210902 (10s)\n",
      "epoch=39, EUBO=-113.394106, ELBO=-115.435782, ESS=34.493, MCKL=1.246910, TKL=0.206312 (10s)\n",
      "epoch=40, EUBO=-113.370689, ELBO=-115.404106, ESS=33.353, MCKL=1.215237, TKL=0.201957 (10s)\n"
     ]
    }
   ],
   "source": [
    "EUBOs = []\n",
    "ELBOs = []\n",
    "ESSs = []\n",
    "MCKls = []\n",
    "TrueKls = []\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    time_start = time.time()\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    ESS = 0.0\n",
    "    MCKl = 0.0\n",
    "    TrueKl = 0.0\n",
    "    for step in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "        batch_Zs = Zs[batch_indices]\n",
    "        eubo, elbo, ess, mckl, truekl = rws(batch_Xs, batch_Zs, Pi, covs, N, K, D, NUM_SAMPLES, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        ESS += ess.item()\n",
    "        MCKl += mckl.item()\n",
    "        TrueKl += truekl.item()\n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    ESS /= num_batches\n",
    "    MCKl /= num_batches\n",
    "    TrueKl /= num_batches\n",
    "    \n",
    "    EUBOs.append(EUBO)\n",
    "    ELBOs.append(ELBO)\n",
    "    ESSs.append(ESS)\n",
    "    MCKls.append(MCKl)\n",
    "    TrueKls.append(TrueKl)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print('epoch=%d, EUBO=%f, ELBO=%f, ESS=%.3f, MCKL=%f, TKL=%f (%ds)' % (epoch, EUBO, ELBO, ESS, MCKl, TrueKl, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESS, MCKls, TrueKls, num_samples, num_epochs, lr):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    fig.tight_layout()\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax1.plot(TrueKls, 'k', label='true KL')\n",
    "    ax1.plot(MCKls, 'orange', label='est KL')\n",
    "    ax1.tick_params(labelsize=14)\n",
    "    ax2.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax1.set_title('epoch=%d, lr=%d, samples=%d' % (num_epochs, lr, num_samples), fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.savefig('gmm_rws_stattodist_lr=%f_samples=%d.svg' % (lr, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
