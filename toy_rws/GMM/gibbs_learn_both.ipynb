{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 100\n",
    "NUM_HIDDEN = 64\n",
    "NUM_STATS = K+D*K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS = D + K\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset/sequences.npy')).float()\n",
    "Zs = torch.from_numpy(np.load('gmm_dataset/states.npy')).float()\n",
    "# mus_true = torch.from_numpy(np.load('gmm_dataset/means.npy')).float()\n",
    "# covs = torch.from_numpy(np.load('gmm_dataset2/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset/init.npy')).float()\n",
    "num_seqs = Zs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatsGMM(Xs, Zs, K, D):\n",
    "    \"\"\"\n",
    "    Xs is B * N * D\n",
    "    Zs is B * N * K\n",
    "    stat1 corresponds I[z_n=1], ..., I[z_n=K]\n",
    "    stat2 corresponds I[z_n=1]x_n, ..., I[z_n=K]x_n\n",
    "    stat3 corresponds I[z_n=1]x_n**2, ..., I[z_n=K]x_n**2\n",
    "    return B * (K+D*K+D*K)\n",
    "    \"\"\"\n",
    "    stat1 = Zs.sum(1)\n",
    "    stat2 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    stat3 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), torch.mul(Xs, Xs).unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    return stat1, stat2, stat3, torch.cat((stat1, stat2.view(-1, D*K), stat3.view(-1, D*K)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "        self.enc_hidden = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.ReLU())\n",
    "        self.sigmas_log_alpha = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.sigmas_log_beta = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "        self.enc_hidden2 = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.ReLU())\n",
    "        self.mus_mean = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.mus_log_std = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        hidden = self.enc_hidden(stats)\n",
    "        alpha = torch.exp(self.sigmas_log_alpha(hidden)).view(-1, K, D) ## B * K * D\n",
    "        beta = torch.exp(self.sigmas_log_beta(hidden)).view(-1, K, D) ## B * K * D\n",
    "        precisions = Gamma(alpha, beta).sample((num_samples,)) ## S * B * K * D\n",
    "        \n",
    "        hidden2 = self.enc_hidden2(stats)                 \n",
    "        mus_mean = self.mus_mean(hidden2).view(-1, K, D)\n",
    "        mus_sigma = torch.exp(self.mus_log_std(hidden2).view(-1, K, D))\n",
    "        mus = Normal(mus_mean, mus_sigma).sample((num_samples,))  \n",
    "        return alpha, beta, precisions, mus_mean, mus_sigma, mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))    \n",
    "    return enc, optimizer\n",
    "enc, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_joints_gmm(Z, Pi, mus, precisions, Xs, N, D, K, num_samples, batch_size):\n",
    "    log_probs = torch.zeros((num_samples, batch_size)).float()\n",
    "    ## priors on mus and sigmas, S * B\n",
    "    log_probs = log_probs + Normal(torch.zeros((batch_size, K, D)), torch.ones((batch_size, K, D))).log_prob(mus).sum(-1).sum(-1)\n",
    "    log_probs = log_probs + Gamma(torch.ones((batch_size, K, D)) * 2.0, torch.ones((batch_size, K, D)) * 2.0).log_prob(precisions).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "    log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    sigmas = 1. / torch.sqrt(precisions)\n",
    "    log_probs = log_probs + Normal(mus[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D), sigmas[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D)).log_prob(Xs).sum(-1).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "# def conjugate_posterior(stat1, stat2, stat3, mus, K, D, batch_size):\n",
    "#     stat1_expand = stat1.unsqueeze(-1).repeat(1, 1, D)\n",
    "#     posterior_alpha = torch.ones((batch_size, K, D)) * 2.0 + (stat1_expand / 2.)\n",
    "#     posterior_beta = torch.ones((batch_size, K, D)) * 2.0 + (stat3 + (stat1_expand * (mus ** 2)) - 2 * mus * stat2) / 2.\n",
    "#     return posterior_mean, posterior_nu, posterior_alpha, posterior_beta\n",
    "    \n",
    "# def kl_gamma_gamma(p_alpha, p_beta, q_alpha, q_beta):\n",
    "#     t1 = q_alpha * (p_beta / q_beta).log()\n",
    "#     t2 = torch.lgamma(q_alpha) - torch.lgamma(p_alpha)\n",
    "#     t3 = (p_alpha - q_alpha) * torch.digamma(p_alpha)\n",
    "#     t4 = (q_beta - p_beta) * (p_alpha / p_beta)\n",
    "#     return t1 + t2 + t3 + t4\n",
    "\n",
    "# def kls_gammas(weights, tau, q_alpha, q_beta, p_alpha, p_beta, K, D):\n",
    "#     log_q = Gamma(q_alpha, q_beta).log_prob(tau).sum(-1).sum(-1)\n",
    "#     log_p = Gamma(p_alpha, p_beta).log_prob(tau).sum(-1).sum(-1)\n",
    "#     MCKl_exclusive = (log_q - log_p).mean(0).mean()\n",
    "#     TrueKl_exclusive = kl_gamma_gamma(q_alpha, q_beta, p_alpha, p_beta).mean()\n",
    "    \n",
    "#     MCKl_inclusive = torch.mul(weights, log_p - log_q).sum(0).mean()\n",
    "#     TrueKl_inclusive = kl_gamma_gamma(p_alpha, p_beta, q_alpha, q_beta).mean()\n",
    "#     return MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive\n",
    "\n",
    "\n",
    "# def kl_normal_normal(p_mean, p_std, q_mean, q_std):\n",
    "#     var_ratio = (p_std / q_std).pow(2)\n",
    "#     t1 = ((p_mean - q_mean) / q_std).pow(2)\n",
    "#     return 0.5 * (var_ratio + t1 - 1 - var_ratio.log())\n",
    "\n",
    "# def kls_gaussians(weights, mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D):\n",
    "#     log_q = Normal(mus_mean, mus_std).log_prob(mus).sum(-1).sum(-1)\n",
    "#     log_p = Normal(posterior_mean, torch.sqrt(posterior_covs)).log_prob(mus).sum(-1).sum(-1)\n",
    "#     MCKl_exclusive = (log_q - log_p).mean(0).mean()\n",
    "#     TrueKl_exclusive = kl_normal_normal(mus_mean, mus_std, posterior_mean, torch.sqrt(posterior_covs)).mean()\n",
    "    \n",
    "#     MCKl_inclusive = torch.mul(weights, log_p - log_q).sum(0).mean()\n",
    "#     TrueKl_inclusive = kl_normal_normal(posterior_mean, torch.sqrt(posterior_covs), mus_mean, mus_std).mean()\n",
    "#     return MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive\n",
    "\n",
    "\n",
    "def rws(Xs, Zs, Pi, N, K, D, num_samples, batch_size):\n",
    "    stat1, stat2, stat3, stats = StatsGMM(Xs, Zs, K, D)\n",
    "    data = torch.cat((Xs, Zs), dim=-1).view(batch_size*N, -1)\n",
    "    alpha, beta, precisions, mus_mean, mus_sigma, mus = enc(data, K, D, num_samples, batch_size)\n",
    "    log_q =  Normal(mus_mean, mus_sigma).log_prob(mus).sum(-1).sum(-1) + Gamma(alpha, beta).log_prob(precisions).sum(-1).sum(-1)## S * B\n",
    "    log_p = log_joints_gmm(Zs, Pi, mus, precisions, Xs, N, D, K, num_samples, batch_size)\n",
    "    log_weights = log_p - log_q\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "    eubo = torch.mul(weights, log_weights).sum(0).mean()\n",
    "    elbo = log_weights.mean(0).mean()\n",
    "    ess = (1. / (weights ** 2).sum(0)).mean()\n",
    "#     posterior_mean, posterior_nu, posterior_alpha, posterior_beta = conjugate_posterior(stat1, stat2, stat3, K, D, batch_size)\n",
    "#     MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive = kls_gammas(weights, precisions, sigmas_alpha, sigmas_beta, posterior_alpha, posterior_beta, K, D)\n",
    "    return eubo, elbo, ess\n",
    "\n",
    "def shuffler(batch_Xs, batch_Zs, N, K, D, batch_size):\n",
    "    indices = torch.cat([torch.randperm(N).unsqueeze(0) for b in range(batch_size)])\n",
    "    indices_Xs = indices.unsqueeze(-1).repeat(1, 1, D)\n",
    "    indices_Zs = indices.unsqueeze(-1).repeat(1, 1, K)\n",
    "    return torch.gather(batch_Xs, 1, indices_Xs), torch.gather(batch_Zs, 1, indices_Zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-17913413602.550278, ELBO=-4302793955446.919434, ESS=1.002 (1s)\n",
      "epoch=10, EUBO=-220.987289, ELBO=-437.789664, ESS=1.255 (13s)\n",
      "epoch=20, EUBO=-194.855402, ELBO=-309.875995, ESS=1.301 (13s)\n",
      "epoch=30, EUBO=-189.306550, ELBO=-273.828865, ESS=1.317 (14s)\n",
      "epoch=40, EUBO=-187.220377, ELBO=-263.323942, ESS=1.378 (13s)\n",
      "epoch=50, EUBO=-184.784094, ELBO=-256.797493, ESS=1.383 (13s)\n",
      "epoch=60, EUBO=-180.940195, ELBO=-248.840160, ESS=1.369 (13s)\n",
      "epoch=70, EUBO=-177.938956, ELBO=-235.133881, ESS=1.443 (16s)\n",
      "epoch=80, EUBO=-174.345942, ELBO=-226.604700, ESS=1.571 (14s)\n",
      "epoch=90, EUBO=-171.835007, ELBO=-215.223885, ESS=1.649 (12s)\n",
      "epoch=100, EUBO=-170.547303, ELBO=-209.745873, ESS=1.763 (12s)\n",
      "epoch=110, EUBO=-169.469238, ELBO=-206.813028, ESS=1.739 (14s)\n",
      "epoch=120, EUBO=-169.090854, ELBO=-205.450643, ESS=1.766 (14s)\n",
      "epoch=130, EUBO=-168.884452, ELBO=-204.599857, ESS=1.778 (13s)\n",
      "epoch=140, EUBO=-168.678850, ELBO=-203.439344, ESS=1.829 (13s)\n",
      "epoch=150, EUBO=-168.154459, ELBO=-203.572115, ESS=1.773 (14s)\n",
      "epoch=160, EUBO=-168.286585, ELBO=-201.766453, ESS=1.866 (13s)\n",
      "epoch=170, EUBO=-167.826550, ELBO=-201.082691, ESS=1.854 (14s)\n",
      "epoch=180, EUBO=-167.507204, ELBO=-199.583890, ESS=1.825 (14s)\n",
      "epoch=190, EUBO=-167.545020, ELBO=-198.422139, ESS=1.941 (14s)\n",
      "epoch=200, EUBO=-167.434295, ELBO=-198.733634, ESS=1.897 (12s)\n",
      "epoch=210, EUBO=-167.199679, ELBO=-199.181764, ESS=1.873 (12s)\n",
      "epoch=220, EUBO=-167.120422, ELBO=-197.299734, ESS=1.947 (13s)\n",
      "epoch=230, EUBO=-167.046670, ELBO=-197.307976, ESS=1.917 (14s)\n",
      "epoch=240, EUBO=-167.028370, ELBO=-197.216533, ESS=1.976 (13s)\n",
      "epoch=250, EUBO=-166.813970, ELBO=-195.181240, ESS=2.021 (13s)\n",
      "epoch=260, EUBO=-166.717791, ELBO=-195.752774, ESS=2.011 (13s)\n",
      "epoch=270, EUBO=-166.831628, ELBO=-195.183072, ESS=2.075 (15s)\n",
      "epoch=280, EUBO=-166.535221, ELBO=-194.201467, ESS=2.052 (13s)\n",
      "epoch=290, EUBO=-166.524104, ELBO=-194.601982, ESS=2.019 (13s)\n",
      "epoch=300, EUBO=-166.561070, ELBO=-193.415925, ESS=2.158 (14s)\n",
      "epoch=310, EUBO=-166.446622, ELBO=-193.330453, ESS=2.127 (15s)\n",
      "epoch=320, EUBO=-166.260046, ELBO=-192.504407, ESS=2.185 (14s)\n",
      "epoch=330, EUBO=-166.299529, ELBO=-192.468780, ESS=2.188 (13s)\n",
      "epoch=340, EUBO=-166.087145, ELBO=-192.870835, ESS=2.145 (14s)\n",
      "epoch=350, EUBO=-166.075532, ELBO=-192.388954, ESS=2.136 (14s)\n",
      "epoch=360, EUBO=-165.809230, ELBO=-191.872733, ESS=2.164 (14s)\n",
      "epoch=370, EUBO=-166.061362, ELBO=-191.137394, ESS=2.192 (14s)\n",
      "epoch=380, EUBO=-165.845971, ELBO=-191.127872, ESS=2.300 (13s)\n",
      "epoch=390, EUBO=-165.679629, ELBO=-191.218876, ESS=2.175 (15s)\n",
      "epoch=400, EUBO=-165.558569, ELBO=-190.471999, ESS=2.249 (14s)\n",
      "epoch=410, EUBO=-165.603809, ELBO=-189.914309, ESS=2.314 (13s)\n",
      "epoch=420, EUBO=-165.533715, ELBO=-190.184904, ESS=2.287 (13s)\n",
      "epoch=430, EUBO=-165.498761, ELBO=-189.079948, ESS=2.331 (14s)\n",
      "epoch=440, EUBO=-165.412440, ELBO=-189.164038, ESS=2.333 (12s)\n",
      "epoch=450, EUBO=-165.472237, ELBO=-188.914669, ESS=2.371 (13s)\n",
      "epoch=460, EUBO=-165.318502, ELBO=-188.915326, ESS=2.268 (12s)\n",
      "epoch=470, EUBO=-165.298072, ELBO=-188.244671, ESS=2.317 (14s)\n",
      "epoch=480, EUBO=-165.101897, ELBO=-188.264178, ESS=2.376 (12s)\n",
      "epoch=490, EUBO=-165.027329, ELBO=-188.165064, ESS=2.349 (12s)\n",
      "epoch=500, EUBO=-164.874820, ELBO=-187.967395, ESS=2.367 (13s)\n",
      "epoch=510, EUBO=-165.056714, ELBO=-187.231322, ESS=2.456 (14s)\n",
      "epoch=520, EUBO=-165.030224, ELBO=-186.582819, ESS=2.472 (14s)\n",
      "epoch=530, EUBO=-164.888356, ELBO=-187.033034, ESS=2.485 (13s)\n",
      "epoch=540, EUBO=-164.867623, ELBO=-187.162166, ESS=2.406 (13s)\n",
      "epoch=550, EUBO=-164.727648, ELBO=-186.350800, ESS=2.509 (15s)\n",
      "epoch=560, EUBO=-164.793191, ELBO=-186.255497, ESS=2.533 (13s)\n",
      "epoch=570, EUBO=-164.714142, ELBO=-185.787665, ESS=2.573 (14s)\n",
      "epoch=580, EUBO=-164.644291, ELBO=-185.800836, ESS=2.527 (13s)\n",
      "epoch=590, EUBO=-164.586540, ELBO=-185.314508, ESS=2.628 (14s)\n",
      "epoch=600, EUBO=-164.531104, ELBO=-185.267832, ESS=2.584 (13s)\n",
      "epoch=610, EUBO=-164.552844, ELBO=-184.990788, ESS=2.734 (14s)\n",
      "epoch=620, EUBO=-164.582823, ELBO=-184.598853, ESS=2.670 (14s)\n",
      "epoch=630, EUBO=-164.441571, ELBO=-184.383357, ESS=2.602 (14s)\n",
      "epoch=640, EUBO=-164.425516, ELBO=-183.974935, ESS=2.771 (13s)\n",
      "epoch=650, EUBO=-164.339059, ELBO=-183.487986, ESS=2.762 (13s)\n",
      "epoch=660, EUBO=-164.484249, ELBO=-183.426856, ESS=2.863 (13s)\n",
      "epoch=670, EUBO=-164.319162, ELBO=-183.357212, ESS=2.815 (15s)\n",
      "epoch=680, EUBO=-164.380692, ELBO=-183.417033, ESS=2.852 (13s)\n",
      "epoch=690, EUBO=-164.234389, ELBO=-183.199342, ESS=2.768 (13s)\n",
      "epoch=700, EUBO=-164.140096, ELBO=-183.177954, ESS=2.794 (13s)\n",
      "epoch=710, EUBO=-164.369500, ELBO=-182.593185, ESS=2.992 (13s)\n",
      "epoch=720, EUBO=-164.189156, ELBO=-182.926583, ESS=2.939 (12s)\n",
      "epoch=730, EUBO=-164.233234, ELBO=-182.630721, ESS=2.851 (15s)\n",
      "epoch=740, EUBO=-164.025750, ELBO=-182.331157, ESS=2.969 (12s)\n",
      "epoch=750, EUBO=-164.233654, ELBO=-181.974787, ESS=3.025 (14s)\n",
      "epoch=760, EUBO=-164.207369, ELBO=-182.051995, ESS=3.037 (12s)\n",
      "epoch=770, EUBO=-164.089339, ELBO=-182.036847, ESS=2.949 (12s)\n",
      "epoch=780, EUBO=-164.095081, ELBO=-181.884719, ESS=3.002 (12s)\n",
      "epoch=790, EUBO=-164.030408, ELBO=-181.667214, ESS=3.040 (14s)\n",
      "epoch=800, EUBO=-163.985048, ELBO=-181.547715, ESS=2.947 (13s)\n",
      "epoch=810, EUBO=-164.261006, ELBO=-181.104788, ESS=3.089 (13s)\n",
      "epoch=820, EUBO=-163.998868, ELBO=-181.722677, ESS=2.971 (13s)\n",
      "epoch=830, EUBO=-163.889783, ELBO=-181.525048, ESS=3.117 (13s)\n",
      "epoch=840, EUBO=-164.125779, ELBO=-181.144745, ESS=3.179 (12s)\n",
      "epoch=850, EUBO=-164.027905, ELBO=-180.747437, ESS=3.176 (13s)\n",
      "epoch=860, EUBO=-164.080984, ELBO=-180.782278, ESS=3.123 (13s)\n",
      "epoch=870, EUBO=-164.033065, ELBO=-180.578568, ESS=3.262 (13s)\n",
      "epoch=880, EUBO=-163.912237, ELBO=-180.873003, ESS=3.122 (13s)\n",
      "epoch=890, EUBO=-164.076648, ELBO=-180.343524, ESS=3.328 (13s)\n",
      "epoch=900, EUBO=-164.046716, ELBO=-180.381676, ESS=3.288 (13s)\n",
      "epoch=910, EUBO=-164.051717, ELBO=-180.430150, ESS=3.252 (14s)\n",
      "epoch=920, EUBO=-163.869787, ELBO=-180.391087, ESS=3.192 (14s)\n",
      "epoch=930, EUBO=-164.153870, ELBO=-179.970749, ESS=3.430 (13s)\n",
      "epoch=940, EUBO=-164.025810, ELBO=-180.398589, ESS=3.306 (13s)\n",
      "epoch=950, EUBO=-164.064819, ELBO=-180.194605, ESS=3.359 (13s)\n",
      "epoch=960, EUBO=-163.950561, ELBO=-180.214264, ESS=3.276 (14s)\n",
      "epoch=970, EUBO=-163.920980, ELBO=-180.292015, ESS=3.192 (13s)\n",
      "epoch=980, EUBO=-163.967142, ELBO=-180.082552, ESS=3.332 (12s)\n",
      "epoch=990, EUBO=-163.963297, ELBO=-179.910131, ESS=3.308 (12s)\n",
      "epoch=1000, EUBO=-163.915509, ELBO=-179.756580, ESS=3.281 (14s)\n",
      "epoch=1010, EUBO=-163.957120, ELBO=-180.039998, ESS=3.335 (13s)\n",
      "epoch=1020, EUBO=-163.940777, ELBO=-179.779833, ESS=3.427 (13s)\n",
      "epoch=1030, EUBO=-163.890694, ELBO=-179.813154, ESS=3.282 (13s)\n",
      "epoch=1040, EUBO=-163.904288, ELBO=-179.817531, ESS=3.409 (14s)\n",
      "epoch=1050, EUBO=-163.844167, ELBO=-179.796268, ESS=3.333 (12s)\n",
      "epoch=1060, EUBO=-163.821978, ELBO=-179.404647, ESS=3.339 (12s)\n",
      "epoch=1070, EUBO=-163.963926, ELBO=-179.645580, ESS=3.384 (13s)\n",
      "epoch=1080, EUBO=-163.992007, ELBO=-179.697800, ESS=3.368 (13s)\n",
      "epoch=1090, EUBO=-164.009534, ELBO=-179.769355, ESS=3.410 (12s)\n",
      "epoch=1100, EUBO=-164.060441, ELBO=-179.446714, ESS=3.504 (12s)\n",
      "epoch=1110, EUBO=-163.847295, ELBO=-179.464269, ESS=3.456 (12s)\n",
      "epoch=1120, EUBO=-163.872451, ELBO=-179.547822, ESS=3.425 (13s)\n",
      "epoch=1130, EUBO=-163.803072, ELBO=-179.480102, ESS=3.324 (12s)\n",
      "epoch=1140, EUBO=-163.829872, ELBO=-179.558985, ESS=3.369 (12s)\n",
      "epoch=1150, EUBO=-163.713803, ELBO=-179.575031, ESS=3.289 (12s)\n",
      "epoch=1160, EUBO=-163.834478, ELBO=-179.482712, ESS=3.322 (13s)\n",
      "epoch=1170, EUBO=-163.854682, ELBO=-179.541487, ESS=3.381 (13s)\n",
      "epoch=1180, EUBO=-163.840271, ELBO=-179.397843, ESS=3.455 (13s)\n",
      "epoch=1190, EUBO=-163.986894, ELBO=-179.153770, ESS=3.471 (12s)\n",
      "epoch=1200, EUBO=-163.926604, ELBO=-179.305367, ESS=3.419 (13s)\n",
      "epoch=1210, EUBO=-163.824130, ELBO=-179.370518, ESS=3.469 (12s)\n",
      "epoch=1220, EUBO=-163.719017, ELBO=-179.134772, ESS=3.449 (13s)\n",
      "epoch=1230, EUBO=-163.828157, ELBO=-179.289670, ESS=3.437 (12s)\n",
      "epoch=1240, EUBO=-163.845940, ELBO=-179.142645, ESS=3.491 (13s)\n",
      "epoch=1250, EUBO=-163.897791, ELBO=-179.306078, ESS=3.483 (12s)\n",
      "epoch=1260, EUBO=-163.840870, ELBO=-179.104555, ESS=3.583 (12s)\n",
      "epoch=1270, EUBO=-163.948588, ELBO=-178.851611, ESS=3.776 (12s)\n",
      "epoch=1280, EUBO=-163.794570, ELBO=-179.098922, ESS=3.564 (13s)\n",
      "epoch=1290, EUBO=-163.728817, ELBO=-179.044665, ESS=3.438 (13s)\n",
      "epoch=1300, EUBO=-163.678993, ELBO=-179.201646, ESS=3.338 (12s)\n",
      "epoch=1310, EUBO=-163.788663, ELBO=-179.129998, ESS=3.433 (12s)\n",
      "epoch=1320, EUBO=-163.803169, ELBO=-178.908310, ESS=3.473 (12s)\n",
      "epoch=1330, EUBO=-163.860491, ELBO=-178.756523, ESS=3.562 (14s)\n",
      "epoch=1340, EUBO=-163.942378, ELBO=-178.821628, ESS=3.691 (12s)\n",
      "epoch=1350, EUBO=-163.762554, ELBO=-178.926393, ESS=3.412 (12s)\n",
      "epoch=1360, EUBO=-163.885222, ELBO=-178.854068, ESS=3.485 (13s)\n",
      "epoch=1370, EUBO=-163.858291, ELBO=-178.792915, ESS=3.609 (13s)\n",
      "epoch=1380, EUBO=-163.778453, ELBO=-178.786842, ESS=3.574 (12s)\n",
      "epoch=1390, EUBO=-163.752669, ELBO=-179.054058, ESS=3.493 (12s)\n",
      "epoch=1400, EUBO=-163.806967, ELBO=-178.918131, ESS=3.462 (12s)\n",
      "epoch=1410, EUBO=-163.770696, ELBO=-178.820386, ESS=3.525 (13s)\n",
      "epoch=1420, EUBO=-163.629570, ELBO=-179.127349, ESS=3.318 (12s)\n",
      "epoch=1430, EUBO=-163.782119, ELBO=-178.861617, ESS=3.494 (13s)\n",
      "epoch=1440, EUBO=-163.802614, ELBO=-178.935405, ESS=3.516 (13s)\n",
      "epoch=1450, EUBO=-163.841495, ELBO=-178.757052, ESS=3.597 (13s)\n",
      "epoch=1460, EUBO=-163.784993, ELBO=-178.758918, ESS=3.555 (13s)\n",
      "epoch=1470, EUBO=-163.855443, ELBO=-178.621239, ESS=3.607 (13s)\n",
      "epoch=1480, EUBO=-163.683864, ELBO=-178.863682, ESS=3.476 (12s)\n",
      "epoch=1490, EUBO=-163.837794, ELBO=-178.662627, ESS=3.605 (13s)\n",
      "epoch=1500, EUBO=-163.818130, ELBO=-178.867408, ESS=3.600 (13s)\n",
      "epoch=1510, EUBO=-163.768214, ELBO=-178.655620, ESS=3.555 (12s)\n",
      "epoch=1520, EUBO=-163.816832, ELBO=-178.830140, ESS=3.658 (12s)\n",
      "epoch=1530, EUBO=-163.899046, ELBO=-178.489377, ESS=3.725 (12s)\n",
      "epoch=1540, EUBO=-163.704579, ELBO=-178.709075, ESS=3.538 (13s)\n",
      "epoch=1550, EUBO=-163.589837, ELBO=-178.853636, ESS=3.410 (12s)\n",
      "epoch=1560, EUBO=-163.652021, ELBO=-178.714183, ESS=3.501 (13s)\n",
      "epoch=1570, EUBO=-163.863166, ELBO=-178.696728, ESS=3.751 (12s)\n",
      "epoch=1580, EUBO=-163.825038, ELBO=-178.630174, ESS=3.675 (13s)\n",
      "epoch=1590, EUBO=-163.705360, ELBO=-178.658137, ESS=3.521 (13s)\n",
      "epoch=1600, EUBO=-163.707979, ELBO=-178.663200, ESS=3.543 (13s)\n",
      "epoch=1610, EUBO=-163.693677, ELBO=-178.540757, ESS=3.610 (13s)\n",
      "epoch=1620, EUBO=-163.825296, ELBO=-178.406955, ESS=3.717 (13s)\n",
      "epoch=1630, EUBO=-163.771632, ELBO=-178.530289, ESS=3.566 (12s)\n",
      "epoch=1640, EUBO=-163.793511, ELBO=-178.703116, ESS=3.642 (13s)\n",
      "epoch=1650, EUBO=-163.843325, ELBO=-178.700941, ESS=3.825 (12s)\n",
      "epoch=1660, EUBO=-163.801581, ELBO=-178.641472, ESS=3.633 (13s)\n",
      "epoch=1670, EUBO=-163.680038, ELBO=-178.423455, ESS=3.604 (12s)\n",
      "epoch=1680, EUBO=-163.755152, ELBO=-178.436245, ESS=3.680 (12s)\n",
      "epoch=1690, EUBO=-163.786594, ELBO=-178.525421, ESS=3.611 (12s)\n",
      "epoch=1700, EUBO=-163.653552, ELBO=-178.475467, ESS=3.562 (13s)\n",
      "epoch=1710, EUBO=-163.697459, ELBO=-178.424336, ESS=3.673 (13s)\n",
      "epoch=1720, EUBO=-163.854495, ELBO=-178.356241, ESS=3.778 (12s)\n",
      "epoch=1730, EUBO=-163.742431, ELBO=-178.466654, ESS=3.647 (12s)\n",
      "epoch=1740, EUBO=-163.789922, ELBO=-178.542462, ESS=3.607 (13s)\n",
      "epoch=1750, EUBO=-163.822438, ELBO=-178.431981, ESS=3.730 (12s)\n",
      "epoch=1760, EUBO=-163.737511, ELBO=-178.442892, ESS=3.626 (12s)\n",
      "epoch=1770, EUBO=-163.712669, ELBO=-178.514816, ESS=3.721 (12s)\n",
      "epoch=1780, EUBO=-163.826382, ELBO=-178.449961, ESS=3.689 (13s)\n",
      "epoch=1790, EUBO=-163.807412, ELBO=-178.239133, ESS=3.733 (12s)\n",
      "epoch=1800, EUBO=-163.799612, ELBO=-178.207856, ESS=3.816 (12s)\n",
      "epoch=1810, EUBO=-163.865783, ELBO=-177.955422, ESS=3.864 (12s)\n",
      "epoch=1820, EUBO=-163.788332, ELBO=-178.212630, ESS=3.749 (12s)\n",
      "epoch=1830, EUBO=-163.698463, ELBO=-178.242290, ESS=3.657 (13s)\n",
      "epoch=1840, EUBO=-163.851267, ELBO=-178.367465, ESS=3.801 (12s)\n",
      "epoch=1850, EUBO=-163.738013, ELBO=-178.161731, ESS=3.732 (12s)\n",
      "epoch=1860, EUBO=-163.778342, ELBO=-178.385267, ESS=3.600 (12s)\n",
      "epoch=1870, EUBO=-163.726454, ELBO=-178.131683, ESS=3.840 (14s)\n"
     ]
    }
   ],
   "source": [
    "EUBOs = []\n",
    "ELBOs = []\n",
    "ESSs = []\n",
    "MCKls_inclusive = []\n",
    "TrueKls_inclusive = []\n",
    "MCKls_exclusive = []\n",
    "TrueKls_exclusive = []\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "time_start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    ESS = 0.0\n",
    "#     MCKl_inclusive = 0.0\n",
    "#     TrueKl_inclusive = 0.0\n",
    "#     MCKl_exclusive = 0.0\n",
    "#     TrueKl_exclusive = 0.0\n",
    "    for step in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "        batch_Zs = Zs[batch_indices]\n",
    "        batch_Xs, batch_Zs = shuffler(batch_Xs, batch_Zs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess = rws(batch_Xs, batch_Zs, Pi, N, K, D, NUM_SAMPLES, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        ESS += ess.item()\n",
    "#         MCKl_inclusive += mckl_inclusive.item()\n",
    "#         MCKl_exclusive += mckl_exclusive.item()\n",
    "#         TrueKl_inclusive += truekl_inclusive.item()\n",
    "#         TrueKl_exclusive += truekl_exclusive.item()\n",
    "        \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    ESS /= num_batches\n",
    "#     MCKl_inclusive /= num_batches\n",
    "#     TrueKl_inclusive /= num_batches\n",
    "#     MCKl_exclusive /= num_batches\n",
    "#     TrueKl_exclusive /= num_batches\n",
    "    \n",
    "    EUBOs.append(EUBO)\n",
    "    ELBOs.append(ELBO)\n",
    "    ESSs.append(ESS)\n",
    "#     MCKls_inclusive.append(MCKl_inclusive)\n",
    "#     TrueKls_inclusive.append(TrueKl_inclusive)\n",
    "#     MCKls_exclusive.append(MCKl_exclusive)\n",
    "#     TrueKls_exclusive.append(TrueKl_exclusive)\n",
    "    \n",
    "#     time_end = time.time()\n",
    "    if epoch % 10 == 0:\n",
    "        time_end = time.time()\n",
    "        print('epoch=%d, EUBO=%f, ELBO=%f, ESS=%.3f (%ds)' % (epoch, EUBO, ELBO, ESS, time_end - time_start))\n",
    "        time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, num_samples, num_epochs, lr):\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    fig.tight_layout()\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax2.plot(TrueKls_exclusive, '#66b3ff', label='true exclusive KL')\n",
    "    ax2.plot(MCKls_exclusive, '#ff9999', label='est exclusive KL')\n",
    "    ax2.plot(TrueKls_inclusive, '#99ff99', label='true inclusive KL')\n",
    "    ax2.plot(MCKls_inclusive, 'gold', label='est inclusive KL')\n",
    "    \n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax3.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax1.set_title('epoch=%d, batch_size=%d, lr=%.1E, samples=%d' % (num_epochs, BATCH_SIZE, lr, num_samples), fontsize=18)\n",
    "    ax1.set_ylim([-300, -80])\n",
    "    ax1.legend()\n",
    "    ax2.set_ylim([-50, 50])\n",
    "    ax2.legend()\n",
    "    ax3.legend()\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax3.tick_params(labelsize=18)\n",
    "    plt.savefig('gmm_rws_datatodist_lr=%.1E_samples=%d.svg' % (lr, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, NUM_SAMPLES, NUM_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
