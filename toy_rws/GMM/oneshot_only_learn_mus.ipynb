{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 10\n",
    "NUM_HIDDEN = 64\n",
    "NUM_STATS = K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS = D\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset/sequences.npy')).float()\n",
    "Zs = torch.from_numpy(np.load('gmm_dataset/states.npy')).float()\n",
    "mus_true = torch.from_numpy(np.load('gmm_dataset/means.npy')).float()\n",
    "covs = torch.from_numpy(np.load('gmm_dataset/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset/init.npy')).float()\n",
    "num_seqs = Zs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatsGMM(Xs, Zs, K, D):\n",
    "    \"\"\"\n",
    "    Xs is B * N * D\n",
    "    Zs is B * N * K\n",
    "    return B * (K+D*K)\n",
    "    \"\"\"\n",
    "    stat1 = Zs.sum(1)\n",
    "    stat2 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    return stat1, stat2, torch.cat((stat1, stat2.view(-1, D*K)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "        self.enc_hidden = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.ReLU())\n",
    "        self.mean = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.log_std = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        hidden = self.enc_hidden(stats)\n",
    "        mean = self.mean(hidden).view(-1, K, D)\n",
    "        std = torch.exp(self.log_std(hidden).view(-1, K, D))\n",
    "        mus = Normal(mean, std).sample((num_samples, )) ## S * B * K * D\n",
    "        return mean, std, mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters()),lr=LEARNING_RATE)    \n",
    "    return enc, optimizer\n",
    "enc, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_joints_gmm(Pi, mus, covs, Xs, N, D, K, num_samples, batch_size):\n",
    "#     log_probs = torch.zeros((num_samples, batch_size)).float()\n",
    "#     ## S * B\n",
    "#     log_probs = log_probs + Normal(torch.zeros((batch_size, K, D)), torch.ones((batch_size, K, D))).log_prob(mus).sum(-1).sum(-1)\n",
    "#     covs_expand = covs.unsqueeze(0).repeat(N, 1, 1, 1).transpose(0, 2).unsqueeze(0).repeat(num_samples, 1, 1, 1, 1) ## S * K * B * N * D\n",
    "#     mus_expand = mus.unsqueeze(1).repeat(1, N, 1, 1, 1).transpose(1, 3) ## S * K * B * N * D\n",
    "#     log_p_lls = Normal(mus_expand, covs_expand).log_prob(Xs).sum(-1) ## S * K * B * N\n",
    "#     log_probs = log_probs + logsumexp(log_p_lls, dim=1).sum(-1) - N * torch.log(torch.FloatTensor([K]))\n",
    "#     return log_probs\n",
    "\n",
    "def log_joints_gmm(Z, Pi, mus, covs, Xs, N, D, K, num_samples, batch_size):\n",
    "    log_probs = torch.zeros((num_samples, batch_size)).float()\n",
    "    ## S * B\n",
    "    log_probs = log_probs + Normal(torch.zeros((batch_size, K, D)), torch.ones((batch_size, K, D))).log_prob(mus).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "    log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    covs_expand = covs.unsqueeze(0).repeat(num_samples, 1, 1, 1)\n",
    "    log_probs = log_probs + Normal(mus[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D), covs_expand[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D)).log_prob(Xs).sum(-1).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "def conjugate_posterior(stat1, stat2, covs, K, D, batch_size):\n",
    "    prior_covs_inv = torch.ones(K, D)\n",
    "    posterior_covs = 1. / (prior_covs_inv + torch.mul(stat1.unsqueeze(-1).repeat(1, 1, D), 1. / covs))\n",
    "    posterior_mean = torch.mul(posterior_covs, torch.mul(stat2, 1. / covs))\n",
    "    return posterior_mean, posterior_covs\n",
    "\n",
    "def kl_normal_normal(p_mean, p_std, q_mean, q_std):\n",
    "    var_ratio = (p_std / q_std).pow(2)\n",
    "    t1 = ((p_mean - q_mean) / q_std).pow(2)\n",
    "    return 0.5 * (var_ratio + t1 - 1 - var_ratio.log())\n",
    "\n",
    "def kls_gaussians(weights, mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D):\n",
    "    log_q = Normal(mus_mean, mus_std).log_prob(mus).sum(-1).sum(-1)\n",
    "    log_p = Normal(posterior_mean, torch.sqrt(posterior_covs)).log_prob(mus).sum(-1).sum(-1)\n",
    "    MCKl_exclusive = (log_q - log_p).mean(0).mean()\n",
    "    TrueKl_exclusive = kl_normal_normal(mus_mean, mus_std, posterior_mean, torch.sqrt(posterior_covs)).mean()\n",
    "    \n",
    "    MCKl_inclusive = torch.mul(weights, log_p - log_q).sum(0).mean()\n",
    "    TrueKl_inclusive = kl_normal_normal(posterior_mean, torch.sqrt(posterior_covs), mus_mean, mus_std).mean()\n",
    "    return MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive\n",
    "    \n",
    "def rws(Xs, Zs, Pi, covs, N, K, D, num_samples, batch_size):\n",
    "    stat1, stat2, stats = StatsGMM(Xs, Zs, K, D)\n",
    "    data = Xs.view(batch_size*N, -1)\n",
    "    mus_mean, mus_std, mus = enc(data, K, D, num_samples, batch_size)\n",
    "    log_q = Normal(mus_mean, mus_std).log_prob(mus).sum(-1).sum(-1) ## S * B\n",
    "#     print(log_q.sum())\n",
    "    log_p = log_joints_gmm(batch_Zs, Pi, mus, covs, Xs, N, D, K, num_samples, batch_size)\n",
    "    log_weights = log_p - log_q\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "    eubo = torch.mul(weights, log_weights).sum(0).mean()\n",
    "    elbo = log_weights.mean(0).mean()\n",
    "    ess = (1. / (weights ** 2).sum(0)).mean()\n",
    "    posterior_mean, posterior_covs = conjugate_posterior(stat1, stat2, covs, K, D, batch_size)\n",
    "    MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive = kls_gaussians(weights, mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D)\n",
    "    return eubo, elbo, ess, MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive\n",
    "\n",
    "def shuffler(batch_Xs, batch_Zs, N, K, D, batch_size):\n",
    "    indices = torch.cat([torch.randperm(N).unsqueeze(0) for b in range(batch_size)])\n",
    "    indices_Xs = indices.unsqueeze(-1).repeat(1, 1, D)\n",
    "    indices_Zs = indices.unsqueeze(-1).repeat(1, 1, K)\n",
    "    return torch.gather(batch_Xs, 1, indices_Xs), torch.gather(batch_Zs, 1, indices_Zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-1182422817530166.250000, ELBO=-45884017144863792.000000, ESS=1.003, inc MCKL=-573189878331491.250000, inc TKL=265590904.334531, exc MCKL=25598632186555756.000000, exc TKL=3878685423100914.500000 (0s)\n",
      "epoch=10, EUBO=-771.536988, ELBO=-2491.579279, ESS=1.034, inc MCKL=-430.785623, inc TKL=7584940916.451494, exc MCKL=1575.733752, exc TKL=252.360525 (5s)\n",
      "epoch=20, EUBO=-667.950650, ELBO=-1312.125728, ESS=1.029, inc MCKL=-351.663277, inc TKL=117221954.760106, exc MCKL=782.986686, exc TKL=129.794845 (5s)\n",
      "epoch=30, EUBO=-623.114935, ELBO=-1138.718393, ESS=1.033, inc MCKL=-322.874606, inc TKL=2365083.736669, exc MCKL=654.126100, exc TKL=109.909221 (5s)\n",
      "epoch=40, EUBO=-599.444606, ELBO=-1087.479728, ESS=1.023, inc MCKL=-308.802070, inc TKL=28836.680083, exc MCKL=620.026581, exc TKL=103.409496 (5s)\n",
      "epoch=50, EUBO=-569.597986, ELBO=-1037.645629, ESS=1.028, inc MCKL=-289.288349, inc TKL=414.311697, exc MCKL=585.250741, exc TKL=98.955954 (5s)\n",
      "epoch=60, EUBO=-554.735721, ELBO=-1011.470476, ESS=1.025, inc MCKL=-282.966734, inc TKL=72.678661, exc MCKL=568.307572, exc TKL=93.458178 (5s)\n",
      "epoch=70, EUBO=-529.798779, ELBO=-1004.798458, ESS=1.023, inc MCKL=-267.148225, inc TKL=16.841667, exc MCKL=566.525929, exc TKL=95.057739 (6s)\n",
      "epoch=80, EUBO=-516.472658, ELBO=-978.633987, ESS=1.021, inc MCKL=-259.552197, inc TKL=19.448183, exc MCKL=543.934323, exc TKL=90.698514 (5s)\n",
      "epoch=90, EUBO=-513.712239, ELBO=-970.431696, ESS=1.021, inc MCKL=-256.255366, inc TKL=14.869477, exc MCKL=546.488383, exc TKL=90.545841 (5s)\n",
      "epoch=100, EUBO=-495.581014, ELBO=-998.185282, ESS=1.021, inc MCKL=-246.246334, inc TKL=10.886539, exc MCKL=559.761365, exc TKL=92.409850 (6s)\n",
      "epoch=110, EUBO=-480.895585, ELBO=-961.760761, ESS=1.023, inc MCKL=-238.310875, inc TKL=5.508902, exc MCKL=537.608156, exc TKL=90.481887 (5s)\n",
      "epoch=120, EUBO=-486.944149, ELBO=-977.358466, ESS=1.022, inc MCKL=-242.298864, inc TKL=6.939396, exc MCKL=543.190495, exc TKL=90.326577 (4s)\n",
      "epoch=130, EUBO=-479.083495, ELBO=-961.727536, ESS=1.016, inc MCKL=-238.855105, inc TKL=5.769134, exc MCKL=533.736465, exc TKL=89.352239 (5s)\n",
      "epoch=140, EUBO=-479.597438, ELBO=-917.861862, ESS=1.026, inc MCKL=-235.601201, inc TKL=5.839249, exc MCKL=503.065718, exc TKL=84.146502 (4s)\n",
      "epoch=150, EUBO=-464.607774, ELBO=-960.462310, ESS=1.024, inc MCKL=-228.670769, inc TKL=5.072480, exc MCKL=533.644749, exc TKL=88.154759 (6s)\n",
      "epoch=160, EUBO=-450.875842, ELBO=-920.124996, ESS=1.017, inc MCKL=-215.796959, inc TKL=4.709675, exc MCKL=504.996458, exc TKL=84.948249 (5s)\n",
      "epoch=170, EUBO=-452.904286, ELBO=-935.498484, ESS=1.025, inc MCKL=-219.641672, inc TKL=4.621411, exc MCKL=519.719373, exc TKL=86.466378 (5s)\n",
      "epoch=180, EUBO=-448.809168, ELBO=-899.895719, ESS=1.027, inc MCKL=-215.169294, inc TKL=4.819053, exc MCKL=495.122918, exc TKL=82.957089 (5s)\n",
      "epoch=190, EUBO=-461.548759, ELBO=-858.253652, ESS=1.024, inc MCKL=-222.141788, inc TKL=6.979647, exc MCKL=468.377812, exc TKL=78.697399 (5s)\n",
      "epoch=200, EUBO=-448.614756, ELBO=-885.354081, ESS=1.019, inc MCKL=-217.122147, inc TKL=4.961762, exc MCKL=486.705457, exc TKL=81.136067 (6s)\n",
      "epoch=210, EUBO=-432.309714, ELBO=-915.739603, ESS=1.023, inc MCKL=-207.219318, inc TKL=4.014919, exc MCKL=505.187943, exc TKL=83.935251 (5s)\n",
      "epoch=220, EUBO=-432.241984, ELBO=-881.928058, ESS=1.029, inc MCKL=-205.288067, inc TKL=4.100748, exc MCKL=483.878298, exc TKL=81.086643 (5s)\n",
      "epoch=230, EUBO=-433.531765, ELBO=-942.254847, ESS=1.020, inc MCKL=-208.967823, inc TKL=3.911903, exc MCKL=521.752024, exc TKL=86.788424 (5s)\n",
      "epoch=240, EUBO=-429.104082, ELBO=-906.931330, ESS=1.026, inc MCKL=-204.558931, inc TKL=3.934088, exc MCKL=499.757991, exc TKL=83.380272 (5s)\n",
      "epoch=250, EUBO=-425.997564, ELBO=-909.670363, ESS=1.027, inc MCKL=-203.015031, inc TKL=3.964466, exc MCKL=498.769836, exc TKL=82.697852 (5s)\n",
      "epoch=260, EUBO=-443.234785, ELBO=-873.290536, ESS=1.029, inc MCKL=-212.518298, inc TKL=5.499951, exc MCKL=479.337717, exc TKL=79.786952 (5s)\n",
      "epoch=270, EUBO=-429.230310, ELBO=-868.402343, ESS=1.025, inc MCKL=-204.010723, inc TKL=4.235049, exc MCKL=473.076364, exc TKL=79.131047 (5s)\n",
      "epoch=280, EUBO=-433.643856, ELBO=-845.785205, ESS=1.024, inc MCKL=-206.481052, inc TKL=4.705317, exc MCKL=461.043746, exc TKL=77.133047 (5s)\n",
      "epoch=290, EUBO=-429.295018, ELBO=-881.995814, ESS=1.033, inc MCKL=-203.351106, inc TKL=4.566297, exc MCKL=480.548507, exc TKL=80.008516 (5s)\n",
      "epoch=300, EUBO=-444.279644, ELBO=-843.033934, ESS=1.028, inc MCKL=-213.422248, inc TKL=5.536801, exc MCKL=457.625603, exc TKL=75.735288 (6s)\n",
      "epoch=310, EUBO=-419.219960, ELBO=-894.115948, ESS=1.027, inc MCKL=-198.250374, inc TKL=4.307067, exc MCKL=492.295945, exc TKL=81.603627 (5s)\n",
      "epoch=320, EUBO=-423.621613, ELBO=-890.220081, ESS=1.018, inc MCKL=-198.763333, inc TKL=3.956198, exc MCKL=490.124392, exc TKL=83.068886 (5s)\n",
      "epoch=330, EUBO=-412.242005, ELBO=-947.926372, ESS=1.023, inc MCKL=-196.361699, inc TKL=3.368380, exc MCKL=524.025128, exc TKL=87.570865 (5s)\n",
      "epoch=340, EUBO=-426.364265, ELBO=-836.447107, ESS=1.030, inc MCKL=-203.620460, inc TKL=4.806904, exc MCKL=451.505518, exc TKL=75.043898 (5s)\n",
      "epoch=350, EUBO=-419.687748, ELBO=-917.274625, ESS=1.023, inc MCKL=-198.822240, inc TKL=3.735806, exc MCKL=508.638449, exc TKL=84.780898 (5s)\n",
      "epoch=360, EUBO=-426.492607, ELBO=-866.073512, ESS=1.023, inc MCKL=-202.135308, inc TKL=5.491057, exc MCKL=478.309874, exc TKL=80.349886 (5s)\n",
      "epoch=370, EUBO=-425.800622, ELBO=-863.810423, ESS=1.022, inc MCKL=-201.396599, inc TKL=4.931830, exc MCKL=471.058549, exc TKL=78.727164 (5s)\n",
      "epoch=380, EUBO=-416.514690, ELBO=-877.992488, ESS=1.026, inc MCKL=-197.868315, inc TKL=4.644789, exc MCKL=482.350961, exc TKL=80.274707 (5s)\n",
      "epoch=390, EUBO=-428.519561, ELBO=-861.457237, ESS=1.029, inc MCKL=-201.883441, inc TKL=4.594977, exc MCKL=472.510038, exc TKL=79.812899 (5s)\n",
      "epoch=400, EUBO=-422.485209, ELBO=-875.951571, ESS=1.024, inc MCKL=-199.463707, inc TKL=4.123349, exc MCKL=480.308550, exc TKL=79.241360 (6s)\n",
      "epoch=410, EUBO=-412.155801, ELBO=-901.989527, ESS=1.026, inc MCKL=-194.468540, inc TKL=3.704057, exc MCKL=498.091931, exc TKL=82.800064 (5s)\n",
      "epoch=420, EUBO=-431.403510, ELBO=-876.288447, ESS=1.033, inc MCKL=-206.314749, inc TKL=5.190052, exc MCKL=479.408583, exc TKL=79.602818 (5s)\n",
      "epoch=430, EUBO=-410.011733, ELBO=-887.941260, ESS=1.032, inc MCKL=-191.677950, inc TKL=3.752259, exc MCKL=485.199440, exc TKL=81.428565 (5s)\n",
      "epoch=440, EUBO=-423.370359, ELBO=-909.369177, ESS=1.021, inc MCKL=-200.843632, inc TKL=7.121864, exc MCKL=499.265079, exc TKL=82.614610 (5s)\n",
      "epoch=450, EUBO=-419.053099, ELBO=-877.855569, ESS=1.024, inc MCKL=-196.595076, inc TKL=4.082253, exc MCKL=483.913226, exc TKL=80.827549 (5s)\n",
      "epoch=460, EUBO=-413.497441, ELBO=-876.020823, ESS=1.021, inc MCKL=-195.240539, inc TKL=3.918761, exc MCKL=478.416567, exc TKL=79.256259 (5s)\n",
      "epoch=470, EUBO=-416.932965, ELBO=-861.059518, ESS=1.022, inc MCKL=-195.635794, inc TKL=4.080235, exc MCKL=469.616464, exc TKL=78.359908 (5s)\n",
      "epoch=480, EUBO=-413.794101, ELBO=-865.464199, ESS=1.024, inc MCKL=-197.279325, inc TKL=4.149155, exc MCKL=474.635119, exc TKL=79.601299 (5s)\n",
      "epoch=490, EUBO=-419.924580, ELBO=-853.763816, ESS=1.032, inc MCKL=-197.534918, inc TKL=3.988128, exc MCKL=468.598720, exc TKL=78.212759 (5s)\n",
      "epoch=500, EUBO=-406.331381, ELBO=-906.193345, ESS=1.022, inc MCKL=-189.038045, inc TKL=3.519407, exc MCKL=499.141161, exc TKL=83.181377 (6s)\n",
      "epoch=510, EUBO=-413.781681, ELBO=-882.033807, ESS=1.028, inc MCKL=-197.250857, inc TKL=4.174088, exc MCKL=486.549283, exc TKL=81.194776 (6s)\n",
      "epoch=520, EUBO=-414.354661, ELBO=-869.400091, ESS=1.026, inc MCKL=-197.894626, inc TKL=4.086794, exc MCKL=477.791878, exc TKL=80.634525 (6s)\n",
      "epoch=530, EUBO=-413.862566, ELBO=-875.077927, ESS=1.029, inc MCKL=-194.937780, inc TKL=4.062697, exc MCKL=480.085699, exc TKL=80.234531 (5s)\n",
      "epoch=540, EUBO=-411.795843, ELBO=-895.572486, ESS=1.023, inc MCKL=-192.124015, inc TKL=3.744510, exc MCKL=494.275200, exc TKL=82.221425 (4s)\n",
      "epoch=550, EUBO=-416.336704, ELBO=-877.139464, ESS=1.029, inc MCKL=-199.485572, inc TKL=4.521532, exc MCKL=483.316971, exc TKL=80.327113 (5s)\n",
      "epoch=560, EUBO=-422.006976, ELBO=-887.458472, ESS=1.027, inc MCKL=-199.990543, inc TKL=4.869040, exc MCKL=493.332730, exc TKL=82.517346 (5s)\n",
      "epoch=570, EUBO=-414.660430, ELBO=-907.144899, ESS=1.025, inc MCKL=-194.198979, inc TKL=3.950548, exc MCKL=504.574343, exc TKL=83.072768 (7s)\n",
      "epoch=580, EUBO=-412.530873, ELBO=-902.225491, ESS=1.033, inc MCKL=-196.270748, inc TKL=3.793027, exc MCKL=499.930317, exc TKL=84.241455 (5s)\n",
      "epoch=590, EUBO=-414.914865, ELBO=-864.045583, ESS=1.025, inc MCKL=-194.919371, inc TKL=3.989877, exc MCKL=477.122108, exc TKL=79.106115 (6s)\n",
      "epoch=600, EUBO=-401.241538, ELBO=-892.262182, ESS=1.025, inc MCKL=-188.857427, inc TKL=3.791025, exc MCKL=491.211412, exc TKL=82.597019 (6s)\n",
      "epoch=610, EUBO=-414.174511, ELBO=-874.358863, ESS=1.034, inc MCKL=-192.709966, inc TKL=3.925411, exc MCKL=476.357312, exc TKL=79.149325 (5s)\n",
      "epoch=620, EUBO=-414.582872, ELBO=-886.374043, ESS=1.026, inc MCKL=-195.999053, inc TKL=3.905372, exc MCKL=486.191536, exc TKL=80.271677 (5s)\n",
      "epoch=630, EUBO=-409.565082, ELBO=-910.803053, ESS=1.028, inc MCKL=-191.975034, inc TKL=3.741467, exc MCKL=506.247439, exc TKL=84.383365 (5s)\n",
      "epoch=640, EUBO=-408.095758, ELBO=-873.344069, ESS=1.024, inc MCKL=-191.757866, inc TKL=4.107166, exc MCKL=483.726158, exc TKL=80.131105 (5s)\n",
      "epoch=650, EUBO=-412.399587, ELBO=-880.060425, ESS=1.024, inc MCKL=-191.130035, inc TKL=4.090960, exc MCKL=481.849368, exc TKL=80.872704 (5s)\n",
      "epoch=660, EUBO=-410.863612, ELBO=-874.838575, ESS=1.026, inc MCKL=-191.580227, inc TKL=4.275743, exc MCKL=476.306829, exc TKL=79.185521 (5s)\n",
      "epoch=670, EUBO=-415.506426, ELBO=-874.943090, ESS=1.032, inc MCKL=-195.212218, inc TKL=5.572797, exc MCKL=481.604078, exc TKL=80.230146 (5s)\n",
      "epoch=680, EUBO=-409.118468, ELBO=-868.388144, ESS=1.025, inc MCKL=-191.302888, inc TKL=4.547183, exc MCKL=477.453090, exc TKL=80.728451 (5s)\n",
      "epoch=690, EUBO=-405.615829, ELBO=-858.503774, ESS=1.028, inc MCKL=-188.372371, inc TKL=4.091427, exc MCKL=470.234706, exc TKL=78.359095 (6s)\n",
      "epoch=700, EUBO=-410.390179, ELBO=-871.478218, ESS=1.025, inc MCKL=-189.771265, inc TKL=4.081965, exc MCKL=478.300779, exc TKL=79.389763 (5s)\n",
      "epoch=710, EUBO=-402.554173, ELBO=-875.500100, ESS=1.027, inc MCKL=-189.568086, inc TKL=3.956957, exc MCKL=483.128181, exc TKL=80.359147 (5s)\n",
      "epoch=720, EUBO=-413.480990, ELBO=-851.017687, ESS=1.023, inc MCKL=-197.828008, inc TKL=4.366140, exc MCKL=468.095212, exc TKL=77.314063 (5s)\n",
      "epoch=730, EUBO=-405.529328, ELBO=-854.840216, ESS=1.027, inc MCKL=-189.519348, inc TKL=5.228927, exc MCKL=469.865876, exc TKL=78.463829 (5s)\n",
      "epoch=740, EUBO=-411.157030, ELBO=-859.133300, ESS=1.026, inc MCKL=-196.128483, inc TKL=4.673716, exc MCKL=468.798670, exc TKL=78.479980 (5s)\n",
      "epoch=750, EUBO=-411.899636, ELBO=-873.629532, ESS=1.028, inc MCKL=-193.303836, inc TKL=6.105515, exc MCKL=478.703574, exc TKL=79.434491 (5s)\n",
      "epoch=760, EUBO=-418.154430, ELBO=-857.438666, ESS=1.034, inc MCKL=-196.546366, inc TKL=5.721728, exc MCKL=466.044016, exc TKL=76.230165 (5s)\n",
      "epoch=770, EUBO=-401.519094, ELBO=-896.751065, ESS=1.020, inc MCKL=-188.297404, inc TKL=4.848732, exc MCKL=497.082827, exc TKL=82.589428 (5s)\n",
      "epoch=780, EUBO=-408.483343, ELBO=-876.333253, ESS=1.023, inc MCKL=-193.579345, inc TKL=5.705102, exc MCKL=484.714345, exc TKL=81.174611 (5s)\n",
      "epoch=790, EUBO=-406.896172, ELBO=-855.615296, ESS=1.032, inc MCKL=-190.255195, inc TKL=5.404993, exc MCKL=470.054237, exc TKL=78.910347 (5s)\n",
      "epoch=800, EUBO=-410.087047, ELBO=-852.678229, ESS=1.030, inc MCKL=-194.619596, inc TKL=5.805076, exc MCKL=470.695669, exc TKL=78.597415 (6s)\n",
      "epoch=810, EUBO=-406.334351, ELBO=-859.209822, ESS=1.033, inc MCKL=-188.076739, inc TKL=4.977993, exc MCKL=466.046918, exc TKL=77.923386 (5s)\n",
      "epoch=820, EUBO=-408.806053, ELBO=-860.391544, ESS=1.030, inc MCKL=-193.877613, inc TKL=5.058017, exc MCKL=474.030725, exc TKL=79.710979 (5s)\n",
      "epoch=830, EUBO=-401.968822, ELBO=-874.321076, ESS=1.032, inc MCKL=-188.769335, inc TKL=4.889583, exc MCKL=479.801429, exc TKL=79.340520 (5s)\n",
      "epoch=840, EUBO=-413.531845, ELBO=-847.335184, ESS=1.033, inc MCKL=-192.623354, inc TKL=5.906518, exc MCKL=467.145968, exc TKL=78.308885 (5s)\n",
      "epoch=850, EUBO=-406.218452, ELBO=-906.734232, ESS=1.017, inc MCKL=-194.749798, inc TKL=3.886743, exc MCKL=508.143273, exc TKL=85.390335 (5s)\n",
      "epoch=860, EUBO=-402.552548, ELBO=-899.245564, ESS=1.028, inc MCKL=-187.170350, inc TKL=4.244446, exc MCKL=495.304385, exc TKL=82.047555 (5s)\n",
      "epoch=870, EUBO=-411.135887, ELBO=-867.643948, ESS=1.026, inc MCKL=-191.957619, inc TKL=5.413331, exc MCKL=480.109772, exc TKL=79.187063 (5s)\n",
      "epoch=880, EUBO=-406.802042, ELBO=-873.638605, ESS=1.027, inc MCKL=-189.622181, inc TKL=4.917136, exc MCKL=480.811119, exc TKL=79.444223 (5s)\n",
      "epoch=890, EUBO=-408.405373, ELBO=-874.698609, ESS=1.021, inc MCKL=-192.455947, inc TKL=4.305507, exc MCKL=482.120486, exc TKL=79.872387 (5s)\n",
      "epoch=900, EUBO=-407.022238, ELBO=-879.430078, ESS=1.026, inc MCKL=-191.970147, inc TKL=6.376473, exc MCKL=480.624325, exc TKL=79.922413 (6s)\n",
      "epoch=910, EUBO=-402.396041, ELBO=-884.673618, ESS=1.022, inc MCKL=-188.993737, inc TKL=4.370439, exc MCKL=488.481078, exc TKL=81.376251 (5s)\n",
      "epoch=920, EUBO=-408.337027, ELBO=-855.184128, ESS=1.032, inc MCKL=-191.266182, inc TKL=4.933679, exc MCKL=469.792462, exc TKL=77.610866 (5s)\n",
      "epoch=930, EUBO=-402.749595, ELBO=-901.394662, ESS=1.030, inc MCKL=-189.217494, inc TKL=5.753095, exc MCKL=495.977303, exc TKL=81.767533 (5s)\n",
      "epoch=940, EUBO=-407.710973, ELBO=-860.649038, ESS=1.033, inc MCKL=-193.088719, inc TKL=5.666686, exc MCKL=471.209305, exc TKL=78.454639 (5s)\n",
      "epoch=950, EUBO=-403.393161, ELBO=-883.955383, ESS=1.036, inc MCKL=-187.332213, inc TKL=5.543754, exc MCKL=486.128055, exc TKL=80.823066 (5s)\n",
      "epoch=960, EUBO=-402.233128, ELBO=-898.838950, ESS=1.029, inc MCKL=-188.872993, inc TKL=4.381689, exc MCKL=501.128981, exc TKL=82.762517 (5s)\n",
      "epoch=970, EUBO=-406.708783, ELBO=-897.281953, ESS=1.029, inc MCKL=-191.758937, inc TKL=4.085577, exc MCKL=504.127160, exc TKL=83.927424 (5s)\n",
      "epoch=980, EUBO=-408.618753, ELBO=-846.154688, ESS=1.031, inc MCKL=-190.559172, inc TKL=5.377064, exc MCKL=460.710866, exc TKL=76.912408 (5s)\n",
      "epoch=990, EUBO=-410.013512, ELBO=-869.742584, ESS=1.025, inc MCKL=-195.152376, inc TKL=4.921292, exc MCKL=478.157538, exc TKL=79.492425 (5s)\n",
      "epoch=1000, EUBO=-411.765766, ELBO=-865.263746, ESS=1.029, inc MCKL=-194.593289, inc TKL=4.969599, exc MCKL=470.901866, exc TKL=78.399657 (6s)\n",
      "epoch=1010, EUBO=-410.534175, ELBO=-876.920573, ESS=1.031, inc MCKL=-191.244466, inc TKL=4.507265, exc MCKL=487.835779, exc TKL=81.715957 (5s)\n",
      "epoch=1020, EUBO=-408.429060, ELBO=-842.245632, ESS=1.031, inc MCKL=-191.551595, inc TKL=5.141927, exc MCKL=463.253177, exc TKL=77.226611 (5s)\n",
      "epoch=1030, EUBO=-404.919639, ELBO=-859.347071, ESS=1.035, inc MCKL=-190.465127, inc TKL=5.574253, exc MCKL=470.983867, exc TKL=78.354044 (5s)\n",
      "epoch=1040, EUBO=-402.492638, ELBO=-850.621801, ESS=1.031, inc MCKL=-188.857613, inc TKL=4.939690, exc MCKL=465.274099, exc TKL=78.833060 (5s)\n",
      "epoch=1050, EUBO=-401.701158, ELBO=-847.655364, ESS=1.028, inc MCKL=-188.165039, inc TKL=5.031919, exc MCKL=464.321080, exc TKL=77.108220 (5s)\n",
      "epoch=1060, EUBO=-398.659279, ELBO=-883.760548, ESS=1.031, inc MCKL=-186.137744, inc TKL=4.487950, exc MCKL=486.988857, exc TKL=81.112152 (5s)\n"
     ]
    }
   ],
   "source": [
    "EUBOs = []\n",
    "ELBOs = []\n",
    "ESSs = []\n",
    "MCKls_inclusive = []\n",
    "TrueKls_inclusive = []\n",
    "MCKls_exclusive = []\n",
    "TrueKls_exclusive = []\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "time_start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    ESS = 0.0\n",
    "    MCKl_inclusive = 0.0\n",
    "    TrueKl_inclusive = 0.0\n",
    "    MCKl_exclusive = 0.0\n",
    "    TrueKl_exclusive = 0.0\n",
    "    for step in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "        batch_Zs = Zs[batch_indices]\n",
    "        batch_Covs = covs[batch_indices]\n",
    "        batch_Xs, batch_Zs = shuffler(batch_Xs, batch_Zs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess, mckl_inclusive, truekl_inclusive, mckl_exclusive, truekl_exclusive = rws(batch_Xs, batch_Zs, Pi, batch_Covs, N, K, D, NUM_SAMPLES, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        ESS += ess.item()\n",
    "        MCKl_inclusive += mckl_inclusive.item()\n",
    "        MCKl_exclusive += mckl_exclusive.item()\n",
    "        TrueKl_inclusive += truekl_inclusive.item()\n",
    "        TrueKl_exclusive += truekl_exclusive.item()\n",
    "        \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    ESS /= num_batches\n",
    "    MCKl_inclusive /= num_batches\n",
    "    TrueKl_inclusive /= num_batches\n",
    "    MCKl_exclusive /= num_batches\n",
    "    TrueKl_exclusive /= num_batches\n",
    "    \n",
    "    EUBOs.append(EUBO)\n",
    "    ELBOs.append(ELBO)\n",
    "    ESSs.append(ESS)\n",
    "    MCKls_inclusive.append(MCKl_inclusive)\n",
    "    TrueKls_inclusive.append(TrueKl_inclusive)\n",
    "    MCKls_exclusive.append(MCKl_exclusive)\n",
    "    TrueKls_exclusive.append(TrueKl_exclusive)\n",
    "    \n",
    "#     time_end = time.time()\n",
    "    if epoch % 10 == 0:\n",
    "        time_end = time.time()\n",
    "        print('epoch=%d, EUBO=%f, ELBO=%f, ESS=%.3f, inc MCKL=%f, inc TKL=%f, exc MCKL=%f, exc TKL=%f (%ds)' % (epoch, EUBO, ELBO, ESS, MCKl_inclusive, TrueKl_inclusive, MCKl_exclusive, TrueKl_exclusive, time_end - time_start))\n",
    "        time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, num_samples, num_epochs, lr):\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    fig.tight_layout()\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax2.plot(TrueKls_exclusive, '#66b3ff', label='true exclusive KL')\n",
    "    ax2.plot(MCKls_exclusive, '#ff9999', label='est exclusive KL')\n",
    "    ax2.plot(TrueKls_inclusive, '#99ff99', label='true inclusive KL')\n",
    "    ax2.plot(MCKls_inclusive, 'gold', label='est inclusive KL')\n",
    "    \n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax3.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax1.set_title('epoch=%d, batch_size=%d, lr=%.1E, samples=%d' % (num_epochs, BATCH_SIZE, lr, num_samples), fontsize=18)\n",
    "    ax1.set_ylim([-300, -80])\n",
    "    ax1.legend()\n",
    "    ax2.set_ylim([-800, 300])\n",
    "    ax2.legend()\n",
    "    ax3.legend()\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax3.tick_params(labelsize=18)\n",
    "    plt.savefig('gmm_rws_datatodist_lr=%.1E_samples=%d.svg' % (lr, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, NUM_SAMPLES, NUM_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "indices = torch.randperm(num_seqs)\n",
    "batch_indices = indices[0*BATCH_SIZE : (0+1)*BATCH_SIZE]\n",
    "batch_Xs = Xs[batch_indices]\n",
    "batch_Zs = Zs[batch_indices]\n",
    "batch_Covs = covs[batch_indices]\n",
    "batch_Mus = mus_true[batch_indices]\n",
    "batch_Xs, batch_Zs = shuffler(batch_Xs, batch_Zs, N, K, D, BATCH_SIZE)\n",
    "\n",
    "data = batch_Xs.view(BATCH_SIZE*N, -1)\n",
    "mus_mean, mus_std, mus = enc(data, K, D, 10, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(Xs, mus_true1, covs_true1, mus_pred):\n",
    "    Xs = Xs.data.numpy()\n",
    "    mus_true1 = mus_true1.data.numpy()\n",
    "    covs_true1 = covs_true1.data.numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(40, 80))\n",
    "    for i in range(10):\n",
    "        for j in range(5):\n",
    "            batch_covs_expand = torch.zeros((K, D, D))\n",
    "            for k in range(K):\n",
    "                batch_covs_expand[k] = torch.diag(batch_Covs[i*5+j][k])\n",
    "            mus_flat = mus_pred[:, i*5+j].contiguous().view(10*K, D).data.numpy()\n",
    "            ax = fig.add_subplot(10, 5, i*5+j+1)\n",
    "            ax.plot(Xs[i*5+j][:,0], Xs[i*5+j][:,1], 'ro')\n",
    "            ax.plot(mus_flat[:, 0], mus_flat[:, 1], 'ko')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            plot_cov_ellipse(cov=batch_covs_expand[0], pos=mus_true1[i*5+j, 0], nstd=2, ax=ax, alpha=0.5)\n",
    "            plot_cov_ellipse(cov=batch_covs_expand[1], pos=mus_true1[i*5+j, 1], nstd=2, ax=ax, alpha=0.5)\n",
    "            plot_cov_ellipse(cov=batch_covs_expand[2], pos=mus_true1[i*5+j, 2], nstd=2, ax=ax, alpha=0.5)\n",
    "            ax.set_ylim([-10, 10])\n",
    "            ax.set_xlim([-10, 10])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions_only_learn_mus.svg')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(batch_Xs, batch_Mus, batch_Covs, mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), 'models/enc-OneShotEncoder-only-learn-mus-samples=10-iters=1e6-lr=1e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, NUM_SAMPLES, NUM_EPOCHS, LEARNING_RATE):\n",
    "    fout = open('OneShotEncoder_only_learn_mus_samples=%d_epochs=%d_lr=%1e-4.txt', 'w+')\n",
    "    fout.write('EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive\\n')\n",
    "    for i in range(len(EUBOs)):\n",
    "        fout.write(str(EUBOs[i]) + ', ' + str(ELBOs[i]) + ', ' + str(ESSs[i]) + ', ' + str(MCKls_exclusive[i]) + ', ' + str(TrueKls_exclusive[i]) + ', ' + str(MCKls_inclusive[i]) + ', ' + str(TrueKls_inclusive[i]) + '\\n')\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(EUBOs, ELBOs, ESSs, MCKls_exclusive, TrueKls_exclusive, MCKls_inclusive, TrueKls_inclusive, NUM_SAMPLES, NUM_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open('results/encode_stats_sigmas_only_learn_mus_samples=%d_epochs=%d_lr=%1e-4.txt')\n",
    "EUBOs0 = []\n",
    "ELBOs0 = []\n",
    "ESSs0 = []\n",
    "MCKl_exclusive0 = []\n",
    "MCKl_inclusive0 = []\n",
    "TrueKl_exclusive0 = []\n",
    "TrueKl_inclusive0 = []\n",
    "\n",
    "for line in fin.readlines():\n",
    "    line = line.strip().split(', ')\n",
    "    if line[0] != 'EUBOs':\n",
    "        EUBOs0.append(float(line[0]))\n",
    "        ELBOs0.append(float(line[1]))\n",
    "        ESSs0.append(float(line[2]))\n",
    "        MCKl_exclusive0.append(line[3])\n",
    "        TrueKl_exclusive0.append(line[4])\n",
    "        MCKl_inclusive0.append(line[5])\n",
    "        TrueKl_inclusive0.append(line[6])\n",
    "fin.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 30))\n",
    "fig.tight_layout()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax3 = fig.add_subplot(2, 1, 2)\n",
    "ax1.plot(EUBOs, 'r', label='EUBOs -- encode sigmas')\n",
    "ax1.plot(ELBOs, 'b', label='ELBOs -- encode sigmas')\n",
    "ax1.plot(EUBOs0, 'g', label='EUBOs ')\n",
    "ax1.plot(ELBOs0, 'k', label='ELBOs')\n",
    "\n",
    "\n",
    "ax1.tick_params(labelsize=18)\n",
    "ax3.plot(np.array(ESSs) / 10., 'm', label='ESS -- encode sigmas')\n",
    "ax3.plot(np.array(ESSs0) / 10., 'k', label='ESS')\n",
    "\n",
    "ax1.set_title('expanded latent')\n",
    "ax1.set_ylim([-250, -80])\n",
    "ax1.legend()\n",
    "ax3.legend()\n",
    "ax3.tick_params(labelsize=18)\n",
    "plt.savefig('comparision_only_learn_mus.svg' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
