{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 1\n",
    "NUM_HIDDEN = 64\n",
    "NUM_STATS = K+D*K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS = D + K\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-4\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset/sequences.npy')).float()\n",
    "Zs = torch.from_numpy(np.load('gmm_dataset/states.npy')).float()\n",
    "# mus_true = torch.from_numpy(np.load('gmm_dataset/means.npy')).float()\n",
    "# covs = torch.from_numpy(np.load('gmm_dataset2/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset/init.npy')).float()\n",
    "num_seqs = Zs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatsGMM(Xs, Zs, K, D):\n",
    "    \"\"\"\n",
    "    Xs is B * N * D\n",
    "    Zs is B * N * K\n",
    "    stat1 corresponds I[z_n=1], ..., I[z_n=K]\n",
    "    stat2 corresponds I[z_n=1]x_n, ..., I[z_n=K]x_n\n",
    "    stat3 corresponds I[z_n=1]x_n**2, ..., I[z_n=K]x_n**2\n",
    "    return B * (K+D*K+D*K)\n",
    "    \"\"\"\n",
    "    stat1 = Zs.sum(1)\n",
    "    stat2 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    stat3 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), torch.mul(Xs, Xs).unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    return stat1, stat2, stat3, torch.cat((stat1, stat2.view(-1, D*K), stat3.view(-1, D*K)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_stats),\n",
    "            nn.ReLU())\n",
    "#         self.enc_hidden = nn.Sequential(\n",
    "#             nn.Linear(num_stats, num_hidden),\n",
    "#             nn.ReLU())\n",
    "#         self.mus_mean = nn.Sequential(\n",
    "#             nn.Linear(num_hidden, num_latents))\n",
    "#         self.mus_log_std = nn.Sequential(\n",
    "#             nn.Linear(num_hidden, num_latents))\n",
    "#         self.sigmas_log_alpha = nn.Sequential(\n",
    "#             nn.Linear(num_hidden, num_latents))\n",
    "#         self.sigmas_log_beta = nn.Sequential(\n",
    "#             nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1) ** 2\n",
    "#         hidden = self.enc_hidden(stats)\n",
    "#         mean = self.mus_mean(hidden).view(-1, K, D)\n",
    "#         std = torch.exp(self.mus_log_std(hidden).view(-1, K, D))\n",
    "#         alpha = torch.exp(self.sigmas_log_alpha(hidden).view(-1, K, D))\n",
    "#         beta = torch.exp(self.sigmas_log_beta(hidden).view(-1, K, D))\n",
    "        \n",
    "#         mus = Normal(mean, std).sample((num_samples, )) ## S * B * K * D\n",
    "#         sigmas = Gamma(alpha, beta).sample((num_samples, )) ## S * B * K * D\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha = 4.0\n",
    "prior_beta = 4.0\n",
    "prior_mus = torch.zeros((K, D))\n",
    "prior_nu = 5.0\n",
    "\n",
    "def log_joints_gmm(Z, Pi, means, stds, precisions, Xs, N, D, K, num_samples, batch_size):\n",
    "    log_probs = torch.zeros((num_samples, batch_size))\n",
    "    ## priors on mus and sigmas, S * B\n",
    "    log_probs = log_probs + Normal(torch.zeros((num_samples, batch_size, K, D)), torch.sqrt(prior_nu / precisions)).log_prob(means).sum(-1).sum(-1)\n",
    "    log_probs = log_probs + Gamma(torch.ones((batch_size, K, D)) * prior_alpha, torch.ones((batch_size, K, D)) * prior_beta).log_prob(precisions).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "#     log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    log_probs = log_probs + Normal(means[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D), stds[:, labels[:, 0], labels[:, -1], :].view(-1, batch_size, N, D)).log_prob(Xs).sum(-1).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "def conjugate_posterior(Xs, stats, N, K, D):\n",
    "    stat1 = stats[:, :K] + 1e-3\n",
    "    stat2 = stats[:, K:K+K*D]\n",
    "    stat3 = stats[:, K+K*D:]\n",
    "    x_mean = stat2.view(-1, K, D) / stat1.unsqueeze(-1).repeat(1, 1, D)\n",
    "    ## every parameter is B * K * D\n",
    "    post_alpha = (prior_alpha + stat1 / 2.).unsqueeze(-1).repeat(1, 1, D)\n",
    "    post_nu = (prior_nu + stat1).unsqueeze(-1).repeat(1, 1, D)\n",
    "    post_mus = (prior_nu * prior_mus + stat2.view(-1, K, D)) / (prior_nu + stat1.unsqueeze(-1).repeat(1, 1, D))\n",
    "    post_beta = prior_beta + (1. / 2) * ((Xs - x_mean) ** 2) + (1. / 2) * (prior_nu * stat1 / (prior_nu + stat1)).unsqueeze(-1).repeat(1, 1, D) * ((prior_mus ** 2) + (x_mean ** 2) - 2 * prior_mus * x_mean)\n",
    "\n",
    "    return post_alpha, post_beta, post_mus, post_nu\n",
    "\n",
    "def sample_normal_gamma(alpha, beta, mus, nu, num_samples):\n",
    "    precisions = Gamma(alpha, beta).sample((num_samples, )) + 0.01\n",
    "    \n",
    "    stds = torch.sqrt((1. / precisions) * nu)\n",
    "    means = Normal(mus.unsqueeze(0).repeat(num_samples, 1, 1, 1), stds).sample()\n",
    "    log_q = Normal(mus.unsqueeze(0).repeat(num_samples, 1, 1, 1), stds).log_prob(means).sum(-1).sum(-1) + Gamma(alpha, beta).log_prob(precisions).sum(-1).sum(-1)## S * B\n",
    "    print(Gamma(alpha, beta).log_prob(precisions).sum(-1).sum(-1))\n",
    "    return means, stds, log_q, precisions\n",
    "\n",
    "def rws(Xs, Zs, Pi, N, K, D, num_samples, batch_size):\n",
    "#     stat1, stat2, stats = StatsGMM(Xs, Zs, K, D)\n",
    "    data = torch.cat((Xs, Zs), dim=-1).view(batch_size*N, -1)\n",
    "    stats = enc(data, K, D, num_samples, batch_size)\n",
    "    post_alpha, post_beta, post_mus, post_nu = conjugate_posterior(stats, N, K, D)\n",
    "    means, stds, log_q, precisions = sample_normal_gamma(post_alpha, post_beta, post_mus, post_nu, num_samples)\n",
    "    \n",
    "    log_p = log_joints_gmm(Zs, Pi, means, stds, precisions, Xs, N, D, K, num_samples, batch_size)\n",
    "#     print(log_p)\n",
    "    log_weights = log_p - log_q\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, dim=0)).detach()\n",
    "    eubo = torch.mul(weights, log_weights).sum(0).mean()\n",
    "    elbo = log_weights.mean(0).mean()\n",
    "    ess = (1. / (weights ** 2).sum(0)).mean()\n",
    "#     posterior_mean, posterior_covs = conjugate_posterior(stat1, stat2, covs, K, D, batch_size)\n",
    "#     MCKl, TrueKl = kls_gaussians(mus, mus_mean, mus_std, posterior_mean, posterior_covs, K, D)\n",
    "    return eubo, elbo, ess\n",
    "\n",
    "def shuffler(batch_Xs, batch_Zs, N, K, D, batch_size):\n",
    "    indices = torch.cat([torch.randperm(N).unsqueeze(0) for b in range(batch_size)])\n",
    "    indices_Xs = indices.unsqueeze(-1).repeat(1, 1, D)\n",
    "    indices_Zs = indices.unsqueeze(-1).repeat(1, 1, K)\n",
    "    return torch.gather(batch_Xs, 1, indices_Xs), torch.gather(batch_Zs, 1, indices_Zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters()),lr=LEARNING_RATE)    \n",
    "    return enc, optimizer\n",
    "enc, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan, -3.1222,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan, -2.6373,\n",
      "             nan,     nan,     nan,     nan]], grad_fn=<SumBackward2>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eubo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2424c06f6600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#         print(post_beta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         eubo, elbo, ess = rws(batch_Xs, batch_Zs, Pi, N, K, D, NUM_SAMPLES, BATCH_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mEUBO\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eubo' is not defined"
     ]
    }
   ],
   "source": [
    "EUBOs = []\n",
    "ELBOs = []\n",
    "ESSs = []\n",
    "# MCKls = []\n",
    "# TrueKls = []\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(1):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    time_start = time.time()\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    ESS = 0.0\n",
    "#     MCKl = 0.0\n",
    "#     TrueKl = 0.0\n",
    "    for step in range(1):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "        batch_Zs = Zs[batch_indices]\n",
    "        batch_Xs, batch_Zs = shuffler(batch_Xs, batch_Zs, N, K, D, BATCH_SIZE)\n",
    "        data = torch.cat((batch_Xs, batch_Zs), dim=-1).view(BATCH_SIZE*N, -1)\n",
    "        stats = enc(data, K, D, NUM_SAMPLES, BATCH_SIZE)\n",
    "        post_alpha, post_beta, post_mus, post_nu = conjugate_posterior(stats, N, K, D)\n",
    "        means, stds, log_q, precisions = sample_normal_gamma(post_alpha, post_beta, post_mus, post_nu, NUM_SAMPLES)\n",
    "#         log_p = log_joints_gmm(batch_Zs, Pi, means, stds, precisions, batch_Xs, N, D, K, NUM_SAMPLES, BATCH_SIZE)\n",
    "#         print(post_beta)\n",
    "#         eubo, elbo, ess = rws(batch_Xs, batch_Zs, Pi, N, K, D, NUM_SAMPLES, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        ESS += ess.item()\n",
    "#         MCKl += mckl.item()\n",
    "#         TrueKl += truekl.item()\n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    ESS /= num_batches\n",
    "#     MCKl /= num_batches\n",
    "#     TrueKl /= num_batches\n",
    "    \n",
    "    EUBOs.append(EUBO)\n",
    "    ELBOs.append(ELBO)\n",
    "    ESSs.append(ESS)\n",
    "#     MCKls.append(MCKl)\n",
    "#     TrueKls.append(TrueKl)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print('epoch=%d, EUBO=%f, ELBO=%f, ESS=%.3f (%ds)' % (epoch, EUBO, ELBO, ESS, time_end - time_start))\n",
    "#     print('epoch=%d, EUBO=%f, ELBO=%f, ESS=%.3f, MCKL=%f, TKL=%f (%ds)' % (epoch, EUBO, ELBO, ESS, MCKl, TrueKl, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma(post_alpha, post_beta).log_prob(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.6100e+02,  1.3365e+02],\n",
       "         [-3.1387e+02, -1.7009e+01],\n",
       "         [ 2.2881e+00, -8.2317e-02]],\n",
       "\n",
       "        [[-2.4348e+02,  1.1507e+02],\n",
       "         [-6.9891e+01, -9.4755e+00],\n",
       "         [ 1.1921e+01, -4.9813e-02]],\n",
       "\n",
       "        [[-4.8666e+02,  7.4931e+01],\n",
       "         [-4.1334e+02, -1.4952e-02],\n",
       "         [ 2.9633e-01, -3.4268e-04]],\n",
       "\n",
       "        [[-3.9734e+05, -3.0691e+05],\n",
       "         [-1.1885e+00, -2.5159e+02],\n",
       "         [ 9.8242e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-6.5936e+03,  3.3732e+02],\n",
       "         [-9.3699e+01, -3.2717e+02],\n",
       "         [ 9.7354e+01, -1.7525e-05]],\n",
       "\n",
       "        [[-9.4977e+03,  1.3549e+02],\n",
       "         [-2.5436e+01, -5.4638e+01],\n",
       "         [ 3.5837e+00, -2.3607e-07]],\n",
       "\n",
       "        [[-3.6718e+02,  2.6077e+02],\n",
       "         [-5.8269e+02, -1.2583e+01],\n",
       "         [ 0.0000e+00, -2.2556e-06]],\n",
       "\n",
       "        [[-1.2631e+05, -1.3507e+04],\n",
       "         [-1.9851e-03, -1.2264e+01],\n",
       "         [ 2.2666e+01, -5.3101e-06]],\n",
       "\n",
       "        [[-3.7911e+03,  1.8345e+02],\n",
       "         [-1.0023e+00, -3.5344e-01],\n",
       "         [ 1.2164e-01,  0.0000e+00]],\n",
       "\n",
       "        [[-4.5539e+02,  9.2729e+01],\n",
       "         [-1.0663e+02, -2.7804e+01],\n",
       "         [ 6.9451e-01, -1.3389e-02]],\n",
       "\n",
       "        [[-2.7110e+06,  1.7948e+02],\n",
       "         [-5.9412e-02, -2.1266e+01],\n",
       "         [ 1.8640e+01, -4.6349e-05]],\n",
       "\n",
       "        [[-7.9276e+05, -1.1692e+05],\n",
       "         [-4.2891e-05, -1.6931e+02],\n",
       "         [ 1.1150e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-4.4626e+02,  1.4880e+02],\n",
       "         [-5.4241e+01, -2.6421e+01],\n",
       "         [ 2.5002e-01, -2.0626e-04]],\n",
       "\n",
       "        [[-3.7128e+02,  1.3505e+02],\n",
       "         [-1.7297e+01, -2.3237e+02],\n",
       "         [ 1.2622e+02, -1.3457e-06]],\n",
       "\n",
       "        [[-6.1222e+03,  2.5276e+02],\n",
       "         [-3.6596e+02, -2.8653e+02],\n",
       "         [ 1.5149e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-3.2151e+03, -3.0161e+06],\n",
       "         [-2.0071e-04, -2.2016e+02],\n",
       "         [ 1.7532e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-1.3304e+03,  3.2848e+02],\n",
       "         [-1.5822e+01, -3.7316e+00],\n",
       "         [ 1.9112e-02, -3.6890e-07]],\n",
       "\n",
       "        [[-1.0187e+03,  3.0232e+02],\n",
       "         [-1.0088e+03, -4.4374e+01],\n",
       "         [ 2.7650e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-5.0582e+02,  8.8164e+01],\n",
       "         [-6.0797e+01, -3.3451e-01],\n",
       "         [ 2.7665e+00, -4.5881e-02]],\n",
       "\n",
       "        [[-2.5288e+02,  5.0302e+01],\n",
       "         [-1.9154e+02, -1.2015e+01],\n",
       "         [ 2.6775e+00, -5.5033e-06]],\n",
       "\n",
       "        [[-1.4661e+03,  8.9702e+01],\n",
       "         [-8.6650e+01, -5.8560e+00],\n",
       "         [ 3.6434e+00, -2.3226e-06]],\n",
       "\n",
       "        [[-8.8929e+01,  1.1177e+02],\n",
       "         [-2.9670e+02, -5.5709e-01],\n",
       "         [ 1.5061e-03, -1.6394e-04]],\n",
       "\n",
       "        [[-2.7767e+02, -4.5555e+01],\n",
       "         [-1.4309e-02, -7.7059e+01],\n",
       "         [ 7.9210e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-6.4896e+05, -2.6931e+03],\n",
       "         [-6.1560e-01, -6.2096e+01],\n",
       "         [ 1.8589e+01,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.9460e+00,  1.3043e+02],\n",
       "         [-1.3955e+02,  1.9741e-01],\n",
       "         [ 5.2091e-01, -2.0771e-02]],\n",
       "\n",
       "        [[ 3.5715e+01,  5.8870e+02],\n",
       "         [-3.4524e+02,  7.0653e+00],\n",
       "         [-2.0760e+00, -1.8691e+02]],\n",
       "\n",
       "        [[-2.8226e+03,  9.2897e+01],\n",
       "         [-3.4037e+00, -1.6675e+02],\n",
       "         [ 5.3098e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-4.8765e+04,  9.4514e+01],\n",
       "         [-2.9960e+04, -1.3646e-01],\n",
       "         [ 3.7510e-02, -2.5864e-07]],\n",
       "\n",
       "        [[-1.2243e+03, -1.9008e+02],\n",
       "         [-5.0236e+00, -9.8724e+01],\n",
       "         [ 4.2254e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-1.9793e+05,  8.4963e+01],\n",
       "         [-5.0936e+00, -3.9172e+01],\n",
       "         [ 3.9957e+00, -8.2937e-05]],\n",
       "\n",
       "        [[-8.3085e+03,  1.7885e+02],\n",
       "         [-2.6726e-01, -8.3819e-05],\n",
       "         [-5.1754e-05, -1.5145e-01]],\n",
       "\n",
       "        [[-1.3744e+02,  3.1339e+01],\n",
       "         [-1.0991e+01, -2.2305e+01],\n",
       "         [ 3.2500e+01, -5.9918e-04]],\n",
       "\n",
       "        [[-9.6873e+02,  1.9251e+02],\n",
       "         [-8.5782e+02, -3.7431e+01],\n",
       "         [ 7.5865e-01,  0.0000e+00]],\n",
       "\n",
       "        [[-1.7000e+03,  2.0578e+02],\n",
       "         [-3.3691e+01, -4.0136e+01],\n",
       "         [ 2.1288e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-4.4431e+02,  1.2170e+02],\n",
       "         [-9.6309e+01, -9.9672e+00],\n",
       "         [ 1.4587e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-4.8500e+03, -2.0278e+02],\n",
       "         [-1.0843e-01, -1.5654e+02],\n",
       "         [ 6.7545e+01, -1.0053e-07]],\n",
       "\n",
       "        [[-4.7768e+02,  9.0306e+01],\n",
       "         [-2.3601e+01, -6.5956e+01],\n",
       "         [ 1.3224e+01, -1.0138e-04]],\n",
       "\n",
       "        [[-3.1680e+04,  3.6325e+02],\n",
       "         [-5.0903e+02, -1.6692e+02],\n",
       "         [ 2.7668e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-2.3754e+03,  1.5508e+02],\n",
       "         [-1.7954e+01, -4.1916e+01],\n",
       "         [ 1.3746e+01, -9.1001e-05]],\n",
       "\n",
       "        [[-1.0015e+03,  3.7375e+02],\n",
       "         [-1.6127e+03, -4.9828e+01],\n",
       "         [ 7.8370e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.4750e+05, -2.1616e+07],\n",
       "         [ 0.0000e+00, -6.7468e+02],\n",
       "         [ 5.2591e+02, -1.1991e-01]],\n",
       "\n",
       "        [[-6.2870e+03,  1.4160e+02],\n",
       "         [-5.6506e+01, -1.2468e+02],\n",
       "         [ 3.6211e+01, -4.2982e-03]],\n",
       "\n",
       "        [[-3.9579e+03,  8.5424e+01],\n",
       "         [-1.5603e+01, -3.8445e+01],\n",
       "         [ 5.6332e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.1617e+05, -1.9485e+03],\n",
       "         [-1.5647e-01, -7.3392e-01],\n",
       "         [ 2.0598e+00, -1.1169e-02]],\n",
       "\n",
       "        [[-2.9226e+04, -4.2588e+02],\n",
       "         [-2.3927e-01, -8.9951e+01],\n",
       "         [ 6.4777e+01, -2.5567e-02]],\n",
       "\n",
       "        [[-1.1252e+04, -3.3143e+05],\n",
       "         [-1.9064e-04, -1.1605e+01],\n",
       "         [ 4.6111e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-2.7851e+02,  1.2064e+02],\n",
       "         [-8.0300e+01, -5.9329e-01],\n",
       "         [ 5.0116e-02, -9.9511e-07]],\n",
       "\n",
       "        [[-1.5060e+04, -7.8757e+05],\n",
       "         [-5.9634e-04, -3.8114e+02],\n",
       "         [ 2.6697e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-4.2696e+05, -2.9606e+04],\n",
       "         [-6.3588e-06, -7.1931e+01],\n",
       "         [ 5.1790e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-2.9098e+02,  2.9671e+02],\n",
       "         [-2.0809e+01,  3.0873e-03],\n",
       "         [-8.9308e-03, -2.1011e+00]],\n",
       "\n",
       "        [[-1.8724e+03,  7.4668e+02],\n",
       "         [-7.6622e+00, -3.1224e+00],\n",
       "         [ 1.8404e+00, -1.1321e+02]],\n",
       "\n",
       "        [[-7.1893e+05, -1.5883e+02],\n",
       "         [-9.1428e+00, -1.6968e+01],\n",
       "         [ 8.2754e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.2670e+03,  1.5880e+02],\n",
       "         [-7.8083e+00, -8.8284e+02],\n",
       "         [ 3.6336e+02, -1.0905e-01]],\n",
       "\n",
       "        [[-2.4315e+03,  1.1744e+02],\n",
       "         [-8.5037e+00, -1.5372e+03],\n",
       "         [ 5.5210e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-2.5005e+02,  8.4969e+01],\n",
       "         [-1.6917e+02, -1.8065e+01],\n",
       "         [ 5.3676e+00, -3.1360e-10]],\n",
       "\n",
       "        [[-6.7186e+03, -1.1904e+04],\n",
       "         [-3.4268e+00, -5.3429e+02],\n",
       "         [ 2.6926e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-1.9616e+03,  4.2208e+02],\n",
       "         [-7.5431e+02, -8.2924e+01],\n",
       "         [ 1.9547e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-7.3933e+03,  1.4508e+02],\n",
       "         [-4.4300e+00, -1.4806e+02],\n",
       "         [ 5.4973e+01, -1.9091e-04]],\n",
       "\n",
       "        [[-2.2399e+04,  7.3012e+01],\n",
       "         [-3.0587e-02, -5.1503e+00],\n",
       "         [ 9.7824e+00, -5.4151e-06]],\n",
       "\n",
       "        [[-2.4364e+02,  8.0506e+01],\n",
       "         [-6.1476e+01, -8.1292e-02],\n",
       "         [ 3.1345e+00, -7.7206e-05]],\n",
       "\n",
       "        [[-1.2090e+04, -2.6366e+02],\n",
       "         [-4.2634e+00, -3.8486e+02],\n",
       "         [ 1.0051e+02, -8.9875e-07]],\n",
       "\n",
       "        [[-3.8793e+02,  1.1554e+02],\n",
       "         [-1.0102e+02, -3.0950e+01],\n",
       "         [ 9.1413e-02, -3.7288e-04]],\n",
       "\n",
       "        [[-1.7861e+02, -5.9202e+02],\n",
       "         [-3.9772e+00, -2.8680e+01],\n",
       "         [ 4.6384e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-7.1592e+04, -8.7444e+03],\n",
       "         [-2.7032e-02, -3.1277e+01],\n",
       "         [ 1.9921e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-5.9699e+02,  9.0861e+01],\n",
       "         [-4.5083e+01, -3.5833e+01],\n",
       "         [ 2.7532e+01, -1.1117e-05]],\n",
       "\n",
       "        [[-3.6597e+05,  3.0758e+02],\n",
       "         [-4.5116e+01, -7.9302e+02],\n",
       "         [ 1.7436e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-2.9397e+02,  9.2780e+01],\n",
       "         [-1.4384e+01, -2.6395e-01],\n",
       "         [ 7.9671e-01, -4.6131e-03]],\n",
       "\n",
       "        [[-6.5343e+02,  1.2116e+02],\n",
       "         [-1.1131e+02, -7.1423e+01],\n",
       "         [ 2.2027e+01, -3.4339e-04]],\n",
       "\n",
       "        [[-4.7177e+03, -8.0063e+02],\n",
       "         [-1.8966e-01, -3.9476e+01],\n",
       "         [ 4.1745e+01, -3.0178e-03]],\n",
       "\n",
       "        [[-7.2134e+04,  7.5291e+01],\n",
       "         [-3.9049e-01, -2.4379e+02],\n",
       "         [ 1.3336e+02, -7.6030e-07]],\n",
       "\n",
       "        [[-4.5736e+02,  3.1373e+01],\n",
       "         [-2.9276e-01, -6.4006e-02],\n",
       "         [ 5.1704e+00, -1.1178e-04]],\n",
       "\n",
       "        [[-2.1750e+02,  4.8203e+01],\n",
       "         [-9.3142e+01, -5.7700e+00],\n",
       "         [ 7.6023e+00, -2.4656e-07]],\n",
       "\n",
       "        [[-2.0541e+02,  7.7358e+01],\n",
       "         [-4.9029e+01, -5.3994e-01],\n",
       "         [ 1.0090e-01, -1.3723e-03]],\n",
       "\n",
       "        [[-1.6362e+03,  2.1664e+02],\n",
       "         [-5.9001e+02, -6.4153e+01],\n",
       "         [ 3.1449e+00, -1.1276e-06]],\n",
       "\n",
       "        [[-6.5972e+03, -1.7158e+01],\n",
       "         [-8.3605e-01, -3.6042e+01],\n",
       "         [ 3.4506e+01, -2.5547e-06]],\n",
       "\n",
       "        [[-2.3330e+02,  1.0663e+02],\n",
       "         [-1.9978e+02, -3.0850e-02],\n",
       "         [ 4.1440e-01, -1.1600e-03]],\n",
       "\n",
       "        [[-1.0767e+03,  7.4532e+01],\n",
       "         [-1.8363e+02, -9.8359e+00],\n",
       "         [ 8.7285e-01,  0.0000e+00]],\n",
       "\n",
       "        [[-4.1652e+01,  6.5930e+01],\n",
       "         [-1.7894e+02, -2.5708e+01],\n",
       "         [ 4.1000e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-1.5536e+03,  1.7697e+02],\n",
       "         [-3.7456e+02, -6.8002e+01],\n",
       "         [ 4.2062e+00, -6.8342e-10]],\n",
       "\n",
       "        [[-5.8426e+02,  5.1725e+01],\n",
       "         [-5.4352e+01, -1.6957e+01],\n",
       "         [ 2.3283e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-5.5091e+01,  1.1839e+02],\n",
       "         [-3.0296e+02, -9.1095e-03],\n",
       "         [ 9.1661e-04, -1.0922e-03]],\n",
       "\n",
       "        [[-4.9172e+02,  9.9339e+01],\n",
       "         [-1.0645e+02, -3.0951e+00],\n",
       "         [ 7.8806e-01,  0.0000e+00]],\n",
       "\n",
       "        [[-3.6247e+02,  2.8600e+02],\n",
       "         [-3.3892e+02, -2.0567e+01],\n",
       "         [ 5.2694e-04, -2.8563e-04]],\n",
       "\n",
       "        [[-4.6906e+05, -4.4168e+05],\n",
       "         [ 0.0000e+00, -6.6235e+02],\n",
       "         [ 2.5593e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-8.8437e+05, -2.0219e+03],\n",
       "         [-6.4354e-01, -2.1875e+02],\n",
       "         [ 1.4172e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-9.2417e+05,  3.2313e+02],\n",
       "         [-2.1230e+00, -2.8802e+00],\n",
       "         [ 8.3929e-02, -7.4231e+00]],\n",
       "\n",
       "        [[-1.2091e+03,  1.3048e+02],\n",
       "         [-1.2816e+02, -5.8413e+01],\n",
       "         [ 1.0695e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-5.3097e+02, -1.2009e+03],\n",
       "         [-7.5157e-02, -8.1115e+01],\n",
       "         [ 4.2891e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-9.8061e+04,  9.8345e+01],\n",
       "         [-1.4929e+00, -1.4170e+01],\n",
       "         [ 1.2432e+01,  0.0000e+00]],\n",
       "\n",
       "        [[-2.1737e+03,  1.8614e+02],\n",
       "         [-4.1093e+02, -3.1250e+00],\n",
       "         [ 6.5364e-01, -2.6654e-01]],\n",
       "\n",
       "        [[-1.6230e+04,  3.9911e+02],\n",
       "         [-4.8951e+02, -5.9484e+02],\n",
       "         [ 1.4155e+02, -3.3140e-09]],\n",
       "\n",
       "        [[-1.8060e+04,  1.6282e+02],\n",
       "         [-7.5686e+00, -3.3340e+01],\n",
       "         [ 2.9306e+00, -1.0240e+00]],\n",
       "\n",
       "        [[-6.2614e+03,  1.0523e+02],\n",
       "         [-2.8302e-01, -5.1997e-05],\n",
       "         [ 6.1938e-01, -7.2457e-03]],\n",
       "\n",
       "        [[-1.7552e+02,  5.8558e+01],\n",
       "         [-1.3771e+02, -2.6643e+01],\n",
       "         [ 4.5901e+01, -1.0643e-07]],\n",
       "\n",
       "        [[-5.6828e+02,  1.8281e+02],\n",
       "         [-1.4128e+01, -2.6345e+00],\n",
       "         [ 3.1354e-04, -5.9008e-01]],\n",
       "\n",
       "        [[-8.1789e+03, -6.8750e+02],\n",
       "         [-4.7232e-06, -7.0408e+00],\n",
       "         [ 6.0174e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.2455e+02,  2.6291e+02],\n",
       "         [-6.7420e+02, -4.4687e+01],\n",
       "         [ 1.1411e+01, -3.1040e-07]],\n",
       "\n",
       "        [[-1.2003e+03,  2.1479e+02],\n",
       "         [-2.5362e+02, -2.7298e+01],\n",
       "         [ 8.4539e-01, -3.3423e+00]],\n",
       "\n",
       "        [[-5.1331e+03, -5.8638e+02],\n",
       "         [-7.3784e-02, -4.8565e+02],\n",
       "         [ 2.3875e+02,  0.0000e+00]],\n",
       "\n",
       "        [[-1.4488e+03,  1.7639e+02],\n",
       "         [-1.9759e+01, -1.8124e+01],\n",
       "         [ 3.2024e-01, -8.5077e-01]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat1 = stats[:, :K] + 1e-3\n",
    "stat2 = stats[:, K:K+K*D]\n",
    "stat3 = stats[:, K+K*D:]\n",
    "(1. / 2) * (stat3.view(-1, K, D) - ((stat2.view(-1, K, D) ** 2) / stat1.unsqueeze(-1).repeat(1, 1, D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESS, num_samples, num_epochs, lr):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "#     fig.tight_layout()\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax3 = fig.add_subplot(2, 1, 2)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax3.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax1.set_title('epoch=%d, lr=%.1E, samples=%d' % (num_epochs, lr, num_samples), fontsize=18)\n",
    "    ax1.set_ylim([-150, -80])\n",
    "    ax1.legend()\n",
    "    ax3.legend()\n",
    "    ax3.tick_params(labelsize=18)\n",
    "#     plt.savefig('gmm_rws_datatodist_lr=%.1E_samples=%d.svg' % (lr, orch.ones((K, D)) * 0.3 num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_results(EUBOs, ELBOs, ESS, NUM_SAMPLES, NUM_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
