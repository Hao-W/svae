{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import logsumexp\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "from utils_v2 import *\n",
    "from plots import *\n",
    "from objectives_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training parameters\n",
    "STEPS = 2000\n",
    "DATA_DIM= \n",
    "NUM_SAMPLES = 16\n",
    "LEARNING_RATE = 5*1e-2\n",
    "JOINT_SAMPLE = False\n",
    "## model parameters\n",
    "# p_mu = torch.tensor([0.0])\n",
    "# p_sigma = torch.tensor([1.0])\n",
    "# q_mu = torch.tensor([8.0], requires_grad=True)\n",
    "# q_sigma = torch.tensor([2.0], requires_grad=True) \n",
    "## initialize optimizer\n",
    "# optimizer = torch.optim.Adam([q_mu, q_sigma], lr=LEARNING_RATE)\n",
    "## estimators\n",
    "ests = ['mc', 'iwae', 'iwae-dreg', 'rws', 'rws-dreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLOSSs = dict()\n",
    "dESSs = dict()\n",
    "dKLs = dict()\n",
    "\n",
    "init_q_mu = torch.randn(DATA_DIM)\n",
    "print('======= start training ========\\n')\n",
    "\n",
    "for est in ests:\n",
    "    ## model parameters\n",
    "    p_mu = torch.zeros(DATA_DIM)\n",
    "    p_sigma = torch.ones(DATA_DIM)\n",
    "    q_mu = init_q_mu * 8.0\n",
    "    q_mu.requires_grad = True\n",
    "    q_sigma = torch.ones(DATA_DIM) * 2.0\n",
    "    q_sigma.requires_grad = True\n",
    "    ## initialize optimizer\n",
    "    optimizer = torch.optim.Adam([q_mu, q_sigma], lr=LEARNING_RATE)\n",
    "    time_start = time.time()\n",
    "    if est == 'mc':\n",
    "        LOSSs, ESSs, KLs = train(mc, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, DATA_DIM, optimizer, filename=est, joint_sample=JOINT_SAMPLE)        \n",
    "    elif est == 'iwae':\n",
    "        LOSSs, ESSs, KLs = train(iwae, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, DATA_DIM, optimizer, filename=est, joint_sample=JOINT_SAMPLE)        \n",
    "    elif est == 'iwae-dreg':\n",
    "        LOSSs, ESSs, KLs = train(driwae, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, DATA_DIM, optimizer, filename=est, joint_sample=JOINT_SAMPLE)        \n",
    "    elif est == 'rws':\n",
    "        LOSSs, ESSs, KLs = train(rws, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, DATA_DIM, optimizer, filename=est, joint_sample=JOINT_SAMPLE)      \n",
    "    elif est == 'rws-dreg':\n",
    "        LOSSs, ESSs, KLs = train(drrws, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, DATA_DIM, optimizer, filename=est, joint_sample=JOINT_SAMPLE)           \n",
    "\n",
    "    dLOSSs[est] = np.array(LOSSs)\n",
    "    dESSs[est] = ESSs\n",
    "    dKLs[est] = KLs\n",
    "    time_end = time.time()\n",
    "    print('%s training completed.. (%ds)' % (est, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_simplified(dLOSSs, dESSs, dKLs, data_dim, num_samples, lr, ests, fs=15):\n",
    "    fig = plt.figure(figsize=(fs,fs))\n",
    "    colors = {'mc':'green', 'iwae': 'red', 'iwae-dreg': 'blue', \n",
    "              'rws': 'deepskyblue', 'rws-dreg': 'firebrick', 'stl': 'black'}\n",
    "    fig = plt.figure(figsize=(fs,fs))\n",
    "    ax = fig.subplots(3, 1, gridspec_kw={'wspace':0.1, 'hspace':0.1})\n",
    "    \n",
    "    for i, est in enumerate(ests):\n",
    "        LOSSs = dLOSSs[est]\n",
    "        ESSs = dESSs[est]\n",
    "        KLs = dKLs[est]\n",
    "        if est == 'mc' or est == 'iwae' or est == 'iwae-dreg':\n",
    "            ax[0].plot(- LOSSs, c=colors[est], label= 'ELBO' + est)\n",
    "            ax[1].plot(KLs, c=colors[est], label=est)\n",
    "            ax[2].plot(np.array(ESSs), c=colors[est], label=est)                 \n",
    "        elif est =='rws' or est == 'rws-dreg':\n",
    "            ax[0].plot(LOSSs, c=colors[est], label= 'EUBO' + est)\n",
    "            ax[1].plot(KLs, c=colors[est], label=est)\n",
    "            ax[2].plot(np.array(ESSs), c=colors[est], label=est)    \n",
    "    ax[0].set_title('Objectives')\n",
    "    ax[1].set_title('exclusive KL')\n",
    "    ax[2].set_title('ESS')\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax[i].legend(fontsize=12)\n",
    "        ax[i].tick_params(labelsize=12)\n",
    "        if i == 1:\n",
    "            ax[i].set_yscale('log')\n",
    "    plt.savefig('results/%ddim-%dsamples-%.4flr.svg' % (data_dim, num_samples, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_simplified(dLOSSs, dESSs, dKLs, DATA_DIM, NUM_SAMPLES, LEARNING_RATE, ests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
