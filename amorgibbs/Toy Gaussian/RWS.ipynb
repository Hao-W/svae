{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import logsumexp\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import numpy as np\n",
    "from utils_v1 import *\n",
    "from plots import *\n",
    "from objectives_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training parameters\n",
    "STEPS = 10000\n",
    "NUM_SAMPLES = 5\n",
    "NUM_BATCHES = 100\n",
    "LEARNING_RATE = 5*1e-3\n",
    "## model parameters\n",
    "p_mu = torch.tensor([0.0])\n",
    "p_sigma = torch.tensor([1.0])\n",
    "q_mu = torch.tensor([4.0], requires_grad=True)\n",
    "q_sigma = torch.tensor([2.0], requires_grad=True) \n",
    "## initialize optimizer\n",
    "optimizer = torch.optim.SGD([q_mu, q_sigma], lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _, _, _, _ = rws(q_mu, q_sigma, p_mu, p_sigma, NUM_SAMPLES, alpha=None, num_batches=NUM_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Normal(q_mu, q_sigma)\n",
    "xs = q.sample((NUM_SAMPLES, NUM_BATCHES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.grad(loss, [q_mu, q_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(obj, q_mu, q_sigma, p_mu, p_sigma, num_samples, optimizer, alpha, num_batches):\n",
    "    Grad_mu = []\n",
    "    Grad_sigma = []\n",
    "    optimizer.zero_grad()\n",
    "    loss, _, _, _, _ = obj(q_mu, q_sigma, p_mu, p_sigma, num_samples, alpha=alpha, num_batches=num_batches)\n",
    "        loss.backward()\n",
    "        Grad_mu.append(- q_mu.grad.item())\n",
    "        Grad_sigma.append(- q_sigma.grad.item())\n",
    "\n",
    "    snr_mu, var_mu = stats(np.array(Grad_mu))\n",
    "    snr_sigma, var_sigma = stats(np.array(Grad_sigma))\n",
    "    optimizer.zero_grad()\n",
    "    return (snr_mu + snr_sigma) / 2, (var_mu + var_sigma) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rws(q_mu, q_sigma, p_mu, p_sigma, num_samples, num_batches=None, alpha=None):\n",
    "    q = Normal(q_mu, q_sigma)\n",
    "    xs = q.sample((num_samples,)) ## nonreparam sampler\n",
    "    log_p = (-1.0 / ((p_sigma**2) * 2.0)) * ((xs - p_mu) ** 2)\n",
    "    log_q = q.log_prob(xs)\n",
    "    log_weights = log_p - log_q\n",
    "    weights = F.softmax(log_weights, 0).detach()\n",
    "    ess = 1. / (weights ** 2).sum()\n",
    "    eubo = (weights * log_weights).sum()\n",
    "    iwelbo = logsumexp(log_weights, 0) - torch.log(torch.FloatTensor([num_samples]))\n",
    "    elbo = log_weights.mean()\n",
    "    loss = eubo\n",
    "    return loss, eubo, elbo, iwelbo, ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EUBOs, ELBOs, IWELBOs, ESSs, SNRs, VARs = train(dreg, q_mu, q_sigma, p_mu, p_sigma, STEPS, NUM_SAMPLES, NUM_SAMPLES_SNR, optimizer, filename='rws', alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBO, ELBO, ESS, num_samples, snr_mu, snr_sigma):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax1, ax2, ax3 = fig.subplots(3, 1, sharex=True)\n",
    "    plt.tight_layout()\n",
    "    ax1.plot(EUBO, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBO, 'b', label='ELBOs')\n",
    "    ax1.legend()\n",
    "    ## SNR\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.plot(snr_sigma, label='SNR_sigma')\n",
    "    ax2.plot(snr_mu, label='SNR_mu')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylim([1e-2,1e2])\n",
    "    ## ESS\n",
    "    ess_ratio = np.array(ESS) / num_samples\n",
    "    ave_ess = np.reshape(ess_ratio, (-1, 10)).mean(-1)\n",
    "    N = ave_ess.shape[0]\n",
    "    ax3.plot(np.arange(N) * 10, ave_ess, 'go', label='ESS')\n",
    "    ax3.set_ylim([0, 1])\n",
    "# plot_results(EUBO, ELBO, ESS, num_samples, snr_mu, snr_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
