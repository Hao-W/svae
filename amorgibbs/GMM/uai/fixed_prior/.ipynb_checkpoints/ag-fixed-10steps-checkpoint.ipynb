{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from kls import *\n",
    "from torch._six import inf\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 10\n",
    "NUM_HIDDEN = 32\n",
    "STEPS = 10\n",
    "NUM_STATS = K+D*K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS_GLOBAL = D + K\n",
    "NUM_OBS_LOCAL = D + K*D + K*D\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-3\n",
    "CUDA = False\n",
    "PATH = 'ag-50000data-fixed-prior-%dsteps' % STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset_uai2/sequences.npy')).float()\n",
    "# Zs_true = torch.from_numpy(np.load('gmm_dataset2/states.npy')).float()\n",
    "# mus_true = torch.from_numpy(np.load('gmm_dataset2/means.npy')).float()\n",
    "# sigma_true = torch.from_numpy(np.load('gmm_dataset2/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset_uai2/init.npy')).float()\n",
    "num_seqs = Xs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_global(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS_GLOBAL,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "\n",
    "        self.sigmas_log_alpha = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.sigmas_log_beta = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "\n",
    "        self.mus_mean = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.mus_log_nu = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        q_alpha = torch.exp(self.sigmas_log_alpha(stats)).view(-1, K, D) ## B * K * D\n",
    "        q_beta = torch.exp(self.sigmas_log_beta(stats)).view(-1, K, D) ## B * K * D\n",
    "        precisions = Gamma(q_alpha, q_beta).sample((num_samples,)) ## S * B * K * D\n",
    "        \n",
    "        q_mean = self.mus_mean(stats).view(-1, K, D).unsqueeze(0).repeat(num_samples, 1, 1, 1)\n",
    "        q_nu = torch.exp(self.mus_log_nu(stats).view(-1, K, D))\n",
    "        q_sigma = torch.sqrt(1. / (q_nu.unsqueeze(0).repeat(num_samples, 1, 1, 1) * precisions))\n",
    "        mus = Normal(q_mean, q_sigma).sample()  \n",
    "        return q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions ## mus_mean and mus_sigma are S * B * K * D\n",
    "    \n",
    "class Encoder_local(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS_LOCAL,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=K):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_onehot = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents),\n",
    "            nn.Softmax(-1))\n",
    "        \n",
    "    def forward(self, obs, N, K, D, num_samples, batch_size):\n",
    "        zs_pi = self.enc_onehot(obs).view(batch_size, N, K)\n",
    "        zs = cat(zs_pi).sample((num_samples,))\n",
    "        log_qz = cat(zs_pi).log_prob(zs).view(num_samples, batch_size, -1).sum(-1) ## S * B\n",
    "        zs = zs.view(num_samples, batch_size, -1, K) ## S * B * N * K\n",
    "        return zs_pi, zs, log_qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 1e-1)     \n",
    "        \n",
    "def initialize():\n",
    "    enc_global = Encoder_global()\n",
    "    enc_local = Encoder_local()\n",
    "    enc_global.apply(weights_init)\n",
    "    optimizer =  torch.optim.Adam(list(enc_global.parameters()) + list(enc_local.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))    \n",
    "    return enc_global, enc_local, optimizer\n",
    "enc_global, enc_local, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = torch.zeros((BATCH_SIZE, K, D))\n",
    "prior_nu = torch.ones((BATCH_SIZE, K, D)) * 0.3\n",
    "prior_alpha = torch.ones((BATCH_SIZE, K, D)) * 3.0\n",
    "prior_beta = torch.ones((BATCH_SIZE, K, D)) * 3.0\n",
    "\n",
    "def log_joints_gmm(X, Z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size):\n",
    "    log_probs = torch.zeros(batch_size).float()\n",
    "    ## priors on mus and sigmas size B\n",
    "    log_probs = log_probs + Gamma(prior_alpha, prior_beta).log_prob(precisions).sum(-1).sum(-1)\n",
    "    prior_sigma = 1. / torch.sqrt(prior_nu * precisions)\n",
    "    log_probs = log_probs + Normal(prior_mean, prior_sigma).log_prob(mus).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "    log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    sigmas = 1. / torch.sqrt(precisions)\n",
    "    log_probs = log_probs + Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), \n",
    "                                   sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(X).sum(-1).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "def post_global(Xs, Zs, prior_mean, prior_nu, prior_alpha, prior_beta, N, K, D, batch_size):\n",
    "    stat1 = Zs.sum(1).unsqueeze(-1).repeat(1, 1, D) ## B * K * D\n",
    "    xz_nk = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)) # B*N*K*D\n",
    "    stat2 = xz_nk.sum(1) ## B*K*D\n",
    "    stat3 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), torch.mul(Xs, Xs).unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    stat1_nonzero = stat1\n",
    "    stat1_nonzero[stat1_nonzero == 0.0] = 1.0\n",
    "    x_bar = stat2 / stat1\n",
    "    posterior_beta = prior_beta + (stat3 - (stat2 ** 2) / stat1_nonzero) / 2. + (stat1 * prior_nu / (stat1 + prior_nu)) * ((prior_nu**2) + x_bar**2 - 2 * x_bar *  prior_nu) / 2.\n",
    "    posterior_nu = prior_nu + stat1\n",
    "    posterior_mean = (prior_mean * prior_nu + stat2) / (prior_nu + stat1) \n",
    "    posterior_alpha = prior_alpha + (stat1 / 2.)\n",
    "#     posterior_sigma = torch.sqrt(posterior_nu * (posterior_beta / posterior_alpha))\n",
    "    return posterior_mean, posterior_nu, posterior_alpha, posterior_beta\n",
    "\n",
    "def post_local(Xs, Pi, mus, precisions, N, K, D, batch_size):\n",
    "    sigma = 1. / torch.sqrt(precisions)\n",
    "    mus_expand = mus.unsqueeze(2).repeat(1, 1, N, 1)\n",
    "    sigma_expand = sigma.unsqueeze(2).repeat(1, 1, N, 1)\n",
    "    Xs_expand = Xs.unsqueeze(1).repeat(1, K, 1, 1)\n",
    "    log_gammas = Normal(mus_expand, sigma_expand).log_prob(Xs_expand).sum(-1).transpose(-1, -2) # B * N * K\n",
    "    log_pis = log_gammas - logsumexp(log_gammas, dim=-1).unsqueeze(-1)\n",
    "    return log_pis\n",
    "\n",
    "def inti_global(K, D, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size):\n",
    "    precisions = Gamma(prior_alpha, prior_beta).sample()\n",
    "    prior_sigma = 1. / torch.sqrt(prior_nu * precisions)\n",
    "    mus = Normal(prior_mean, prior_sigma).sample()\n",
    "    ## log prior size B\n",
    "    log_p =  Normal(prior_mean, prior_sigma).log_prob(mus).sum(-1).sum(-1) + Gamma(prior_alpha, prior_beta).log_prob(precisions).sum(-1).sum(-1)\n",
    "    return mus, precisions, log_p\n",
    "\n",
    "def E_step(X, mus, precisions, N, D, K, batch_size):\n",
    "    mus_flat = mus.view(-1, K*D).unsqueeze(1).repeat(1, N, 1)\n",
    "    sigma = 1. / torch.sqrt(precisions)\n",
    "    sigma_flat = sigma.view(-1, K*D).unsqueeze(1).repeat(1, N, 1)\n",
    "    data = torch.cat((X, mus_flat, sigma_flat), -1).view(batch_size*N, -1)\n",
    "    zs_pi, zs, log_q_z = enc_local(data, N, K, D, 1, batch_size)\n",
    "    return zs_pi, zs[0], log_q_z[0]\n",
    "\n",
    "def M_step(X, z, N, D, K, batch_size):\n",
    "    data = torch.cat((X, z), dim=-1).view(batch_size*N, -1)\n",
    "    q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions = enc_global(data, K, D, 1, batch_size)  \n",
    "    log_q_eta =  Normal(q_mean[0], q_sigma[0]).log_prob(mus[0]).sum(-1).sum(-1) + Gamma(q_alpha, q_beta).log_prob(precisions[0]).sum(-1).sum(-1)## B\n",
    "    return q_mean[0], q_nu, q_alpha, q_beta, q_sigma[0], mus[0], precisions[0], log_q_eta\n",
    "\n",
    "def kls_step(x, z, q_mean, q_nu, q_alpha, q_beta, zs_pi, mus, precisions, N, K, D, batch_size):\n",
    "    p_mean, p_nu, p_alpha, p_beta = post_global(x, z, prior_mean, prior_nu, prior_alpha, prior_beta, N, K, D, batch_size)\n",
    "    kl_eta_ex, kl_eta_in = kls_NGs(p_mean, p_nu, p_alpha, p_beta, q_mean, q_nu, q_alpha, q_beta)\n",
    "    p_logits = post_local(x, Pi, mus, precisions, N, K, D, batch_size)\n",
    "    kl_z_ex, kl_z_in = kls_cats(p_logits, torch.log(zs_pi))\n",
    "    return kl_eta_ex, kl_eta_in, kl_z_ex, kl_z_in\n",
    "\n",
    "def ag(x, Pi, N, K, D, num_samples, steps, batch_size):\n",
    "    \"\"\"\n",
    "    train both encoders\n",
    "    rws gradient estimator\n",
    "    sis sampling scheme\n",
    "    no resampling\n",
    "    \"\"\"\n",
    "    \n",
    "    kls_eta_ex_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_eta_in_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_ex_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_in_ag = torch.zeros((num_samples, batch_size))\n",
    "    ##\n",
    "    log_increment_weights = torch.zeros((steps, num_samples, batch_size))\n",
    "    Z_samples = torch.zeros((num_samples, batch_size, N, K))\n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            for l in range(num_samples):\n",
    "                mus, precisions, log_p_eta = inti_global(K, D, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                \n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                labels = z.nonzero()\n",
    "                log_p_z = cat(Pi).log_prob(z).sum(-1)\n",
    "                sigmas = 1. / torch.sqrt(precisions)\n",
    "                log_p_x = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1)\n",
    "                log_increment_weights[m, l] = log_p_x + log_p_z - log_q_z \n",
    "\n",
    "        else:\n",
    "            for l in range(num_samples):\n",
    "                z_prev = Z_samples[l]\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z_prev, N, D, K, batch_size)\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                log_p_joint = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_increment_weights[m, l] = log_p_joint - log_q_z - log_q_eta\n",
    "                if m == (steps-1):\n",
    "                    kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = kls_step(x, z, q_mean, q_nu, q_alpha, q_beta, zs_pi, mus, precisions, N, K, D, batch_size)\n",
    "                    kls_eta_ex_ag[l] = kl_eta_ex_ag\n",
    "                    kls_eta_in_ag[l] = kl_eta_in_ag\n",
    "                    kls_z_ex_ag[l] = kl_z_ex_ag\n",
    "                    kls_z_in_ag[l] = kl_z_in_ag\n",
    "                    \n",
    "    increment_weights = torch.exp(log_increment_weights - logsumexp(log_increment_weights, 1).unsqueeze(1).repeat(1, num_samples, 1)).detach()\n",
    "    ess = (1./ (increment_weights ** 2).sum(1)).mean(0).mean()   \n",
    "#     ess = (1./ (increment_weights ** 2).sum(1)).mean(0).mean() \n",
    "    ## EUBO and ELBO\n",
    "    eubos = torch.mul(increment_weights, log_increment_weights).sum(1)\n",
    "    eubo = eubos.mean(0).mean()\n",
    "    \n",
    "    elbos = log_increment_weights.mean(1).mean(-1)\n",
    "    elbo = elbos.mean(0).mean()\n",
    "    ## eubo and elbo at init step\n",
    "    eubo_ag = eubos[-1].mean()\n",
    "    elbo_ag = elbos[-1].mean()     \n",
    "    ## KL after 10 steps\n",
    "    final_weights = increment_weights[-1]\n",
    "    KL_eta_ex_ag = torch.mul(final_weights, kls_eta_ex_ag).sum(0).mean()\n",
    "    KL_eta_in_ag = torch.mul(final_weights, kls_eta_in_ag).sum(0).mean()\n",
    "    KL_z_ex_ag = torch.mul(final_weights, kls_z_ex_ag).sum(0).mean()\n",
    "    KL_z_in_ag = torch.mul(final_weights, kls_z_in_ag).sum(0).mean()  \n",
    "    \n",
    "    return eubo, elbo, ess, eubo_ag, elbo_ag, KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\n",
    "\n",
    "def shuffler(batch_Xs, N, K, D, batch_size):\n",
    "    indices = torch.cat([torch.randperm(N).unsqueeze(0) for b in range(batch_size)])\n",
    "    indices_Xs = indices.unsqueeze(-1).repeat(1, 1, D)\n",
    "    return torch.gather(batch_Xs, 1, indices_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-186.989, ELBO=-242.688, ESS=1.322, EX_eta=40.573, IN_eta=22.193, EX_z=6.770, IN_z=3.876 (502s)\n",
      "epoch=1, EUBO=-170.252, ELBO=-218.701, ESS=1.416, EX_eta=30.518, IN_eta=15.728, EX_z=2.105, IN_z=1.617 (499s)\n",
      "epoch=2, EUBO=-164.986, ELBO=-210.272, ESS=1.454, EX_eta=28.900, IN_eta=13.494, EX_z=1.541, IN_z=1.094 (499s)\n",
      "epoch=3, EUBO=-160.824, ELBO=-203.588, ESS=1.494, EX_eta=24.070, IN_eta=11.221, EX_z=1.241, IN_z=0.786 (499s)\n",
      "epoch=4, EUBO=-158.342, ELBO=-200.207, ESS=1.529, EX_eta=19.190, IN_eta=9.290, EX_z=0.978, IN_z=0.599 (500s)\n",
      "epoch=5, EUBO=-156.834, ELBO=-198.644, ESS=1.559, EX_eta=15.603, IN_eta=7.957, EX_z=0.827, IN_z=0.496 (501s)\n",
      "epoch=6, EUBO=-156.013, ELBO=-198.042, ESS=1.575, EX_eta=13.419, IN_eta=7.093, EX_z=0.740, IN_z=0.419 (502s)\n",
      "epoch=7, EUBO=-155.381, ELBO=-197.663, ESS=1.588, EX_eta=12.202, IN_eta=6.554, EX_z=0.661, IN_z=0.373 (502s)\n",
      "epoch=8, EUBO=-154.993, ELBO=-197.039, ESS=1.615, EX_eta=11.302, IN_eta=6.239, EX_z=0.633, IN_z=0.333 (502s)\n",
      "epoch=9, EUBO=-154.615, ELBO=-196.546, ESS=1.643, EX_eta=10.695, IN_eta=5.884, EX_z=0.517, IN_z=0.302 (502s)\n",
      "epoch=10, EUBO=-154.377, ELBO=-195.859, ESS=1.662, EX_eta=10.313, IN_eta=5.746, EX_z=0.516, IN_z=0.282 (501s)\n",
      "epoch=11, EUBO=-154.031, ELBO=-195.207, ESS=1.685, EX_eta=10.070, IN_eta=5.570, EX_z=0.478, IN_z=0.263 (501s)\n",
      "epoch=12, EUBO=-153.875, ELBO=-194.694, ESS=1.700, EX_eta=9.932, IN_eta=5.427, EX_z=0.415, IN_z=0.252 (501s)\n",
      "epoch=13, EUBO=-153.713, ELBO=-194.261, ESS=1.714, EX_eta=9.639, IN_eta=5.350, EX_z=0.386, IN_z=0.238 (502s)\n",
      "epoch=14, EUBO=-153.527, ELBO=-193.980, ESS=1.725, EX_eta=9.545, IN_eta=5.259, EX_z=0.341, IN_z=0.225 (501s)\n",
      "epoch=15, EUBO=-153.367, ELBO=-193.397, ESS=1.735, EX_eta=9.408, IN_eta=5.209, EX_z=0.343, IN_z=0.215 (500s)\n",
      "epoch=16, EUBO=-153.259, ELBO=-193.202, ESS=1.746, EX_eta=9.241, IN_eta=5.124, EX_z=0.349, IN_z=0.207 (501s)\n",
      "epoch=17, EUBO=-153.112, ELBO=-192.773, ESS=1.752, EX_eta=9.178, IN_eta=5.057, EX_z=0.304, IN_z=0.200 (500s)\n",
      "epoch=18, EUBO=-152.957, ELBO=-192.398, ESS=1.762, EX_eta=9.102, IN_eta=5.009, EX_z=0.296, IN_z=0.197 (501s)\n",
      "epoch=19, EUBO=-152.867, ELBO=-192.046, ESS=1.770, EX_eta=9.002, IN_eta=4.944, EX_z=0.268, IN_z=0.186 (500s)\n",
      "epoch=20, EUBO=-152.768, ELBO=-191.703, ESS=1.776, EX_eta=8.932, IN_eta=4.917, EX_z=0.283, IN_z=0.183 (501s)\n",
      "epoch=21, EUBO=-152.656, ELBO=-191.395, ESS=1.783, EX_eta=8.882, IN_eta=4.872, EX_z=0.253, IN_z=0.176 (501s)\n",
      "epoch=22, EUBO=-152.601, ELBO=-191.266, ESS=1.789, EX_eta=8.879, IN_eta=4.846, EX_z=0.256, IN_z=0.176 (501s)\n",
      "epoch=23, EUBO=-152.462, ELBO=-191.001, ESS=1.791, EX_eta=8.822, IN_eta=4.812, EX_z=0.233, IN_z=0.170 (501s)\n",
      "epoch=24, EUBO=-152.367, ELBO=-190.722, ESS=1.800, EX_eta=8.703, IN_eta=4.748, EX_z=0.228, IN_z=0.164 (500s)\n",
      "epoch=25, EUBO=-152.371, ELBO=-190.791, ESS=1.800, EX_eta=8.762, IN_eta=4.764, EX_z=0.228, IN_z=0.161 (500s)\n",
      "epoch=26, EUBO=-152.366, ELBO=-190.721, ESS=1.806, EX_eta=8.742, IN_eta=4.732, EX_z=0.230, IN_z=0.162 (500s)\n",
      "epoch=27, EUBO=-152.302, ELBO=-190.514, ESS=1.814, EX_eta=8.651, IN_eta=4.692, EX_z=0.239, IN_z=0.157 (501s)\n",
      "epoch=28, EUBO=-152.260, ELBO=-190.351, ESS=1.819, EX_eta=8.677, IN_eta=4.663, EX_z=0.223, IN_z=0.152 (501s)\n",
      "epoch=29, EUBO=-152.209, ELBO=-190.176, ESS=1.818, EX_eta=8.612, IN_eta=4.660, EX_z=0.209, IN_z=0.150 (500s)\n",
      "epoch=30, EUBO=-152.074, ELBO=-189.937, ESS=1.822, EX_eta=8.577, IN_eta=4.628, EX_z=0.208, IN_z=0.147 (500s)\n",
      "epoch=31, EUBO=-152.102, ELBO=-189.757, ESS=1.828, EX_eta=8.513, IN_eta=4.619, EX_z=0.217, IN_z=0.148 (500s)\n",
      "epoch=32, EUBO=-152.082, ELBO=-189.624, ESS=1.826, EX_eta=8.547, IN_eta=4.618, EX_z=0.188, IN_z=0.143 (500s)\n",
      "epoch=33, EUBO=-152.008, ELBO=-189.495, ESS=1.833, EX_eta=8.535, IN_eta=4.584, EX_z=0.193, IN_z=0.140 (500s)\n",
      "epoch=34, EUBO=-151.952, ELBO=-189.392, ESS=1.835, EX_eta=8.503, IN_eta=4.587, EX_z=0.194, IN_z=0.136 (500s)\n",
      "epoch=35, EUBO=-152.010, ELBO=-189.191, ESS=1.841, EX_eta=8.355, IN_eta=4.518, EX_z=0.210, IN_z=0.135 (500s)\n",
      "epoch=36, EUBO=-151.910, ELBO=-189.066, ESS=1.844, EX_eta=8.452, IN_eta=4.533, EX_z=0.196, IN_z=0.134 (500s)\n",
      "epoch=37, EUBO=-151.916, ELBO=-189.039, ESS=1.847, EX_eta=8.379, IN_eta=4.488, EX_z=0.190, IN_z=0.130 (500s)\n",
      "epoch=38, EUBO=-151.858, ELBO=-188.913, ESS=1.846, EX_eta=8.383, IN_eta=4.506, EX_z=0.179, IN_z=0.128 (500s)\n",
      "epoch=39, EUBO=-151.793, ELBO=-188.834, ESS=1.851, EX_eta=8.372, IN_eta=4.475, EX_z=0.177, IN_z=0.126 (500s)\n",
      "epoch=40, EUBO=-151.744, ELBO=-188.628, ESS=1.856, EX_eta=8.356, IN_eta=4.453, EX_z=0.165, IN_z=0.126 (500s)\n",
      "epoch=41, EUBO=-151.749, ELBO=-188.491, ESS=1.855, EX_eta=8.253, IN_eta=4.445, EX_z=0.195, IN_z=0.122 (500s)\n",
      "epoch=42, EUBO=-151.669, ELBO=-188.430, ESS=1.857, EX_eta=8.319, IN_eta=4.440, EX_z=0.160, IN_z=0.122 (500s)\n",
      "epoch=43, EUBO=-151.576, ELBO=-188.274, ESS=1.858, EX_eta=8.283, IN_eta=4.440, EX_z=0.166, IN_z=0.121 (500s)\n",
      "epoch=44, EUBO=-151.626, ELBO=-188.232, ESS=1.861, EX_eta=8.231, IN_eta=4.416, EX_z=0.160, IN_z=0.120 (500s)\n",
      "epoch=45, EUBO=-151.663, ELBO=-188.171, ESS=1.858, EX_eta=8.281, IN_eta=4.438, EX_z=0.165, IN_z=0.119 (500s)\n",
      "epoch=46, EUBO=-151.615, ELBO=-188.059, ESS=1.869, EX_eta=8.199, IN_eta=4.390, EX_z=0.149, IN_z=0.117 (500s)\n",
      "epoch=47, EUBO=-151.702, ELBO=-188.044, ESS=1.865, EX_eta=8.277, IN_eta=4.410, EX_z=0.156, IN_z=0.117 (500s)\n",
      "epoch=48, EUBO=-151.557, ELBO=-187.874, ESS=1.871, EX_eta=8.169, IN_eta=4.385, EX_z=0.158, IN_z=0.114 (499s)\n",
      "epoch=49, EUBO=-151.531, ELBO=-187.810, ESS=1.875, EX_eta=8.124, IN_eta=4.360, EX_z=0.146, IN_z=0.113 (499s)\n",
      "epoch=50, EUBO=-151.544, ELBO=-187.804, ESS=1.873, EX_eta=8.164, IN_eta=4.380, EX_z=0.142, IN_z=0.112 (500s)\n",
      "epoch=51, EUBO=-151.482, ELBO=-187.667, ESS=1.877, EX_eta=8.087, IN_eta=4.327, EX_z=0.143, IN_z=0.113 (499s)\n",
      "epoch=52, EUBO=-151.487, ELBO=-187.551, ESS=1.876, EX_eta=8.115, IN_eta=4.349, EX_z=0.144, IN_z=0.112 (499s)\n",
      "epoch=53, EUBO=-151.466, ELBO=-187.542, ESS=1.878, EX_eta=8.116, IN_eta=4.355, EX_z=0.144, IN_z=0.112 (499s)\n",
      "epoch=54, EUBO=-151.396, ELBO=-187.402, ESS=1.878, EX_eta=8.128, IN_eta=4.342, EX_z=0.143, IN_z=0.111 (499s)\n",
      "epoch=55, EUBO=-151.375, ELBO=-187.416, ESS=1.885, EX_eta=8.054, IN_eta=4.332, EX_z=0.147, IN_z=0.109 (499s)\n",
      "epoch=56, EUBO=-151.347, ELBO=-187.238, ESS=1.884, EX_eta=8.050, IN_eta=4.346, EX_z=0.137, IN_z=0.110 (499s)\n",
      "epoch=57, EUBO=-151.303, ELBO=-187.156, ESS=1.885, EX_eta=7.990, IN_eta=4.314, EX_z=0.137, IN_z=0.108 (499s)\n",
      "epoch=58, EUBO=-151.386, ELBO=-187.261, ESS=1.883, EX_eta=8.023, IN_eta=4.321, EX_z=0.135, IN_z=0.108 (500s)\n",
      "epoch=59, EUBO=-151.400, ELBO=-187.212, ESS=1.887, EX_eta=7.962, IN_eta=4.292, EX_z=0.148, IN_z=0.107 (498s)\n",
      "epoch=60, EUBO=-151.306, ELBO=-187.030, ESS=1.892, EX_eta=7.958, IN_eta=4.269, EX_z=0.138, IN_z=0.107 (499s)\n",
      "epoch=61, EUBO=-151.276, ELBO=-187.033, ESS=1.894, EX_eta=7.999, IN_eta=4.272, EX_z=0.136, IN_z=0.107 (499s)\n",
      "epoch=62, EUBO=-151.295, ELBO=-186.969, ESS=1.893, EX_eta=7.906, IN_eta=4.265, EX_z=0.129, IN_z=0.108 (499s)\n",
      "epoch=63, EUBO=-151.241, ELBO=-186.818, ESS=1.897, EX_eta=7.872, IN_eta=4.256, EX_z=0.139, IN_z=0.106 (499s)\n",
      "epoch=64, EUBO=-151.171, ELBO=-186.700, ESS=1.900, EX_eta=7.851, IN_eta=4.235, EX_z=0.128, IN_z=0.106 (498s)\n",
      "epoch=65, EUBO=-151.252, ELBO=-186.687, ESS=1.899, EX_eta=7.848, IN_eta=4.262, EX_z=0.129, IN_z=0.105 (499s)\n",
      "epoch=66, EUBO=-151.246, ELBO=-186.748, ESS=1.897, EX_eta=7.783, IN_eta=4.244, EX_z=0.130, IN_z=0.105 (499s)\n",
      "epoch=67, EUBO=-151.288, ELBO=-186.703, ESS=1.904, EX_eta=7.772, IN_eta=4.210, EX_z=0.120, IN_z=0.103 (499s)\n",
      "epoch=68, EUBO=-151.139, ELBO=-186.665, ESS=1.901, EX_eta=7.796, IN_eta=4.221, EX_z=0.133, IN_z=0.103 (498s)\n",
      "epoch=69, EUBO=-151.227, ELBO=-186.743, ESS=1.904, EX_eta=7.816, IN_eta=4.200, EX_z=0.133, IN_z=0.103 (499s)\n",
      "epoch=70, EUBO=-151.165, ELBO=-186.555, ESS=1.907, EX_eta=7.739, IN_eta=4.197, EX_z=0.123, IN_z=0.102 (498s)\n",
      "epoch=71, EUBO=-151.139, ELBO=-186.401, ESS=1.910, EX_eta=7.767, IN_eta=4.194, EX_z=0.128, IN_z=0.102 (499s)\n",
      "epoch=72, EUBO=-151.199, ELBO=-186.472, ESS=1.910, EX_eta=7.677, IN_eta=4.176, EX_z=0.127, IN_z=0.104 (498s)\n",
      "epoch=73, EUBO=-151.113, ELBO=-186.454, ESS=1.912, EX_eta=7.773, IN_eta=4.196, EX_z=0.128, IN_z=0.102 (498s)\n",
      "epoch=74, EUBO=-151.062, ELBO=-186.422, ESS=1.916, EX_eta=7.665, IN_eta=4.169, EX_z=0.134, IN_z=0.101 (499s)\n",
      "epoch=75, EUBO=-151.113, ELBO=-186.352, ESS=1.914, EX_eta=7.656, IN_eta=4.182, EX_z=0.117, IN_z=0.101 (499s)\n",
      "epoch=76, EUBO=-151.131, ELBO=-186.299, ESS=1.910, EX_eta=7.637, IN_eta=4.159, EX_z=0.121, IN_z=0.100 (498s)\n",
      "epoch=77, EUBO=-151.011, ELBO=-186.177, ESS=1.917, EX_eta=7.616, IN_eta=4.158, EX_z=0.118, IN_z=0.102 (498s)\n",
      "epoch=78, EUBO=-151.106, ELBO=-186.110, ESS=1.918, EX_eta=7.598, IN_eta=4.148, EX_z=0.119, IN_z=0.100 (499s)\n",
      "epoch=79, EUBO=-151.004, ELBO=-186.108, ESS=1.916, EX_eta=7.591, IN_eta=4.150, EX_z=0.120, IN_z=0.100 (498s)\n",
      "epoch=80, EUBO=-151.113, ELBO=-186.222, ESS=1.916, EX_eta=7.599, IN_eta=4.146, EX_z=0.124, IN_z=0.099 (499s)\n",
      "epoch=81, EUBO=-150.961, ELBO=-186.152, ESS=1.919, EX_eta=7.612, IN_eta=4.140, EX_z=0.115, IN_z=0.099 (498s)\n",
      "epoch=82, EUBO=-151.118, ELBO=-186.198, ESS=1.921, EX_eta=7.535, IN_eta=4.120, EX_z=0.116, IN_z=0.099 (498s)\n",
      "epoch=83, EUBO=-151.041, ELBO=-186.187, ESS=1.924, EX_eta=7.527, IN_eta=4.126, EX_z=0.122, IN_z=0.099 (499s)\n",
      "epoch=84, EUBO=-150.986, ELBO=-186.103, ESS=1.921, EX_eta=7.635, IN_eta=4.129, EX_z=0.119, IN_z=0.100 (499s)\n",
      "epoch=85, EUBO=-151.028, ELBO=-186.138, ESS=1.920, EX_eta=7.546, IN_eta=4.120, EX_z=0.120, IN_z=0.099 (499s)\n",
      "epoch=86, EUBO=-151.037, ELBO=-186.136, ESS=1.922, EX_eta=7.494, IN_eta=4.113, EX_z=0.123, IN_z=0.098 (498s)\n",
      "epoch=87, EUBO=-150.984, ELBO=-186.115, ESS=1.925, EX_eta=7.567, IN_eta=4.124, EX_z=0.114, IN_z=0.100 (499s)\n",
      "epoch=88, EUBO=-151.034, ELBO=-186.147, ESS=1.928, EX_eta=7.493, IN_eta=4.084, EX_z=0.115, IN_z=0.098 (498s)\n",
      "epoch=89, EUBO=-150.919, ELBO=-185.947, ESS=1.926, EX_eta=7.545, IN_eta=4.085, EX_z=0.121, IN_z=0.098 (498s)\n",
      "epoch=90, EUBO=-151.014, ELBO=-186.034, ESS=1.927, EX_eta=7.517, IN_eta=4.073, EX_z=0.118, IN_z=0.099 (499s)\n",
      "epoch=91, EUBO=-150.929, ELBO=-185.997, ESS=1.929, EX_eta=7.452, IN_eta=4.097, EX_z=0.115, IN_z=0.097 (498s)\n",
      "epoch=92, EUBO=-150.884, ELBO=-185.845, ESS=1.928, EX_eta=7.467, IN_eta=4.075, EX_z=0.116, IN_z=0.096 (498s)\n",
      "epoch=93, EUBO=-150.991, ELBO=-185.811, ESS=1.932, EX_eta=7.461, IN_eta=4.078, EX_z=0.115, IN_z=0.097 (498s)\n",
      "epoch=94, EUBO=-150.944, ELBO=-185.840, ESS=1.930, EX_eta=7.411, IN_eta=4.070, EX_z=0.113, IN_z=0.098 (498s)\n",
      "epoch=95, EUBO=-150.902, ELBO=-185.868, ESS=1.929, EX_eta=7.426, IN_eta=4.074, EX_z=0.126, IN_z=0.099 (498s)\n",
      "epoch=96, EUBO=-150.891, ELBO=-185.809, ESS=1.934, EX_eta=7.431, IN_eta=4.055, EX_z=0.125, IN_z=0.096 (498s)\n",
      "epoch=97, EUBO=-150.961, ELBO=-185.757, ESS=1.932, EX_eta=7.417, IN_eta=4.062, EX_z=0.121, IN_z=0.097 (498s)\n",
      "epoch=98, EUBO=-150.943, ELBO=-185.865, ESS=1.934, EX_eta=7.372, IN_eta=4.043, EX_z=0.115, IN_z=0.097 (498s)\n",
      "epoch=99, EUBO=-150.913, ELBO=-185.671, ESS=1.931, EX_eta=7.466, IN_eta=4.067, EX_z=0.112, IN_z=0.098 (498s)\n",
      "epoch=100, EUBO=-150.868, ELBO=-185.707, ESS=1.934, EX_eta=7.406, IN_eta=4.075, EX_z=0.117, IN_z=0.098 (498s)\n",
      "epoch=101, EUBO=-150.940, ELBO=-185.791, ESS=1.937, EX_eta=7.387, IN_eta=4.048, EX_z=0.114, IN_z=0.097 (498s)\n",
      "epoch=102, EUBO=-150.809, ELBO=-185.599, ESS=1.939, EX_eta=7.394, IN_eta=4.050, EX_z=0.113, IN_z=0.098 (498s)\n",
      "epoch=103, EUBO=-150.851, ELBO=-185.565, ESS=1.937, EX_eta=7.334, IN_eta=4.018, EX_z=0.113, IN_z=0.096 (498s)\n",
      "epoch=104, EUBO=-150.892, ELBO=-185.641, ESS=1.936, EX_eta=7.350, IN_eta=4.050, EX_z=0.113, IN_z=0.096 (498s)\n",
      "epoch=105, EUBO=-150.854, ELBO=-185.563, ESS=1.940, EX_eta=7.373, IN_eta=4.037, EX_z=0.111, IN_z=0.096 (498s)\n",
      "epoch=106, EUBO=-150.883, ELBO=-185.650, ESS=1.938, EX_eta=7.360, IN_eta=4.039, EX_z=0.113, IN_z=0.097 (498s)\n",
      "epoch=107, EUBO=-150.901, ELBO=-185.668, ESS=1.938, EX_eta=7.364, IN_eta=4.034, EX_z=0.143, IN_z=0.096 (498s)\n",
      "epoch=108, EUBO=-150.849, ELBO=-185.539, ESS=1.941, EX_eta=7.324, IN_eta=4.032, EX_z=0.122, IN_z=0.095 (498s)\n",
      "epoch=109, EUBO=-150.869, ELBO=-185.677, ESS=1.941, EX_eta=7.320, IN_eta=4.001, EX_z=0.117, IN_z=0.095 (498s)\n",
      "epoch=110, EUBO=-150.847, ELBO=-185.580, ESS=1.943, EX_eta=7.315, IN_eta=4.008, EX_z=0.111, IN_z=0.095 (498s)\n",
      "epoch=111, EUBO=-150.771, ELBO=-185.517, ESS=1.946, EX_eta=7.308, IN_eta=4.013, EX_z=0.115, IN_z=0.096 (498s)\n",
      "epoch=112, EUBO=-150.783, ELBO=-185.424, ESS=1.946, EX_eta=7.266, IN_eta=3.983, EX_z=0.123, IN_z=0.095 (498s)\n",
      "epoch=113, EUBO=-150.948, ELBO=-185.390, ESS=1.945, EX_eta=7.286, IN_eta=3.992, EX_z=0.112, IN_z=0.095 (498s)\n",
      "epoch=114, EUBO=-150.841, ELBO=-185.387, ESS=1.949, EX_eta=7.250, IN_eta=3.982, EX_z=0.119, IN_z=0.094 (498s)\n",
      "epoch=115, EUBO=-150.852, ELBO=-185.490, ESS=1.948, EX_eta=7.302, IN_eta=3.987, EX_z=0.114, IN_z=0.096 (498s)\n",
      "epoch=116, EUBO=-150.752, ELBO=-185.324, ESS=1.950, EX_eta=7.265, IN_eta=3.982, EX_z=0.107, IN_z=0.095 (498s)\n",
      "epoch=117, EUBO=-150.795, ELBO=-185.258, ESS=1.953, EX_eta=7.238, IN_eta=3.966, EX_z=0.111, IN_z=0.094 (497s)\n",
      "epoch=118, EUBO=-150.791, ELBO=-185.157, ESS=1.950, EX_eta=7.218, IN_eta=3.981, EX_z=0.118, IN_z=0.093 (498s)\n",
      "epoch=119, EUBO=-150.754, ELBO=-185.206, ESS=1.950, EX_eta=7.219, IN_eta=3.971, EX_z=0.120, IN_z=0.094 (498s)\n",
      "epoch=120, EUBO=-150.803, ELBO=-185.317, ESS=1.953, EX_eta=7.206, IN_eta=3.966, EX_z=0.117, IN_z=0.095 (498s)\n",
      "epoch=121, EUBO=-150.749, ELBO=-185.208, ESS=1.956, EX_eta=7.215, IN_eta=3.949, EX_z=0.109, IN_z=0.096 (498s)\n",
      "epoch=122, EUBO=-150.710, ELBO=-185.077, ESS=1.954, EX_eta=7.195, IN_eta=3.953, EX_z=0.104, IN_z=0.093 (498s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-660f7ad3c4a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         batch_sigma2 = sigma2_true[batch_indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_ag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa990a790b89>\u001b[0m in \u001b[0;36mag\u001b[0;34m(x, Pi, N, K, D, num_samples, steps, batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mz_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa990a790b89>\u001b[0m in \u001b[0;36mM_step\u001b[0;34m(X, z, N, D, K, batch_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mlog_q_eta\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dev/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e2192f60054a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, K, D, num_samples, batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mq_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmus_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mq_nu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmus_log_nu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mq_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_nu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dev/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flog = open('results/log-' + PATH + '.txt', 'w+')\n",
    "flog.write('EUBO_ave, ELBO_ave, ESS, EUBO_ag, ELBO_ag, KLs_eta_ex_ag, KLs_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\\n')\n",
    "flog.close()\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    EUBO_ag = 0.0\n",
    "    ELBO_ag = 0.0\n",
    "    \n",
    "    ESS = 0.0\n",
    "    KL_eta_ex_ag = 0.0\n",
    "    KL_eta_in_ag = 0.0\n",
    "    KL_z_ex_ag = 0.0\n",
    "    KL_z_in_ag = 0.0\n",
    "    \n",
    "    \n",
    "    for step in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "#         batch_Zs = Zs_true[batch_indices]\n",
    "#         batch_mus = mus_true[batch_indices]\n",
    "#         batch_sigma2 = sigma2_true[batch_indices]\n",
    "        batch_Xs = shuffler(batch_Xs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess, eubo_ag, elbo_ag, kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = ag(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "\n",
    "        EUBO_ag += eubo_ag.item()\n",
    "        ELBO_ag += elbo_ag.item()\n",
    "        \n",
    "        ESS += ess.item()\n",
    "        KL_eta_ex_ag += kl_eta_ex_ag.item()\n",
    "        KL_eta_in_ag += kl_eta_in_ag.item()\n",
    "        KL_z_ex_ag += kl_z_ex_ag.item()\n",
    "        KL_z_in_ag += kl_z_in_ag.item()\n",
    "\n",
    "            \n",
    "        flog = open('results/log-' + PATH + '.txt', 'a+')\n",
    "        flog.write(str(eubo.item()) + ', ' + str(elbo.item()) + ', ' + str(ess.item()) + ', ' + \n",
    "               str(eubo_ag.item()) + ', ' + str(elbo_ag.item()) + ', ' +\n",
    "               str(kl_eta_ex_ag.item()) + ', ' + str(kl_eta_in_ag.item()) + ', ' + str(kl_z_ex_ag.item()) + ', ' + str(kl_z_in_ag.item()) + '\\n')\n",
    "        flog.close()\n",
    "             \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    \n",
    "    EUBO_ag /= num_batches\n",
    "    ELBO_ag /= num_batches\n",
    "    \n",
    "    ESS /= num_batches\n",
    "    KL_eta_ex_ag /= num_batches\n",
    "    KL_eta_in_ag /= num_batches\n",
    "    KL_z_ex_ag /= num_batches\n",
    "    KL_z_in_ag /= num_batches\n",
    "\n",
    "    time_end = time.time()  \n",
    "    print('epoch=%d, EUBO=%.3f, ELBO=%.3f, ESS=%.3f, EX_eta=%.3f, IN_eta=%.3f, EX_z=%.3f, IN_z=%.3f (%ds)'\n",
    "            % (epoch, EUBO, ELBO, ESS,  KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc_global.state_dict(), 'models/global-enc-' + PATH)\n",
    "torch.save(enc_local.state_dict(), 'models/local-enc' + PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'ag-stage2-50000datasets-fixed-prior-%dsteps' % STEPS\n",
    "opt2 =  torch.optim.Adam(list(enc_global.parameters()) + list(enc_local.parameters()),lr=1e-5, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-150.532, ELBO=-184.401, ESS=2.073, EX_eta=6.618, IN_eta=3.602, EX_z=0.103, IN_z=0.086 (500s)\n",
      "epoch=1, EUBO=-150.518, ELBO=-184.394, ESS=2.082, EX_eta=6.554, IN_eta=3.556, EX_z=0.106, IN_z=0.083 (500s)\n",
      "epoch=2, EUBO=-150.456, ELBO=-184.300, ESS=2.083, EX_eta=6.585, IN_eta=3.556, EX_z=0.108, IN_z=0.080 (500s)\n",
      "epoch=3, EUBO=-150.431, ELBO=-184.267, ESS=2.084, EX_eta=6.595, IN_eta=3.545, EX_z=0.101, IN_z=0.081 (500s)\n",
      "epoch=4, EUBO=-150.429, ELBO=-184.341, ESS=2.087, EX_eta=6.627, IN_eta=3.542, EX_z=0.088, IN_z=0.079 (500s)\n",
      "epoch=5, EUBO=-150.466, ELBO=-184.232, ESS=2.087, EX_eta=6.571, IN_eta=3.533, EX_z=0.117, IN_z=0.079 (500s)\n",
      "epoch=6, EUBO=-150.470, ELBO=-184.289, ESS=2.087, EX_eta=6.548, IN_eta=3.535, EX_z=0.092, IN_z=0.079 (500s)\n",
      "epoch=7, EUBO=-150.472, ELBO=-184.249, ESS=2.087, EX_eta=6.553, IN_eta=3.526, EX_z=0.111, IN_z=0.078 (500s)\n",
      "epoch=8, EUBO=-150.437, ELBO=-184.240, ESS=2.087, EX_eta=6.523, IN_eta=3.531, EX_z=0.095, IN_z=0.078 (500s)\n",
      "epoch=9, EUBO=-150.493, ELBO=-184.359, ESS=2.088, EX_eta=6.542, IN_eta=3.534, EX_z=0.109, IN_z=0.078 (500s)\n",
      "epoch=10, EUBO=-150.472, ELBO=-184.350, ESS=2.090, EX_eta=6.538, IN_eta=3.524, EX_z=0.100, IN_z=0.078 (500s)\n",
      "epoch=11, EUBO=-150.431, ELBO=-184.188, ESS=2.090, EX_eta=6.590, IN_eta=3.535, EX_z=0.107, IN_z=0.077 (500s)\n",
      "epoch=12, EUBO=-150.433, ELBO=-184.249, ESS=2.089, EX_eta=6.556, IN_eta=3.526, EX_z=0.100, IN_z=0.076 (500s)\n",
      "epoch=13, EUBO=-150.502, ELBO=-184.271, ESS=2.090, EX_eta=6.564, IN_eta=3.522, EX_z=0.088, IN_z=0.078 (499s)\n",
      "epoch=14, EUBO=-150.472, ELBO=-184.264, ESS=2.089, EX_eta=6.569, IN_eta=3.531, EX_z=0.088, IN_z=0.078 (500s)\n",
      "epoch=15, EUBO=-150.504, ELBO=-184.318, ESS=2.092, EX_eta=6.512, IN_eta=3.514, EX_z=0.115, IN_z=0.077 (500s)\n",
      "epoch=16, EUBO=-150.465, ELBO=-184.268, ESS=2.089, EX_eta=6.536, IN_eta=3.523, EX_z=0.101, IN_z=0.077 (500s)\n",
      "epoch=17, EUBO=-150.454, ELBO=-184.242, ESS=2.090, EX_eta=6.533, IN_eta=3.520, EX_z=0.102, IN_z=0.078 (500s)\n",
      "epoch=18, EUBO=-150.427, ELBO=-184.211, ESS=2.090, EX_eta=6.574, IN_eta=3.532, EX_z=0.090, IN_z=0.078 (500s)\n",
      "epoch=19, EUBO=-150.483, ELBO=-184.297, ESS=2.091, EX_eta=6.480, IN_eta=3.515, EX_z=0.089, IN_z=0.075 (499s)\n",
      "epoch=20, EUBO=-150.463, ELBO=-184.326, ESS=2.091, EX_eta=6.539, IN_eta=3.516, EX_z=0.124, IN_z=0.077 (500s)\n",
      "epoch=21, EUBO=-150.431, ELBO=-184.198, ESS=2.089, EX_eta=6.505, IN_eta=3.521, EX_z=0.091, IN_z=0.076 (500s)\n",
      "epoch=22, EUBO=-150.487, ELBO=-184.228, ESS=2.092, EX_eta=6.491, IN_eta=3.524, EX_z=0.088, IN_z=0.077 (500s)\n",
      "epoch=23, EUBO=-150.469, ELBO=-184.168, ESS=2.093, EX_eta=6.513, IN_eta=3.523, EX_z=0.103, IN_z=0.076 (500s)\n",
      "epoch=24, EUBO=-150.446, ELBO=-184.226, ESS=2.094, EX_eta=6.518, IN_eta=3.511, EX_z=0.145, IN_z=0.077 (500s)\n",
      "epoch=25, EUBO=-150.457, ELBO=-184.224, ESS=2.091, EX_eta=6.496, IN_eta=3.515, EX_z=0.087, IN_z=0.078 (500s)\n",
      "epoch=26, EUBO=-150.590, ELBO=-184.295, ESS=2.092, EX_eta=6.533, IN_eta=3.513, EX_z=0.098, IN_z=0.076 (500s)\n",
      "epoch=27, EUBO=-150.444, ELBO=-184.195, ESS=2.094, EX_eta=6.533, IN_eta=3.514, EX_z=0.102, IN_z=0.077 (500s)\n",
      "epoch=28, EUBO=-150.496, ELBO=-184.314, ESS=2.091, EX_eta=6.524, IN_eta=3.519, EX_z=0.090, IN_z=0.076 (500s)\n",
      "epoch=29, EUBO=-150.415, ELBO=-184.234, ESS=2.089, EX_eta=6.552, IN_eta=3.509, EX_z=0.099, IN_z=0.076 (500s)\n",
      "epoch=30, EUBO=-150.496, ELBO=-184.321, ESS=2.091, EX_eta=6.482, IN_eta=3.521, EX_z=0.087, IN_z=0.082 (500s)\n",
      "epoch=31, EUBO=-150.486, ELBO=-184.153, ESS=2.092, EX_eta=6.516, IN_eta=3.513, EX_z=0.094, IN_z=0.076 (500s)\n",
      "epoch=32, EUBO=-150.444, ELBO=-184.270, ESS=2.092, EX_eta=6.512, IN_eta=3.512, EX_z=0.103, IN_z=0.077 (500s)\n",
      "epoch=33, EUBO=-150.459, ELBO=-184.220, ESS=2.091, EX_eta=6.446, IN_eta=3.501, EX_z=0.099, IN_z=0.077 (500s)\n",
      "epoch=34, EUBO=-150.437, ELBO=-184.234, ESS=2.091, EX_eta=6.503, IN_eta=3.514, EX_z=0.090, IN_z=0.076 (499s)\n",
      "epoch=35, EUBO=-150.412, ELBO=-184.191, ESS=2.093, EX_eta=6.503, IN_eta=3.502, EX_z=0.098, IN_z=0.077 (500s)\n",
      "epoch=36, EUBO=-150.447, ELBO=-184.170, ESS=2.092, EX_eta=6.495, IN_eta=3.507, EX_z=0.089, IN_z=0.076 (500s)\n",
      "epoch=37, EUBO=-150.503, ELBO=-184.271, ESS=2.093, EX_eta=6.543, IN_eta=3.504, EX_z=0.091, IN_z=0.076 (500s)\n",
      "epoch=38, EUBO=-150.461, ELBO=-184.135, ESS=2.094, EX_eta=6.474, IN_eta=3.502, EX_z=0.091, IN_z=0.077 (500s)\n",
      "epoch=39, EUBO=-150.434, ELBO=-184.250, ESS=2.094, EX_eta=6.475, IN_eta=3.504, EX_z=0.101, IN_z=0.076 (500s)\n",
      "epoch=40, EUBO=-150.418, ELBO=-184.286, ESS=2.094, EX_eta=6.468, IN_eta=3.503, EX_z=0.092, IN_z=0.077 (500s)\n",
      "epoch=41, EUBO=-150.476, ELBO=-184.144, ESS=2.094, EX_eta=6.478, IN_eta=3.518, EX_z=0.101, IN_z=0.080 (500s)\n",
      "epoch=42, EUBO=-150.356, ELBO=-184.162, ESS=2.093, EX_eta=6.504, IN_eta=3.498, EX_z=0.099, IN_z=0.077 (499s)\n",
      "epoch=43, EUBO=-150.409, ELBO=-184.211, ESS=2.093, EX_eta=6.485, IN_eta=3.513, EX_z=0.102, IN_z=0.080 (500s)\n",
      "epoch=44, EUBO=-150.541, ELBO=-184.263, ESS=2.094, EX_eta=6.477, IN_eta=3.513, EX_z=0.093, IN_z=0.076 (499s)\n",
      "epoch=45, EUBO=-150.471, ELBO=-184.243, ESS=2.095, EX_eta=6.491, IN_eta=3.497, EX_z=0.104, IN_z=0.076 (500s)\n",
      "epoch=46, EUBO=-150.416, ELBO=-184.168, ESS=2.095, EX_eta=6.499, IN_eta=3.497, EX_z=0.099, IN_z=0.075 (500s)\n",
      "epoch=47, EUBO=-150.469, ELBO=-184.253, ESS=2.094, EX_eta=6.492, IN_eta=3.509, EX_z=0.143, IN_z=0.078 (500s)\n",
      "epoch=48, EUBO=-150.422, ELBO=-184.153, ESS=2.094, EX_eta=6.553, IN_eta=3.520, EX_z=0.090, IN_z=0.075 (499s)\n",
      "epoch=49, EUBO=-150.485, ELBO=-184.265, ESS=2.093, EX_eta=6.503, IN_eta=3.506, EX_z=0.090, IN_z=0.075 (500s)\n",
      "epoch=50, EUBO=-150.453, ELBO=-184.148, ESS=2.094, EX_eta=6.492, IN_eta=3.519, EX_z=0.098, IN_z=0.081 (500s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-139a7f5d4409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         batch_sigma2 = sigma2_true[batch_indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_ag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mopt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa990a790b89>\u001b[0m in \u001b[0;36mag\u001b[0;34m(x, Pi, N, K, D, num_samples, steps, batch_size)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mz_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mlog_p_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_joints_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa990a790b89>\u001b[0m in \u001b[0;36mE_step\u001b[0;34m(X, mus, precisions, N, D, K, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmus_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0msigma_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flog = open('results/log-' + PATH + '.txt', 'w+')\n",
    "flog.write('EUBO_ave, ELBO_ave, ESS, EUBO_ag, ELBO_ag, KLs_eta_ex_ag, KLs_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\\n')\n",
    "flog.close()\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    EUBO_ag = 0.0\n",
    "    ELBO_ag = 0.0\n",
    "    \n",
    "    ESS = 0.0\n",
    "    KL_eta_ex_ag = 0.0\n",
    "    KL_eta_in_ag = 0.0NUM_STATS\n",
    "    KL_z_ex_ag = 0.0\n",
    "    KL_z_in_ag = 0.0\n",
    "    \n",
    "    \n",
    "    for step in range(num_batches):\n",
    "        opt2.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "#         batch_Zs = Zs_true[batch_indices]\n",
    "#         batch_mus = mus_true[batch_indices]\n",
    "#         batch_sigma2 = sigma2_true[batch_indices]\n",
    "        batch_Xs = shuffler(batch_Xs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess, eubo_ag, elbo_ag, kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = ag(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        opt2.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "\n",
    "        EUBO_ag += eubo_ag.item()\n",
    "        ELBO_ag += elbo_ag.item()\n",
    "        \n",
    "        ESS += ess.item()\n",
    "        KL_eta_ex_ag += kl_eta_ex_ag.item()\n",
    "        KL_eta_in_ag += kl_eta_in_ag.item()\n",
    "        KL_z_ex_ag += kl_z_ex_ag.item()\n",
    "        KL_z_in_ag += kl_z_in_ag.item()\n",
    "\n",
    "            \n",
    "        flog = open('results/log-' + PATH + '.txt', 'a+')\n",
    "        flog.write(str(eubo.item()) + ', ' + str(elbo.item()) + ', ' + str(ess.item()) + ', ' + \n",
    "               str(eubo_ag.item()) + ', ' + str(elbo_ag.item()) + ', ' +\n",
    "               str(kl_eta_ex_ag.item()) + ', ' + str(kl_eta_in_ag.item()) + ', ' + str(kl_z_ex_ag.item()) + ', ' + str(kl_z_in_ag.item()) + '\\n')\n",
    "        flog.close()\n",
    "             \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    \n",
    "    EUBO_ag /= num_batches\n",
    "    ELBO_ag /= num_batches\n",
    "    \n",
    "    ESS /= num_batches\n",
    "    KL_eta_ex_ag /= num_batches\n",
    "    KL_eta_in_ag /= num_batches\n",
    "    KL_z_ex_ag /= num_batches\n",
    "    KL_z_in_ag /= num_batches\n",
    "\n",
    "    time_end = time.time()  \n",
    "    print('epoch=%d, EUBO=%.3f, ELBO=%.3f, ESS=%.3f, EX_eta=%.3f, IN_eta=%.3f, EX_z=%.3f, IN_z=%.3f (%ds)'\n",
    "            % (epoch, EUBO, ELBO, ESS,  KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EUBOs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7eb2989deb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    + str(KLs_eta_ex[i]) + str(KLs_eta_in[i]) + str(KLs_z_ex[i]) + str(KLs_z_in[i]) + '\\n')\n\u001b[1;32m      7\u001b[0m     \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEUBOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELBOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mESSs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_eta_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_eta_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_z_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_z_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EUBOs' is not defined"
     ]
    }
   ],
   "source": [
    "def save_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KL_z_ex, KL_z_in):\n",
    "    fout = open('results/logs-' + PATH +'.txt', 'w+')\n",
    "    fout.write('EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KL_z_ex, KL_z_in\\n')\n",
    "    for i in range(len(EUBOs)):\n",
    "        fout.write(str(EUBOs[i]) + ', ' + str(ELBOs[i]) + ', ' + str(ESSs[i]) \n",
    "                   + str(KLs_eta_ex[i]) + str(KLs_eta_in[i]) + str(KLs_z_ex[i]) + str(KLs_z_in[i]) + '\\n')\n",
    "    fout.close()\n",
    "save_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in, num_samples):\n",
    "    fig = plt.figure(figsize=(20, 30))\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax1.set_ylim([-220, -130])\n",
    "    ax1.legend(fontsize=18)\n",
    "    ##\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax2.plot(KLs_eta_ex, '#66b3ff', label='KLs_eta_ex')\n",
    "    ax2.plot(KLs_eta_in, '#ff9999', label='KLs_eta_in')\n",
    "    ax2.plot(KLs_z_ex, '#99ff99', label='KLs_z_ex')\n",
    "    ax2.plot(KLs_z_in, 'gold', label='KLs_z_in')   \n",
    "    ax2.plot(np.ones(len(KLs_z_in)) * 5, 'k', label='const=5.0')\n",
    "    ax2.legend(fontsize=18)\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax2.set_ylim([-1, 30])\n",
    "    ##\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax3.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax3.tick_params(labelsize=18)\n",
    "    ax3.set_xlabel('epochs (%d gradient steps per epoch)'  % num_batches, size=18)\n",
    "    ax3.legend()\n",
    "    plt.savefig('results/train-' + PATH + '.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 50\n",
    "def reverse(X, z, mus_prev, precisions_prev, N, D, K, batch_size):\n",
    "    data = torch.cat((X, z), dim=-1).view(batch_size*N, -1)\n",
    "    q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions = enc_global(data, K, D, 1, batch_size)  \n",
    "    log_q_eta =  Normal(q_mean[0], q_sigma[0]).log_prob(mus_prev).sum(-1).sum(-1) + Gamma(q_alpha, q_beta).log_prob(precisions_prev).sum(-1).sum(-1)## B\n",
    "    return log_q_eta\n",
    "\n",
    "def test(x, Pi, N, K, D, num_samples, steps, batch_size):\n",
    "    log_increment_weights = torch.zeros((steps, num_samples, batch_size))\n",
    "    log_p_joints = torch.zeros((steps, num_samples, batch_size))\n",
    "    log_qf = torch.zeros((steps-1, num_samples, batch_size))\n",
    "    log_qr = torch.zeros((steps-1, num_samples, batch_size))\n",
    "    Z_samples = torch.zeros((num_samples, batch_size, N, K))\n",
    "    mus_prevs = torch.zeros((num_samples, batch_size, K, D))\n",
    "    precisions_prevs = torch.zeros((num_samples, batch_size, K, D))\n",
    "    \n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            for l in range(num_samples):\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = Init_step(x, N, D, K, batch_size)\n",
    "                mus_prevs[l] = mus\n",
    "                precisions_prevs[l] = precisions\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                labels = z.nonzero()\n",
    "                log_p_z = cat(Pi).log_prob(z).sum(-1)\n",
    "                sigmas = 1. / torch.sqrt(precisions)\n",
    "                log_p_x = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1)\n",
    "                log_increment_weights[m, l] = log_p_x + log_p_z - log_q_z     \n",
    "                log_p_joints[m, l] = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                \n",
    "        else:\n",
    "            for l in range(num_samples):\n",
    "                z_prev = Z_samples[l]\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z_prev, N, D, K, batch_size)\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                log_p_joints[m, l] = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_qf[m-1, l] = log_q_eta + log_q_z\n",
    "                \n",
    "                mus_prev = mus_prevs[l]\n",
    "                precisions_prev = precisions_prevs[l]\n",
    "                \n",
    "                log_qr[m-1, l] = reverse(x, z, mus_prev, precisions_prev, N, D, K, batch_size)\n",
    "                log_p_joint = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_increment_weights[m, l] = log_p_joint - log_q_z - log_q_eta\n",
    "                mus_prevs[l] = mus\n",
    "                precisions_prevs[l] = precisions\n",
    "    detail_balances = log_p_joints[1:] - log_p_joints[:-1] -log_qf + log_qr\n",
    "    increment_weights = torch.exp(log_increment_weights - logsumexp(log_increment_weights, 1).unsqueeze(1).repeat(1, num_samples, 1)).detach()\n",
    "    esses = (1./ (increment_weights ** 2).sum(1))                   \n",
    "    log_last_weights = log_increment_weights[-1] ## S * B\n",
    "    ## EUBO and ELBO\n",
    "    eubos = torch.mul(increment_weights, log_increment_weights).sum(1).mean(-1)\n",
    "    elbos = log_increment_weights.mean(1).mean(-1)     \n",
    "    return eubos, elbos, esses, log_increment_weights, detail_balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_batch(num_seqs, N, K, D, batch_size):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    batch_indices = indices[0*batch_size : (0+1)*batch_size]\n",
    "    batch_Xs = Xs[batch_indices]\n",
    "    batch_Xs = shuffler(batch_Xs, N, K, D, batch_size)\n",
    "    return batch_Xs\n",
    "batch_Xs = sample_single_batch(num_seqs, N, K, D, BATCH_SIZE)\n",
    "eubo, elbo, ess, log_increment_weights, detail_balances = test(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detail_balances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BATCH_SIZE):\n",
    "    log_weights = log_increment_weights[:, :, i]\n",
    "    ess_stepwise = ess[:, i].data.numpy()\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax3 = fig.add_subplot(1,3,3)\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, -1)[:, None]).data.numpy()\n",
    "    db = detail_balances[:, :, i].mean(-1)\n",
    "    ax1.plot(db.data.numpy(), 'r-o')\n",
    "    ax1.set_ylim([-20, 20])\n",
    "    for s in range(NUM_SAMPLES):\n",
    "        ax2.plot(ess_stepwise, 'b-o')\n",
    "        ax3.plot(weights[:, s], 'g-o')\n",
    "        ax2.set_ylim([1.0, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(x, num_seqs, Pi, N, K, D, steps, batch_size):\n",
    "    LLs = [] \n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            mus, precisions, log_p_eta = inti_global(K, D, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "            zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "        else:\n",
    "            q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z, N, D, K, batch_size)\n",
    "            zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "            labels = z.nonzero()\n",
    "            sigmas = 1. / torch.sqrt(precisions)\n",
    "            ll = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1).mean()\n",
    "            LLs.append(ll.item())\n",
    "    E_precisions = q_alpha / q_beta\n",
    "    E_mus = q_mean\n",
    "    E_z = torch.argmax(zs_pi, dim=-1)\n",
    "\n",
    "    return z, mus, precisions, LLs, E_mus, E_precisions, E_z\n",
    "\n",
    "x,z_true = sample_single_batch(num_seqs, N, K, D, BATCH_SIZE)\n",
    "z, mus, precisions, LLs, E_mus, E_precisions, E_z = test(x, num_seqs, Pi, N, K, D, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_samples(Xs, Zs, mus, precisions, steps, batch_size):\n",
    "    colors = ['r', 'b', 'gold']\n",
    "    fig = plt.figure(figsize=(25,100))\n",
    "    for b in range(batch_size):\n",
    "        ax = fig.add_subplot(int(batch_size / 5), 5, b+1)\n",
    "        x = Xs[b].data.numpy()\n",
    "        z = Zs[b].data.numpy()\n",
    "        mu = mus[b].data.numpy()\n",
    "        precision = precisions[b].data.numpy()\n",
    "\n",
    "        covs = np.zeros((K, D, D))\n",
    "        assignments = z\n",
    "        for k in range(K):\n",
    "            covs[k] = np.diag(1. / precision[k])\n",
    "            xk = x[np.where(assignments == k)]\n",
    "            ax.scatter(xk[:, 0], xk[:, 1], c=colors[k])\n",
    "            plot_cov_ellipse(cov=covs[k], pos=mu[k], nstd=2, ax=ax, alpha=0.2, color=colors[k])\n",
    "        ax.set_ylim([-10, 10])\n",
    "        ax.set_xlim([-10, 10])\n",
    "    plt.savefig('results/modes' + PATH + '.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_final_samples(x, E_z, E_mus, E_precisions, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(LLs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
