{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from kls import *\n",
    "from torch._six import inf\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch import logsumexp\n",
    "import sys\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 10\n",
    "NUM_HIDDEN = 32\n",
    "STEPS = 10\n",
    "NUM_STATS = K+D*K+D*K\n",
    "NUM_LATENTS = D * K\n",
    "NUM_OBS_GLOBAL = D + K\n",
    "NUM_OBS_LOCAL = D + K*D + K*D\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "CUDA = False\n",
    "PATH = 'ag-correct-50000datasets-oneshot-%dsteps' % STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('gmm_dataset_uai2/sequences.npy')).float()\n",
    "# Zs_true = torch.from_numpy(np.load('gmm_dataset2/states.npy')).float()\n",
    "# mus_true = torch.from_numpy(np.load('gmm_dataset2/means.npy')).float()\n",
    "# sigma_true = torch.from_numpy(np.load('gmm_dataset2/covariances.npy')).float()\n",
    "Pi = torch.from_numpy(np.load('gmm_dataset_uai2/init.npy')).float()\n",
    "num_seqs = Xs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_init(nn.Module):\n",
    "    def __init__(self, num_obs=D,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "\n",
    "        self.sigmas_log_alpha = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.sigmas_log_beta = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "        self.mus_mean = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.mus_log_nu = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        q_alpha = torch.exp(self.sigmas_log_alpha(stats)).view(-1, K, D) ## B * K * D\n",
    "        q_beta = torch.exp(self.sigmas_log_beta(stats)).view(-1, K, D) ## B * K * D\n",
    "        precisions = Gamma(q_alpha, q_beta).sample((num_samples,)) ## S * B * K * D\n",
    "        \n",
    "        q_mean = self.mus_mean(stats).view(-1, K, D).unsqueeze(0).repeat(num_samples, 1, 1, 1)\n",
    "        q_nu = torch.exp(self.mus_log_nu(stats).view(-1, K, D))\n",
    "        q_sigma = torch.sqrt(1. / (q_nu.unsqueeze(0).repeat(num_samples, 1, 1, 1) * precisions))\n",
    "        mus = Normal(q_mean, q_sigma).sample()  \n",
    "        return q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions ## mus_mean and mus_sigma are S * B * K * D\n",
    "    \n",
    "class Encoder_global(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS_GLOBAL,\n",
    "                       num_stats=NUM_STATS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_stats = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "\n",
    "        self.sigmas_log_alpha = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.sigmas_log_beta = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "\n",
    "        self.mus_mean = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.mus_log_nu = nn.Sequential(\n",
    "            nn.Linear(num_stats, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, K, D, num_samples, batch_size):\n",
    "        stats = self.enc_stats(obs).view(batch_size, N, -1).sum(1)\n",
    "        q_alpha = torch.exp(self.sigmas_log_alpha(stats)).view(-1, K, D) ## B * K * D\n",
    "        q_beta = torch.exp(self.sigmas_log_beta(stats)).view(-1, K, D) ## B * K * D\n",
    "        precisions = Gamma(q_alpha, q_beta).sample((num_samples,)) ## S * B * K * D\n",
    "        \n",
    "        q_mean = self.mus_mean(stats).view(-1, K, D).unsqueeze(0).repeat(num_samples, 1, 1, 1)\n",
    "        q_nu = torch.exp(self.mus_log_nu(stats).view(-1, K, D))\n",
    "        q_sigma = torch.sqrt(1. / (q_nu.unsqueeze(0).repeat(num_samples, 1, 1, 1) * precisions))\n",
    "        mus = Normal(q_mean, q_sigma).sample()  \n",
    "        return q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions ## mus_mean and mus_sigma are S * B * K * D\n",
    "    \n",
    "class Encoder_local(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS_LOCAL,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=K):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_onehot = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_latents),\n",
    "            nn.Softmax(-1))\n",
    "        \n",
    "    def forward(self, obs, N, K, D, num_samples, batch_size):\n",
    "        zs_pi = self.enc_onehot(obs).view(batch_size, N, K)\n",
    "        zs = cat(zs_pi).sample((num_samples,))\n",
    "        log_qz = cat(zs_pi).log_prob(zs).view(num_samples, batch_size, -1).sum(-1) ## S * B\n",
    "        zs = zs.view(num_samples, batch_size, -1, K) ## S * B * N * K\n",
    "        return zs_pi, zs, log_qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 1e-1)     \n",
    "        \n",
    "def initialize():\n",
    "    enc_init = Encoder_init()\n",
    "    enc_global = Encoder_global()\n",
    "    enc_local = Encoder_local()\n",
    "    enc_global.apply(weights_init)\n",
    "#     enc_init.apply(weights_init)\n",
    "    optimizer =  torch.optim.Adam(list(enc_init.parameters()) + list(enc_global.parameters()) + list(enc_local.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))    \n",
    "    return enc_init, enc_global, enc_local, optimizer\n",
    "enc_init, enc_global, enc_local, optimizer = initialize()\n",
    "# enc_init.load_state_dict(torch.load('models/global-enc-uai-oneshot-all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = torch.zeros((BATCH_SIZE, K, D))\n",
    "prior_nu = torch.ones((BATCH_SIZE, K, D)) * 0.3\n",
    "prior_alpha = torch.ones((BATCH_SIZE, K, D)) * 3.0\n",
    "prior_beta = torch.ones((BATCH_SIZE, K, D)) * 3.0\n",
    "\n",
    "def log_joints_gmm(X, Z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size):\n",
    "    log_probs = torch.zeros(batch_size).float()\n",
    "    ## priors on mus and sigmas size B\n",
    "    log_probs = log_probs + Gamma(prior_alpha, prior_beta).log_prob(precisions).sum(-1).sum(-1)\n",
    "    prior_sigma = 1. / torch.sqrt(prior_nu * precisions)\n",
    "    log_probs = log_probs + Normal(prior_mean, prior_sigma).log_prob(mus).sum(-1).sum(-1)\n",
    "    ## Z B-by-T-by-K\n",
    "    log_probs = log_probs + cat(Pi).log_prob(Z).sum(-1)\n",
    "    labels = Z.nonzero()\n",
    "    sigmas = 1. / torch.sqrt(precisions)\n",
    "    log_probs = log_probs + Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), \n",
    "                                   sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(X).sum(-1).sum(-1)\n",
    "    return log_probs\n",
    "\n",
    "def post_global(Xs, Zs, prior_mean, prior_nu, prior_alpha, prior_beta, N, K, D, batch_size):\n",
    "    stat1 = Zs.sum(1).unsqueeze(-1).repeat(1, 1, D) ## B * K * D\n",
    "    xz_nk = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), Xs.unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)) # B*N*K*D\n",
    "    stat2 = xz_nk.sum(1) ## B*K*D\n",
    "    stat3 = torch.mul(Zs.unsqueeze(-1).repeat(1, 1, 1, D), torch.mul(Xs, Xs).unsqueeze(-1).repeat(1, 1, 1, K).transpose(-1, -2)).sum(1) \n",
    "    stat1_nonzero = stat1\n",
    "    stat1_nonzero[stat1_nonzero == 0.0] = 1.0\n",
    "    x_bar = stat2 / stat1\n",
    "    posterior_beta = prior_beta + (stat3 - (stat2 ** 2) / stat1_nonzero) / 2. + (stat1 * prior_nu / (stat1 + prior_nu)) * ((prior_nu**2) + x_bar**2 - 2 * x_bar *  prior_nu) / 2.\n",
    "    posterior_nu = prior_nu + stat1\n",
    "    posterior_mean = (prior_mean * prior_nu + stat2) / (prior_nu + stat1) \n",
    "    posterior_alpha = prior_alpha + (stat1 / 2.)\n",
    "#     posterior_sigma = torch.sqrt(posterior_nu * (posterior_beta / posterior_alpha))\n",
    "    return posterior_mean, posterior_nu, posterior_alpha, posterior_beta\n",
    "\n",
    "def post_local(Xs, Pi, mus, precisions, N, K, D, batch_size):\n",
    "    sigma = 1. / torch.sqrt(precisions)\n",
    "    mus_expand = mus.unsqueeze(2).repeat(1, 1, N, 1)\n",
    "    sigma_expand = sigma.unsqueeze(2).repeat(1, 1, N, 1)\n",
    "    Xs_expand = Xs.unsqueeze(1).repeat(1, K, 1, 1)\n",
    "    log_gammas = Normal(mus_expand, sigma_expand).log_prob(Xs_expand).sum(-1).transpose(-1, -2) # B * N * K\n",
    "    log_pis = log_gammas - logsumexp(log_gammas, dim=-1).unsqueeze(-1)\n",
    "    return log_pis\n",
    "\n",
    "# def inti_global(K, D, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size):\n",
    "#     precisions = Gamma(prior_alpha, prior_beta).sample()\n",
    "#     prior_sigma = 1. / torch.sqrt(prior_nu * precisions)\n",
    "#     mus = Normal(prior_mean, prior_sigma).sample()\n",
    "#     ## log prior size B\n",
    "#     log_p =  Normal(prior_mean, prior_sigma).log_prob(mus).sum(-1).sum(-1) + Gamma(prior_alpha, prior_beta).log_prob(precisions).sum(-1).sum(-1)\n",
    "#     return mus, precisions, log_p\n",
    "def Init_step(X, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size):\n",
    "    data = X.view(batch_size*N, -1)\n",
    "    \n",
    "    q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions = enc_init(data, K, D, 1, batch_size) \n",
    "    prior_sigma = 1. / torch.sqrt(prior_nu * precisions)\n",
    "    log_q_eta =  Normal(q_mean[0], q_sigma[0]).log_prob(mus[0]).sum(-1).sum(-1) + Gamma(q_alpha, q_beta).log_prob(precisions[0]).sum(-1).sum(-1)## B\n",
    "    log_p_eta = Normal(prior_mean, prior_sigma).log_prob(mus[0]).sum(-1).sum(-1) + Gamma(prior_alpha, prior_beta).log_prob(precisions[0]).sum(-1).sum(-1)## B\n",
    "    return q_mean[0], q_nu, q_alpha, q_beta, q_sigma[0], mus[0], precisions[0], log_q_eta, log_p_eta\n",
    "\n",
    "def E_step(X, mus, precisions, N, D, K, batch_size):\n",
    "    mus_flat = mus.view(-1, K*D).unsqueeze(1).repeat(1, N, 1)\n",
    "    sigma = 1. / torch.sqrt(precisions)\n",
    "    sigma_flat = sigma.view(-1, K*D).unsqueeze(1).repeat(1, N, 1)\n",
    "    data = torch.cat((X, mus_flat, sigma_flat), -1).view(batch_size*N, -1)\n",
    "    zs_pi, zs, log_q_z = enc_local(data, N, K, D, 1, batch_size)\n",
    "    return zs_pi, zs[0], log_q_z[0]\n",
    "\n",
    "def M_step(X, z, N, D, K, batch_size):\n",
    "    data = torch.cat((X, z), dim=-1).view(batch_size*N, -1)\n",
    "    q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions = enc_global(data, K, D, 1, batch_size)  \n",
    "    log_q_eta =  Normal(q_mean[0], q_sigma[0]).log_prob(mus[0]).sum(-1).sum(-1) + Gamma(q_alpha, q_beta).log_prob(precisions[0]).sum(-1).sum(-1)## B\n",
    "    return q_mean[0], q_nu, q_alpha, q_beta, q_sigma[0], mus[0], precisions[0], log_q_eta\n",
    "\n",
    "def kls_step(x, z, q_mean, q_nu, q_alpha, q_beta, zs_pi, mus, precisions, N, K, D, batch_size):\n",
    "    p_mean, p_nu, p_alpha, p_beta = post_global(x, z, prior_mean, prior_nu, prior_alpha, prior_beta, N, K, D, batch_size)\n",
    "    kl_eta_ex, kl_eta_in = kls_NGs(p_mean, p_nu, p_alpha, p_beta, q_mean, q_nu, q_alpha, q_beta)\n",
    "    p_logits = post_local(x, Pi, mus, precisions, N, K, D, batch_size)\n",
    "    kl_z_ex, kl_z_in = kls_cats(p_logits, torch.log(zs_pi))\n",
    "    return kl_eta_ex, kl_eta_in, kl_z_ex, kl_z_in\n",
    "\n",
    "def ag(x, Pi, N, K, D, num_samples, steps, batch_size):\n",
    "    \"\"\"\n",
    "    train both encoders\n",
    "    rws gradient estimator\n",
    "    sis sampling scheme\n",
    "    no resampling\n",
    "    \"\"\"\n",
    "    kls_eta_ex_os = torch.zeros((num_samples, batch_size))\n",
    "    kls_eta_in_os = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_ex_os = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_in_os = torch.zeros((num_samples, batch_size))\n",
    "    \n",
    "    kls_eta_ex_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_eta_in_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_ex_ag = torch.zeros((num_samples, batch_size))\n",
    "    kls_z_in_ag = torch.zeros((num_samples, batch_size))\n",
    "    ##\n",
    "    log_increment_weights = torch.zeros((steps, num_samples, batch_size))\n",
    "    Z_samples = torch.zeros((num_samples, batch_size, N, K))\n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            for l in range(num_samples):\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta, log_p_eta = Init_step(x, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                labels = z.nonzero()\n",
    "                log_p_z = cat(Pi).log_prob(z).sum(-1)\n",
    "                sigmas = 1. / torch.sqrt(precisions)\n",
    "                log_p_x = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1)\n",
    "                log_increment_weights[m, l] = log_p_x + log_p_z + log_p_eta - log_q_z - log_q_eta\n",
    "                kl_eta_ex_os, kl_eta_in_os, kl_z_ex_os, kl_z_in_os = kls_step(x, z, q_mean, q_nu, q_alpha, q_beta, zs_pi, mus, precisions, N, K, D, batch_size)\n",
    "                kls_eta_ex_os[l] = kl_eta_ex_os\n",
    "                kls_eta_in_os[l] = kl_eta_in_os\n",
    "                kls_z_ex_os[l] = kl_z_ex_os\n",
    "                kls_z_in_os[l] = kl_z_in_os\n",
    "        else:\n",
    "            for l in range(num_samples):\n",
    "                z_prev = Z_samples[l]\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z_prev, N, D, K, batch_size)\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                log_p_joint = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_increment_weights[m, l] = log_p_joint - log_q_z - log_q_eta\n",
    "                if m == (steps-1):\n",
    "                    kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = kls_step(x, z, q_mean, q_nu, q_alpha, q_beta, zs_pi, mus, precisions, N, K, D, batch_size)\n",
    "                    kls_eta_ex_ag[l] = kl_eta_ex_ag\n",
    "                    kls_eta_in_ag[l] = kl_eta_in_ag\n",
    "                    kls_z_ex_ag[l] = kl_z_ex_ag\n",
    "                    kls_z_in_ag[l] = kl_z_in_ag\n",
    "                    \n",
    "    increment_weights = torch.exp(log_increment_weights - logsumexp(log_increment_weights, 1).unsqueeze(1).repeat(1, num_samples, 1)).detach()\n",
    "    ess = (1./ (increment_weights ** 2).sum(1)).mean(0).mean()   \n",
    "#     ess = (1./ (increment_weights ** 2).sum(1)).mean(0).mean() \n",
    "    ## EUBO and ELBO\n",
    "    eubos = torch.mul(increment_weights, log_increment_weights).sum(1)\n",
    "    eubo = eubos.mean(0).mean()\n",
    "    \n",
    "    elbos = log_increment_weights.mean(1)\n",
    "    elbo = elbos.mean(0).mean()\n",
    "    ## eubo and elbo at init step\n",
    "    eubo_os = eubos[0].mean()\n",
    "    elbo_os = elbos[0].mean()\n",
    "    ## eubo and elbo at init step\n",
    "    eubo_ag = eubos[-1].mean()\n",
    "    elbo_ag = elbos[-1].mean()\n",
    "    ## KL at init steps\n",
    "    oneshot_weights = increment_weights[0]\n",
    "    KL_eta_ex_os = torch.mul(oneshot_weights, kls_eta_ex_os).sum(0).mean()\n",
    "    KL_eta_in_os = torch.mul(oneshot_weights, kls_eta_in_os).sum(0).mean()\n",
    "    KL_z_ex_os = torch.mul(oneshot_weights, kls_z_ex_os).sum(0).mean()\n",
    "    KL_z_in_os = torch.mul(oneshot_weights, kls_z_in_os).sum(0).mean()       \n",
    "    ## KL after 10 steps\n",
    "    final_weights = increment_weights[-1]\n",
    "    KL_eta_ex_ag = torch.mul(final_weights, kls_eta_ex_ag).sum(0).mean()\n",
    "    KL_eta_in_ag = torch.mul(final_weights, kls_eta_in_ag).sum(0).mean()\n",
    "    KL_z_ex_ag = torch.mul(final_weights, kls_z_ex_ag).sum(0).mean()\n",
    "    KL_z_in_ag = torch.mul(final_weights, kls_z_in_ag).sum(0).mean()  \n",
    "    \n",
    "    return eubo, elbo, ess, eubo_os, elbo_os, eubo_ag, elbo_ag, KL_eta_ex_os, KL_eta_in_os, KL_z_ex_os, KL_z_in_os, KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\n",
    "\n",
    "def shuffler(batch_Xs, N, K, D, batch_size):\n",
    "    indices = torch.cat([torch.randperm(N).unsqueeze(0) for b in range(batch_size)])\n",
    "    indices_Xs = indices.unsqueeze(-1).repeat(1, 1, D)\n",
    "    return torch.gather(batch_Xs, 1, indices_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-169.300, ELBO=-197.125, ESS=1.331, EX_eta=46.324, IN_eta=22.929, EX_z=7.031, IN_z=3.846 (415s)\n",
      "epoch=1, EUBO=-151.925, ELBO=-167.955, ESS=1.450, EX_eta=31.279, IN_eta=15.579, EX_z=2.194, IN_z=1.698 (410s)\n",
      "epoch=2, EUBO=-148.385, ELBO=-163.695, ESS=1.493, EX_eta=28.900, IN_eta=13.282, EX_z=1.668, IN_z=1.172 (409s)\n",
      "epoch=3, EUBO=-145.321, ELBO=-159.737, ESS=1.557, EX_eta=22.963, IN_eta=10.703, EX_z=1.339, IN_z=0.828 (409s)\n",
      "epoch=4, EUBO=-143.291, ELBO=-156.902, ESS=1.622, EX_eta=18.942, IN_eta=8.923, EX_z=1.083, IN_z=0.625 (409s)\n",
      "epoch=5, EUBO=-142.022, ELBO=-154.731, ESS=1.686, EX_eta=16.437, IN_eta=7.768, EX_z=0.915, IN_z=0.522 (409s)\n",
      "epoch=6, EUBO=-141.120, ELBO=-152.979, ESS=1.752, EX_eta=14.522, IN_eta=6.884, EX_z=0.794, IN_z=0.430 (408s)\n",
      "epoch=7, EUBO=-140.480, ELBO=-151.716, ESS=1.812, EX_eta=13.099, IN_eta=6.263, EX_z=0.657, IN_z=0.355 (408s)\n",
      "epoch=8, EUBO=-140.069, ELBO=-150.936, ESS=1.855, EX_eta=12.181, IN_eta=5.851, EX_z=0.595, IN_z=0.302 (408s)\n",
      "epoch=9, EUBO=-139.774, ELBO=-150.366, ESS=1.891, EX_eta=11.495, IN_eta=5.591, EX_z=0.557, IN_z=0.261 (408s)\n",
      "epoch=10, EUBO=-139.580, ELBO=-150.018, ESS=1.915, EX_eta=11.235, IN_eta=5.415, EX_z=0.460, IN_z=0.235 (408s)\n",
      "epoch=11, EUBO=-139.417, ELBO=-149.682, ESS=1.937, EX_eta=10.883, IN_eta=5.284, EX_z=0.431, IN_z=0.212 (408s)\n",
      "epoch=12, EUBO=-139.290, ELBO=-149.451, ESS=1.952, EX_eta=10.610, IN_eta=5.160, EX_z=0.405, IN_z=0.199 (407s)\n",
      "epoch=13, EUBO=-139.186, ELBO=-149.308, ESS=1.967, EX_eta=10.409, IN_eta=5.055, EX_z=0.393, IN_z=0.184 (407s)\n",
      "epoch=14, EUBO=-139.089, ELBO=-149.024, ESS=1.984, EX_eta=10.261, IN_eta=4.989, EX_z=0.373, IN_z=0.173 (407s)\n",
      "epoch=15, EUBO=-139.013, ELBO=-148.822, ESS=1.997, EX_eta=10.009, IN_eta=4.897, EX_z=0.340, IN_z=0.165 (406s)\n",
      "epoch=16, EUBO=-138.964, ELBO=-148.703, ESS=2.006, EX_eta=9.962, IN_eta=4.856, EX_z=0.319, IN_z=0.160 (407s)\n",
      "epoch=17, EUBO=-138.904, ELBO=-148.641, ESS=2.017, EX_eta=9.856, IN_eta=4.791, EX_z=0.287, IN_z=0.156 (406s)\n",
      "epoch=18, EUBO=-138.856, ELBO=-148.458, ESS=2.023, EX_eta=9.799, IN_eta=4.747, EX_z=0.280, IN_z=0.149 (408s)\n",
      "epoch=19, EUBO=-138.808, ELBO=-148.326, ESS=2.030, EX_eta=9.604, IN_eta=4.712, EX_z=0.280, IN_z=0.144 (408s)\n",
      "epoch=20, EUBO=-138.779, ELBO=-148.263, ESS=2.039, EX_eta=9.561, IN_eta=4.664, EX_z=0.299, IN_z=0.141 (407s)\n",
      "epoch=21, EUBO=-138.747, ELBO=-148.137, ESS=2.050, EX_eta=9.465, IN_eta=4.622, EX_z=0.268, IN_z=0.137 (407s)\n",
      "epoch=22, EUBO=-138.693, ELBO=-148.068, ESS=2.054, EX_eta=9.363, IN_eta=4.587, EX_z=0.267, IN_z=0.135 (407s)\n",
      "epoch=23, EUBO=-138.665, ELBO=-148.027, ESS=2.058, EX_eta=9.382, IN_eta=4.579, EX_z=0.270, IN_z=0.134 (407s)\n",
      "epoch=24, EUBO=-138.635, ELBO=-147.984, ESS=2.067, EX_eta=9.312, IN_eta=4.532, EX_z=0.336, IN_z=0.129 (406s)\n",
      "epoch=25, EUBO=-138.631, ELBO=-147.805, ESS=2.070, EX_eta=9.145, IN_eta=4.527, EX_z=0.242, IN_z=0.126 (407s)\n",
      "epoch=26, EUBO=-138.587, ELBO=-147.716, ESS=2.078, EX_eta=9.114, IN_eta=4.481, EX_z=0.242, IN_z=0.126 (407s)\n",
      "epoch=27, EUBO=-138.564, ELBO=-147.699, ESS=2.084, EX_eta=9.140, IN_eta=4.466, EX_z=0.223, IN_z=0.122 (407s)\n",
      "epoch=28, EUBO=-138.557, ELBO=-147.606, ESS=2.090, EX_eta=9.035, IN_eta=4.437, EX_z=0.229, IN_z=0.119 (407s)\n",
      "epoch=29, EUBO=-138.527, ELBO=-147.509, ESS=2.091, EX_eta=8.998, IN_eta=4.430, EX_z=0.229, IN_z=0.117 (407s)\n",
      "epoch=30, EUBO=-138.492, ELBO=-147.408, ESS=2.102, EX_eta=8.848, IN_eta=4.394, EX_z=0.223, IN_z=0.114 (407s)\n",
      "epoch=31, EUBO=-138.507, ELBO=-147.409, ESS=2.095, EX_eta=8.993, IN_eta=4.408, EX_z=0.221, IN_z=0.114 (406s)\n",
      "epoch=32, EUBO=-138.470, ELBO=-147.368, ESS=2.102, EX_eta=8.845, IN_eta=4.377, EX_z=0.238, IN_z=0.111 (407s)\n",
      "epoch=33, EUBO=-138.444, ELBO=-147.326, ESS=2.109, EX_eta=8.852, IN_eta=4.360, EX_z=0.220, IN_z=0.111 (406s)\n",
      "epoch=34, EUBO=-138.429, ELBO=-147.252, ESS=2.105, EX_eta=8.916, IN_eta=4.373, EX_z=0.214, IN_z=0.109 (407s)\n",
      "epoch=35, EUBO=-138.428, ELBO=-147.228, ESS=2.113, EX_eta=8.824, IN_eta=4.336, EX_z=0.217, IN_z=0.107 (406s)\n",
      "epoch=36, EUBO=-138.406, ELBO=-147.163, ESS=2.119, EX_eta=8.799, IN_eta=4.316, EX_z=0.196, IN_z=0.105 (406s)\n",
      "epoch=37, EUBO=-138.399, ELBO=-147.123, ESS=2.122, EX_eta=8.779, IN_eta=4.301, EX_z=0.219, IN_z=0.105 (407s)\n",
      "epoch=38, EUBO=-138.385, ELBO=-147.084, ESS=2.126, EX_eta=8.728, IN_eta=4.299, EX_z=0.195, IN_z=0.103 (408s)\n",
      "epoch=39, EUBO=-138.367, ELBO=-147.065, ESS=2.129, EX_eta=8.692, IN_eta=4.278, EX_z=0.204, IN_z=0.104 (406s)\n",
      "epoch=40, EUBO=-138.348, ELBO=-146.905, ESS=2.133, EX_eta=8.708, IN_eta=4.284, EX_z=0.203, IN_z=0.100 (407s)\n",
      "epoch=41, EUBO=-138.353, ELBO=-146.946, ESS=2.139, EX_eta=8.637, IN_eta=4.267, EX_z=0.218, IN_z=0.098 (407s)\n",
      "epoch=42, EUBO=-138.342, ELBO=-146.917, ESS=2.139, EX_eta=8.598, IN_eta=4.254, EX_z=0.216, IN_z=0.097 (407s)\n",
      "epoch=43, EUBO=-138.330, ELBO=-146.818, ESS=2.143, EX_eta=8.565, IN_eta=4.251, EX_z=0.216, IN_z=0.097 (417s)\n",
      "epoch=44, EUBO=-138.314, ELBO=-146.757, ESS=2.150, EX_eta=8.559, IN_eta=4.234, EX_z=0.189, IN_z=0.094 (406s)\n",
      "epoch=45, EUBO=-138.293, ELBO=-146.728, ESS=2.150, EX_eta=8.452, IN_eta=4.206, EX_z=0.178, IN_z=0.094 (407s)\n",
      "epoch=46, EUBO=-138.286, ELBO=-146.683, ESS=2.154, EX_eta=8.444, IN_eta=4.185, EX_z=0.188, IN_z=0.090 (407s)\n",
      "epoch=47, EUBO=-138.269, ELBO=-146.593, ESS=2.159, EX_eta=8.450, IN_eta=4.187, EX_z=0.215, IN_z=0.091 (406s)\n",
      "epoch=48, EUBO=-138.268, ELBO=-146.563, ESS=2.160, EX_eta=8.360, IN_eta=4.179, EX_z=0.189, IN_z=0.089 (407s)\n",
      "epoch=49, EUBO=-138.246, ELBO=-146.526, ESS=2.170, EX_eta=8.304, IN_eta=4.146, EX_z=0.170, IN_z=0.089 (407s)\n",
      "epoch=50, EUBO=-138.234, ELBO=-146.517, ESS=2.170, EX_eta=8.344, IN_eta=4.136, EX_z=0.182, IN_z=0.088 (407s)\n",
      "epoch=51, EUBO=-138.236, ELBO=-146.399, ESS=2.176, EX_eta=8.320, IN_eta=4.142, EX_z=0.177, IN_z=0.088 (406s)\n",
      "epoch=52, EUBO=-138.224, ELBO=-146.383, ESS=2.178, EX_eta=8.277, IN_eta=4.126, EX_z=0.163, IN_z=0.087 (406s)\n",
      "epoch=53, EUBO=-138.215, ELBO=-146.344, ESS=2.183, EX_eta=8.354, IN_eta=4.141, EX_z=0.173, IN_z=0.086 (407s)\n",
      "epoch=54, EUBO=-138.207, ELBO=-146.355, ESS=2.186, EX_eta=8.273, IN_eta=4.108, EX_z=0.206, IN_z=0.085 (407s)\n",
      "epoch=55, EUBO=-138.190, ELBO=-146.265, ESS=2.195, EX_eta=8.152, IN_eta=4.089, EX_z=0.188, IN_z=0.085 (406s)\n",
      "epoch=56, EUBO=-138.196, ELBO=-146.257, ESS=2.196, EX_eta=8.160, IN_eta=4.074, EX_z=0.165, IN_z=0.083 (407s)\n",
      "epoch=57, EUBO=-138.176, ELBO=-146.205, ESS=2.200, EX_eta=8.136, IN_eta=4.075, EX_z=0.158, IN_z=0.084 (407s)\n",
      "epoch=58, EUBO=-138.178, ELBO=-146.221, ESS=2.202, EX_eta=8.125, IN_eta=4.050, EX_z=0.171, IN_z=0.082 (407s)\n",
      "epoch=59, EUBO=-138.161, ELBO=-146.173, ESS=2.208, EX_eta=8.030, IN_eta=4.041, EX_z=0.165, IN_z=0.084 (406s)\n",
      "epoch=60, EUBO=-138.163, ELBO=-146.134, ESS=2.211, EX_eta=8.115, IN_eta=4.032, EX_z=0.173, IN_z=0.083 (406s)\n",
      "epoch=61, EUBO=-138.143, ELBO=-146.052, ESS=2.217, EX_eta=8.015, IN_eta=4.015, EX_z=0.170, IN_z=0.083 (406s)\n",
      "epoch=62, EUBO=-138.135, ELBO=-146.020, ESS=2.220, EX_eta=7.957, IN_eta=4.012, EX_z=0.169, IN_z=0.082 (407s)\n",
      "epoch=63, EUBO=-138.142, ELBO=-146.015, ESS=2.227, EX_eta=7.902, IN_eta=3.980, EX_z=0.184, IN_z=0.081 (407s)\n",
      "epoch=64, EUBO=-138.132, ELBO=-146.034, ESS=2.232, EX_eta=7.942, IN_eta=3.991, EX_z=0.231, IN_z=0.081 (407s)\n",
      "epoch=65, EUBO=-138.110, ELBO=-145.957, ESS=2.236, EX_eta=7.976, IN_eta=3.991, EX_z=0.173, IN_z=0.080 (407s)\n",
      "epoch=66, EUBO=-138.099, ELBO=-145.920, ESS=2.239, EX_eta=7.832, IN_eta=3.944, EX_z=0.171, IN_z=0.079 (407s)\n",
      "epoch=67, EUBO=-138.114, ELBO=-145.882, ESS=2.242, EX_eta=7.817, IN_eta=3.945, EX_z=0.170, IN_z=0.079 (407s)\n",
      "epoch=68, EUBO=-138.096, ELBO=-145.877, ESS=2.252, EX_eta=7.852, IN_eta=3.940, EX_z=0.154, IN_z=0.079 (407s)\n",
      "epoch=69, EUBO=-138.070, ELBO=-145.802, ESS=2.259, EX_eta=7.804, IN_eta=3.919, EX_z=0.194, IN_z=0.078 (406s)\n",
      "epoch=70, EUBO=-138.089, ELBO=-145.763, ESS=2.263, EX_eta=7.728, IN_eta=3.903, EX_z=0.156, IN_z=0.077 (406s)\n",
      "epoch=71, EUBO=-138.065, ELBO=-145.762, ESS=2.269, EX_eta=7.616, IN_eta=3.890, EX_z=0.155, IN_z=0.078 (406s)\n",
      "epoch=72, EUBO=-138.067, ELBO=-145.716, ESS=2.279, EX_eta=7.650, IN_eta=3.864, EX_z=0.162, IN_z=0.076 (407s)\n",
      "epoch=73, EUBO=-138.066, ELBO=-145.722, ESS=2.277, EX_eta=7.637, IN_eta=3.869, EX_z=0.155, IN_z=0.077 (406s)\n",
      "epoch=74, EUBO=-138.064, ELBO=-145.744, ESS=2.286, EX_eta=7.668, IN_eta=3.865, EX_z=0.147, IN_z=0.076 (406s)\n",
      "epoch=75, EUBO=-138.052, ELBO=-145.749, ESS=2.290, EX_eta=7.552, IN_eta=3.831, EX_z=0.152, IN_z=0.076 (406s)\n",
      "epoch=76, EUBO=-138.033, ELBO=-145.690, ESS=2.292, EX_eta=7.623, IN_eta=3.839, EX_z=0.219, IN_z=0.075 (406s)\n",
      "epoch=77, EUBO=-138.030, ELBO=-145.659, ESS=2.301, EX_eta=7.541, IN_eta=3.823, EX_z=0.157, IN_z=0.074 (406s)\n",
      "epoch=78, EUBO=-138.039, ELBO=-145.669, ESS=2.306, EX_eta=7.464, IN_eta=3.805, EX_z=0.145, IN_z=0.074 (407s)\n",
      "epoch=79, EUBO=-138.027, ELBO=-145.690, ESS=2.307, EX_eta=7.522, IN_eta=3.817, EX_z=0.163, IN_z=0.075 (406s)\n",
      "epoch=80, EUBO=-138.030, ELBO=-145.670, ESS=2.308, EX_eta=7.525, IN_eta=3.800, EX_z=0.189, IN_z=0.074 (406s)\n",
      "epoch=81, EUBO=-138.012, ELBO=-145.551, ESS=2.319, EX_eta=7.469, IN_eta=3.780, EX_z=0.157, IN_z=0.073 (407s)\n",
      "epoch=82, EUBO=-138.009, ELBO=-145.542, ESS=2.326, EX_eta=7.443, IN_eta=3.759, EX_z=0.155, IN_z=0.072 (407s)\n",
      "epoch=83, EUBO=-138.016, ELBO=-145.534, ESS=2.325, EX_eta=7.412, IN_eta=3.766, EX_z=0.175, IN_z=0.072 (407s)\n",
      "epoch=84, EUBO=-138.012, ELBO=-145.471, ESS=2.331, EX_eta=7.383, IN_eta=3.749, EX_z=0.170, IN_z=0.072 (406s)\n",
      "epoch=85, EUBO=-138.005, ELBO=-145.465, ESS=2.339, EX_eta=7.336, IN_eta=3.744, EX_z=0.197, IN_z=0.071 (406s)\n",
      "epoch=86, EUBO=-138.013, ELBO=-145.443, ESS=2.338, EX_eta=7.372, IN_eta=3.741, EX_z=0.201, IN_z=0.071 (407s)\n",
      "epoch=87, EUBO=-138.011, ELBO=-145.454, ESS=2.346, EX_eta=7.337, IN_eta=3.713, EX_z=0.151, IN_z=0.070 (407s)\n",
      "epoch=88, EUBO=-137.990, ELBO=-145.347, ESS=2.353, EX_eta=7.367, IN_eta=3.710, EX_z=0.170, IN_z=0.070 (406s)\n",
      "epoch=89, EUBO=-137.979, ELBO=-145.272, ESS=2.359, EX_eta=7.250, IN_eta=3.683, EX_z=0.179, IN_z=0.070 (406s)\n",
      "epoch=90, EUBO=-137.989, ELBO=-145.329, ESS=2.360, EX_eta=7.266, IN_eta=3.693, EX_z=0.157, IN_z=0.071 (406s)\n",
      "epoch=91, EUBO=-137.979, ELBO=-145.340, ESS=2.363, EX_eta=7.239, IN_eta=3.672, EX_z=0.153, IN_z=0.071 (406s)\n",
      "epoch=92, EUBO=-137.984, ELBO=-145.317, ESS=2.365, EX_eta=7.206, IN_eta=3.693, EX_z=0.162, IN_z=0.071 (406s)\n",
      "epoch=93, EUBO=-137.988, ELBO=-145.347, ESS=2.372, EX_eta=7.239, IN_eta=3.658, EX_z=0.190, IN_z=0.070 (405s)\n",
      "epoch=94, EUBO=-137.996, ELBO=-145.191, ESS=2.380, EX_eta=7.119, IN_eta=3.660, EX_z=0.191, IN_z=0.070 (406s)\n",
      "epoch=95, EUBO=-137.981, ELBO=-145.248, ESS=2.385, EX_eta=7.149, IN_eta=3.651, EX_z=0.131, IN_z=0.069 (407s)\n",
      "epoch=96, EUBO=-137.989, ELBO=-145.214, ESS=2.389, EX_eta=7.160, IN_eta=3.639, EX_z=0.175, IN_z=0.070 (406s)\n",
      "epoch=97, EUBO=-137.987, ELBO=-145.249, ESS=2.386, EX_eta=7.110, IN_eta=3.647, EX_z=0.151, IN_z=0.069 (407s)\n",
      "epoch=98, EUBO=-137.985, ELBO=-145.199, ESS=2.394, EX_eta=7.129, IN_eta=3.640, EX_z=0.153, IN_z=0.068 (406s)\n",
      "epoch=99, EUBO=-137.976, ELBO=-145.210, ESS=2.400, EX_eta=7.075, IN_eta=3.604, EX_z=0.165, IN_z=0.068 (406s)\n",
      "epoch=100, EUBO=-137.954, ELBO=-145.157, ESS=2.406, EX_eta=7.096, IN_eta=3.604, EX_z=0.184, IN_z=0.069 (406s)\n",
      "epoch=101, EUBO=-137.968, ELBO=-145.204, ESS=2.415, EX_eta=7.045, IN_eta=3.591, EX_z=0.181, IN_z=0.068 (407s)\n",
      "epoch=102, EUBO=-137.955, ELBO=-145.145, ESS=2.412, EX_eta=7.081, IN_eta=3.596, EX_z=0.175, IN_z=0.069 (407s)\n",
      "epoch=103, EUBO=-137.960, ELBO=-145.118, ESS=2.418, EX_eta=6.991, IN_eta=3.579, EX_z=0.167, IN_z=0.068 (406s)\n",
      "epoch=104, EUBO=-137.942, ELBO=-145.069, ESS=2.426, EX_eta=7.004, IN_eta=3.560, EX_z=0.156, IN_z=0.067 (405s)\n",
      "epoch=105, EUBO=-137.954, ELBO=-145.062, ESS=2.431, EX_eta=7.011, IN_eta=3.553, EX_z=0.207, IN_z=0.067 (406s)\n",
      "epoch=106, EUBO=-137.930, ELBO=-145.019, ESS=2.437, EX_eta=6.934, IN_eta=3.536, EX_z=0.159, IN_z=0.067 (405s)\n",
      "epoch=107, EUBO=-137.931, ELBO=-144.979, ESS=2.447, EX_eta=6.966, IN_eta=3.546, EX_z=0.159, IN_z=0.067 (406s)\n",
      "epoch=108, EUBO=-137.956, ELBO=-145.004, ESS=2.450, EX_eta=6.981, IN_eta=3.543, EX_z=0.159, IN_z=0.069 (405s)\n",
      "epoch=109, EUBO=-137.933, ELBO=-144.901, ESS=2.458, EX_eta=6.863, IN_eta=3.518, EX_z=0.168, IN_z=0.067 (406s)\n",
      "epoch=110, EUBO=-137.933, ELBO=-144.928, ESS=2.465, EX_eta=6.839, IN_eta=3.508, EX_z=0.145, IN_z=0.067 (406s)\n",
      "epoch=111, EUBO=-137.930, ELBO=-144.956, ESS=2.478, EX_eta=6.796, IN_eta=3.481, EX_z=0.186, IN_z=0.067 (406s)\n",
      "epoch=112, EUBO=-137.933, ELBO=-144.845, ESS=2.485, EX_eta=6.758, IN_eta=3.489, EX_z=0.188, IN_z=0.066 (406s)\n",
      "epoch=113, EUBO=-137.932, ELBO=-144.935, ESS=2.482, EX_eta=6.771, IN_eta=3.481, EX_z=0.182, IN_z=0.066 (405s)\n",
      "epoch=114, EUBO=-137.924, ELBO=-144.865, ESS=2.490, EX_eta=6.809, IN_eta=3.461, EX_z=0.171, IN_z=0.066 (406s)\n",
      "epoch=115, EUBO=-137.931, ELBO=-144.847, ESS=2.500, EX_eta=6.670, IN_eta=3.449, EX_z=0.133, IN_z=0.066 (406s)\n",
      "epoch=116, EUBO=-137.949, ELBO=-144.952, ESS=2.502, EX_eta=6.715, IN_eta=3.458, EX_z=0.202, IN_z=0.066 (407s)\n",
      "epoch=117, EUBO=-137.913, ELBO=-144.808, ESS=2.517, EX_eta=6.656, IN_eta=3.421, EX_z=0.215, IN_z=0.066 (407s)\n",
      "epoch=118, EUBO=-137.902, ELBO=-144.877, ESS=2.524, EX_eta=6.630, IN_eta=3.413, EX_z=0.199, IN_z=0.065 (406s)\n",
      "epoch=119, EUBO=-137.911, ELBO=-144.810, ESS=2.526, EX_eta=6.670, IN_eta=3.417, EX_z=0.202, IN_z=0.064 (406s)\n",
      "epoch=120, EUBO=-137.924, ELBO=-144.900, ESS=2.524, EX_eta=6.640, IN_eta=3.414, EX_z=0.159, IN_z=0.066 (406s)\n",
      "epoch=121, EUBO=-137.909, ELBO=-144.779, ESS=2.535, EX_eta=6.581, IN_eta=3.398, EX_z=0.185, IN_z=0.067 (406s)\n",
      "epoch=122, EUBO=-137.907, ELBO=-144.844, ESS=2.537, EX_eta=6.617, IN_eta=3.397, EX_z=0.163, IN_z=0.065 (406s)\n",
      "epoch=123, EUBO=-137.908, ELBO=-144.758, ESS=2.546, EX_eta=6.542, IN_eta=3.378, EX_z=0.191, IN_z=0.065 (406s)\n",
      "epoch=124, EUBO=-137.896, ELBO=-144.814, ESS=2.552, EX_eta=6.534, IN_eta=3.378, EX_z=0.193, IN_z=0.065 (406s)\n",
      "epoch=125, EUBO=-137.898, ELBO=-144.812, ESS=2.554, EX_eta=6.526, IN_eta=3.382, EX_z=0.149, IN_z=0.064 (407s)\n",
      "epoch=126, EUBO=-137.897, ELBO=-144.850, ESS=2.554, EX_eta=6.442, IN_eta=3.366, EX_z=0.193, IN_z=0.065 (407s)\n",
      "epoch=127, EUBO=-137.915, ELBO=-144.782, ESS=2.559, EX_eta=6.541, IN_eta=3.357, EX_z=0.216, IN_z=0.064 (406s)\n",
      "epoch=128, EUBO=-137.894, ELBO=-144.854, ESS=2.562, EX_eta=6.555, IN_eta=3.359, EX_z=0.204, IN_z=0.064 (406s)\n",
      "epoch=129, EUBO=-137.894, ELBO=-144.699, ESS=2.569, EX_eta=6.503, IN_eta=3.368, EX_z=0.196, IN_z=0.063 (406s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0cca1e8f77a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         batch_sigma2 = sigma2_true[batch_indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbatch_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_ag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cbdbcab81035>\u001b[0m in \u001b[0;36mag\u001b[0;34m(x, Pi, N, K, D, num_samples, steps, batch_size)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mz_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cbdbcab81035>\u001b[0m in \u001b[0;36mM_step\u001b[0;34m(X, z, N, D, K, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mlog_q_eta\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d0a33b4efc77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, K, D, num_samples, batch_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mq_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmus_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mq_nu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmus_log_nu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mq_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq_nu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flog = open('results/log-' + PATH + '.txt', 'w+')\n",
    "flog.write('EUBO_ave, ELBO_ave, ESS, EUBO_os, ELBO_os, EUBO_ag, ELBO_ag, KLs_eta_ex_os, KLs_eta_in_os, KL_z_ex_os, KL_z_in_os, KLs_eta_ex_ag, KLs_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\\n')\n",
    "flog.close()\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    EUBO_os = 0.0\n",
    "    ELBO_os = 0.0\n",
    "    EUBO_ag = 0.0\n",
    "    ELBO_ag = 0.0\n",
    "    \n",
    "    ESS = 0.0\n",
    "    KL_eta_ex_ag = 0.0\n",
    "    KL_eta_in_ag = 0.0\n",
    "    KL_z_ex_ag = 0.0\n",
    "    KL_z_in_ag = 0.0\n",
    "    \n",
    "    KL_eta_ex_os = 0.0\n",
    "    KL_eta_in_os = 0.0\n",
    "    KL_z_ex_os = 0.0\n",
    "    KL_z_in_os = 0.0\n",
    "    \n",
    "    for step in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "#         batch_Zs = Zs_true[batch_indices]\n",
    "#         batch_mus = mus_true[batch_indices]\n",
    "#         batch_sigma2 = sigma2_true[batch_indices]\n",
    "        batch_Xs = shuffler(batch_Xs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess, eubo_os, elbo_os, eubo_ag, elbo_ag, kl_eta_ex_os, kl_eta_in_os, kl_z_ex_os, kl_z_in_os, kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = ag(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        \n",
    "        EUBO_os += eubo_os.item()\n",
    "        ELBO_os += elbo_os.item()\n",
    "        EUBO_ag += eubo_ag.item()\n",
    "        ELBO_ag += elbo_ag.item()\n",
    "        \n",
    "        ESS += ess.item()\n",
    "        KL_eta_ex_ag += kl_eta_ex_ag.item()\n",
    "        KL_eta_in_ag += kl_eta_in_ag.item()\n",
    "        KL_z_ex_ag += kl_z_ex_ag.item()\n",
    "        KL_z_in_ag += kl_z_in_ag.item()\n",
    "        \n",
    "        KL_eta_ex_os += kl_eta_ex_os.item()\n",
    "        KL_eta_in_os += kl_eta_in_os.item()\n",
    "        KL_z_ex_os += kl_z_ex_os.item()\n",
    "        KL_z_in_os += kl_z_in_os.item()\n",
    "        flog = open('results/log-' + PATH + '.txt', 'a+')\n",
    "        flog.write(str(eubo.item()) + ', ' + str(elbo.item()) + ', ' + str(ess.item()) + ', ' + \n",
    "               str(eubo_os.item()) + ', ' + str(elbo_os.item()) + ', ' + str(eubo_ag.item()) + ', ' + str(elbo_ag.item()) + ', ' +\n",
    "               str(kl_eta_ex_os.item()) + ', ' + str(kl_eta_in_os.item()) + ', ' + str(kl_z_ex_os.item()) + ', ' + str(kl_z_in_os.item()) + ', ' +\n",
    "               str(kl_eta_ex_ag.item()) + ', ' + str(kl_eta_in_ag.item()) + ', ' + str(kl_z_ex_ag.item()) + ', ' + str(kl_z_in_ag.item()) + '\\n')\n",
    "        flog.close()\n",
    "             \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    \n",
    "    EUBO_os /= num_batches\n",
    "    ELBO_os /= num_batches\n",
    "    EUBO_ag /= num_batches\n",
    "    ELBO_ag /= num_batches\n",
    "    \n",
    "    ESS /= num_batches\n",
    "    KL_eta_ex_ag /= num_batches\n",
    "    KL_eta_in_ag /= num_batches\n",
    "    KL_z_ex_ag /= num_batches\n",
    "    KL_z_in_ag /= num_batches\n",
    "    \n",
    "    KL_eta_ex_os /= num_batches\n",
    "    KL_eta_in_os /= num_batches\n",
    "    KL_z_ex_os /= num_batches\n",
    "    KL_z_in_os /= num_batches \n",
    "\n",
    "    time_end = time.time()  \n",
    "    print('epoch=%d, EUBO=%.3f, ELBO=%.3f, ESS=%.3f, EX_eta=%.3f, IN_eta=%.3f, EX_z=%.3f, IN_z=%.3f (%ds)'\n",
    "            % (epoch, EUBO, ELBO, ESS,  KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag, time_end - time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc_global.state_dict(), 'models/global-enc-' + PATH)\n",
    "torch.save(enc_local.state_dict(), 'models/local-enc' + PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EUBOs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7eb2989deb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                    + str(KLs_eta_ex[i]) + str(KLs_eta_in[i]) + str(KLs_z_ex[i]) + str(KLs_z_in[i]) + '\\n')\n\u001b[1;32m      7\u001b[0m     \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEUBOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELBOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mESSs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_eta_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_eta_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_z_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLs_z_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EUBOs' is not defined"
     ]
    }
   ],
   "source": [
    "def save_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KL_z_ex, KL_z_in):\n",
    "    fout = open('results/logs-' + PATH +'.txt', 'w+')\n",
    "    fout.write('EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KL_z_ex, KL_z_in\\n')\n",
    "    for i in range(len(EUBOs)):\n",
    "        fout.write(str(EUBOs[i]) + ', ' + str(ELBOs[i]) + ', ' + str(ESSs[i]) \n",
    "                   + str(KLs_eta_ex[i]) + str(KLs_eta_in[i]) + str(KLs_z_ex[i]) + str(KLs_z_in[i]) + '\\n')\n",
    "    fout.close()\n",
    "save_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'ag-correct-stage2-50000datasets-oneshot-%dsteps' % STEPS\n",
    "opt2 =  torch.optim.Adam(list(enc_init.parameters()) + list(enc_global.parameters()) + list(enc_local.parameters()),lr=1e-5, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-137.702, ELBO=-143.959, ESS=2.807, EX_eta=5.903, IN_eta=2.996, EX_z=0.175, IN_z=0.055 (405s)\n",
      "epoch=1, EUBO=-137.699, ELBO=-143.951, ESS=2.832, EX_eta=5.858, IN_eta=2.963, EX_z=0.139, IN_z=0.052 (405s)\n",
      "epoch=2, EUBO=-137.699, ELBO=-143.982, ESS=2.844, EX_eta=6.015, IN_eta=2.967, EX_z=0.119, IN_z=0.052 (405s)\n",
      "epoch=3, EUBO=-137.701, ELBO=-143.940, ESS=2.847, EX_eta=5.814, IN_eta=2.944, EX_z=0.137, IN_z=0.052 (405s)\n",
      "epoch=4, EUBO=-137.691, ELBO=-143.954, ESS=2.850, EX_eta=5.903, IN_eta=2.953, EX_z=0.157, IN_z=0.051 (406s)\n",
      "epoch=5, EUBO=-137.685, ELBO=-143.955, ESS=2.851, EX_eta=5.835, IN_eta=2.952, EX_z=0.148, IN_z=0.051 (406s)\n",
      "epoch=6, EUBO=-137.695, ELBO=-143.948, ESS=2.858, EX_eta=5.930, IN_eta=2.951, EX_z=0.154, IN_z=0.052 (406s)\n",
      "epoch=7, EUBO=-137.694, ELBO=-143.903, ESS=2.861, EX_eta=5.834, IN_eta=2.952, EX_z=0.191, IN_z=0.051 (406s)\n",
      "epoch=8, EUBO=-137.696, ELBO=-143.972, ESS=2.863, EX_eta=5.881, IN_eta=2.953, EX_z=0.144, IN_z=0.051 (406s)\n",
      "epoch=9, EUBO=-137.691, ELBO=-143.963, ESS=2.865, EX_eta=5.839, IN_eta=2.948, EX_z=0.224, IN_z=0.051 (405s)\n",
      "epoch=10, EUBO=-137.699, ELBO=-143.978, ESS=2.865, EX_eta=5.819, IN_eta=2.960, EX_z=0.151, IN_z=0.050 (406s)\n",
      "epoch=11, EUBO=-137.686, ELBO=-143.954, ESS=2.867, EX_eta=5.842, IN_eta=2.956, EX_z=0.182, IN_z=0.051 (406s)\n",
      "epoch=12, EUBO=-137.698, ELBO=-143.924, ESS=2.868, EX_eta=5.844, IN_eta=2.963, EX_z=0.137, IN_z=0.050 (405s)\n",
      "epoch=13, EUBO=-137.684, ELBO=-143.946, ESS=2.871, EX_eta=5.782, IN_eta=2.941, EX_z=0.134, IN_z=0.051 (406s)\n",
      "epoch=14, EUBO=-137.690, ELBO=-143.925, ESS=2.875, EX_eta=5.870, IN_eta=2.947, EX_z=0.143, IN_z=0.050 (406s)\n",
      "epoch=15, EUBO=-137.696, ELBO=-143.978, ESS=2.877, EX_eta=5.880, IN_eta=2.942, EX_z=0.214, IN_z=0.050 (404s)\n",
      "epoch=16, EUBO=-137.695, ELBO=-143.927, ESS=2.875, EX_eta=5.825, IN_eta=2.957, EX_z=0.123, IN_z=0.051 (405s)\n",
      "epoch=17, EUBO=-137.701, ELBO=-143.984, ESS=2.876, EX_eta=5.856, IN_eta=2.948, EX_z=0.139, IN_z=0.051 (405s)\n",
      "epoch=18, EUBO=-137.702, ELBO=-143.984, ESS=2.879, EX_eta=5.838, IN_eta=2.949, EX_z=0.182, IN_z=0.051 (405s)\n",
      "epoch=19, EUBO=-137.692, ELBO=-143.941, ESS=2.878, EX_eta=5.858, IN_eta=2.946, EX_z=0.156, IN_z=0.050 (405s)\n",
      "epoch=20, EUBO=-137.689, ELBO=-143.949, ESS=2.880, EX_eta=5.768, IN_eta=2.940, EX_z=0.132, IN_z=0.050 (405s)\n",
      "epoch=21, EUBO=-137.701, ELBO=-143.957, ESS=2.880, EX_eta=5.839, IN_eta=2.945, EX_z=0.205, IN_z=0.051 (405s)\n",
      "epoch=22, EUBO=-137.693, ELBO=-144.014, ESS=2.881, EX_eta=5.833, IN_eta=2.934, EX_z=0.152, IN_z=0.050 (405s)\n",
      "epoch=23, EUBO=-137.692, ELBO=-144.040, ESS=2.884, EX_eta=5.844, IN_eta=2.931, EX_z=0.250, IN_z=0.052 (406s)\n",
      "epoch=24, EUBO=-137.682, ELBO=-143.905, ESS=2.881, EX_eta=5.811, IN_eta=2.930, EX_z=0.162, IN_z=0.050 (405s)\n",
      "epoch=25, EUBO=-137.694, ELBO=-143.958, ESS=2.888, EX_eta=5.817, IN_eta=2.940, EX_z=0.155, IN_z=0.051 (405s)\n",
      "epoch=26, EUBO=-137.684, ELBO=-143.963, ESS=2.888, EX_eta=5.827, IN_eta=2.932, EX_z=0.182, IN_z=0.051 (405s)\n",
      "epoch=27, EUBO=-137.691, ELBO=-143.997, ESS=2.887, EX_eta=5.796, IN_eta=2.928, EX_z=0.218, IN_z=0.050 (405s)\n",
      "epoch=28, EUBO=-137.694, ELBO=-144.024, ESS=2.889, EX_eta=5.748, IN_eta=2.935, EX_z=0.177, IN_z=0.051 (405s)\n",
      "epoch=29, EUBO=-137.689, ELBO=-143.897, ESS=2.885, EX_eta=5.801, IN_eta=2.930, EX_z=0.248, IN_z=0.051 (405s)\n",
      "epoch=30, EUBO=-137.689, ELBO=-143.922, ESS=2.891, EX_eta=5.753, IN_eta=2.935, EX_z=0.149, IN_z=0.050 (405s)\n",
      "epoch=31, EUBO=-137.690, ELBO=-143.919, ESS=2.886, EX_eta=5.775, IN_eta=2.924, EX_z=0.151, IN_z=0.050 (405s)\n",
      "epoch=32, EUBO=-137.692, ELBO=-143.911, ESS=2.890, EX_eta=5.851, IN_eta=2.941, EX_z=0.129, IN_z=0.052 (405s)\n",
      "epoch=33, EUBO=-137.686, ELBO=-143.945, ESS=2.893, EX_eta=5.783, IN_eta=2.923, EX_z=0.156, IN_z=0.050 (406s)\n",
      "epoch=34, EUBO=-137.691, ELBO=-143.916, ESS=2.895, EX_eta=5.704, IN_eta=2.918, EX_z=0.135, IN_z=0.050 (405s)\n",
      "epoch=35, EUBO=-137.698, ELBO=-143.974, ESS=2.891, EX_eta=5.887, IN_eta=2.938, EX_z=0.166, IN_z=0.051 (406s)\n",
      "epoch=36, EUBO=-137.698, ELBO=-143.969, ESS=2.890, EX_eta=5.796, IN_eta=2.939, EX_z=0.184, IN_z=0.050 (405s)\n",
      "epoch=37, EUBO=-137.700, ELBO=-143.950, ESS=2.895, EX_eta=5.774, IN_eta=2.930, EX_z=0.188, IN_z=0.050 (405s)\n",
      "epoch=38, EUBO=-137.693, ELBO=-143.964, ESS=2.898, EX_eta=5.819, IN_eta=2.925, EX_z=0.191, IN_z=0.052 (405s)\n",
      "epoch=39, EUBO=-137.696, ELBO=-143.983, ESS=2.894, EX_eta=5.811, IN_eta=2.926, EX_z=0.217, IN_z=0.050 (405s)\n",
      "epoch=40, EUBO=-137.694, ELBO=-144.005, ESS=2.894, EX_eta=5.836, IN_eta=2.940, EX_z=0.141, IN_z=0.051 (406s)\n",
      "epoch=41, EUBO=-137.698, ELBO=-143.960, ESS=2.897, EX_eta=5.787, IN_eta=2.934, EX_z=0.186, IN_z=0.051 (405s)\n",
      "epoch=42, EUBO=-137.682, ELBO=-143.946, ESS=2.899, EX_eta=5.844, IN_eta=2.926, EX_z=0.221, IN_z=0.050 (405s)\n",
      "epoch=43, EUBO=-137.691, ELBO=-143.893, ESS=2.902, EX_eta=5.700, IN_eta=2.918, EX_z=0.145, IN_z=0.050 (406s)\n",
      "epoch=44, EUBO=-137.685, ELBO=-143.926, ESS=2.899, EX_eta=5.684, IN_eta=2.916, EX_z=0.138, IN_z=0.050 (406s)\n",
      "epoch=45, EUBO=-137.694, ELBO=-143.893, ESS=2.899, EX_eta=5.742, IN_eta=2.925, EX_z=0.148, IN_z=0.051 (405s)\n",
      "epoch=46, EUBO=-137.683, ELBO=-143.927, ESS=2.900, EX_eta=5.790, IN_eta=2.925, EX_z=0.132, IN_z=0.051 (405s)\n",
      "epoch=47, EUBO=-137.696, ELBO=-143.954, ESS=2.899, EX_eta=5.796, IN_eta=2.914, EX_z=0.190, IN_z=0.052 (406s)\n",
      "epoch=48, EUBO=-137.685, ELBO=-143.946, ESS=2.901, EX_eta=5.770, IN_eta=2.913, EX_z=0.128, IN_z=0.050 (405s)\n",
      "epoch=49, EUBO=-137.694, ELBO=-143.956, ESS=2.905, EX_eta=5.800, IN_eta=2.914, EX_z=0.223, IN_z=0.050 (405s)\n",
      "epoch=50, EUBO=-137.691, ELBO=-143.889, ESS=2.903, EX_eta=5.776, IN_eta=2.927, EX_z=0.260, IN_z=0.050 (405s)\n",
      "epoch=51, EUBO=-137.691, ELBO=-143.940, ESS=2.903, EX_eta=5.855, IN_eta=2.927, EX_z=0.143, IN_z=0.050 (406s)\n",
      "epoch=52, EUBO=-137.687, ELBO=-143.957, ESS=2.902, EX_eta=5.787, IN_eta=2.920, EX_z=0.160, IN_z=0.051 (405s)\n",
      "epoch=53, EUBO=-137.696, ELBO=-143.858, ESS=2.905, EX_eta=5.783, IN_eta=2.919, EX_z=0.387, IN_z=0.051 (406s)\n",
      "epoch=54, EUBO=-137.690, ELBO=-143.908, ESS=2.908, EX_eta=5.862, IN_eta=2.927, EX_z=0.199, IN_z=0.051 (406s)\n",
      "epoch=55, EUBO=-137.700, ELBO=-144.020, ESS=2.905, EX_eta=5.782, IN_eta=2.917, EX_z=0.186, IN_z=0.051 (406s)\n",
      "epoch=56, EUBO=-137.696, ELBO=-143.919, ESS=2.909, EX_eta=5.684, IN_eta=2.909, EX_z=0.178, IN_z=0.051 (405s)\n",
      "epoch=57, EUBO=-137.681, ELBO=-143.989, ESS=2.905, EX_eta=5.661, IN_eta=2.908, EX_z=0.219, IN_z=0.050 (405s)\n",
      "epoch=58, EUBO=-137.693, ELBO=-143.922, ESS=2.909, EX_eta=5.774, IN_eta=2.916, EX_z=0.133, IN_z=0.051 (405s)\n",
      "epoch=59, EUBO=-137.679, ELBO=-143.928, ESS=2.906, EX_eta=5.789, IN_eta=2.905, EX_z=0.155, IN_z=0.051 (405s)\n",
      "epoch=60, EUBO=-137.698, ELBO=-143.935, ESS=2.913, EX_eta=5.743, IN_eta=2.910, EX_z=0.151, IN_z=0.051 (405s)\n",
      "epoch=61, EUBO=-137.689, ELBO=-143.930, ESS=2.910, EX_eta=5.768, IN_eta=2.918, EX_z=0.131, IN_z=0.051 (406s)\n",
      "epoch=62, EUBO=-137.692, ELBO=-143.903, ESS=2.909, EX_eta=5.741, IN_eta=2.917, EX_z=0.161, IN_z=0.050 (406s)\n",
      "epoch=63, EUBO=-137.687, ELBO=-143.939, ESS=2.908, EX_eta=5.679, IN_eta=2.902, EX_z=0.166, IN_z=0.051 (405s)\n",
      "epoch=64, EUBO=-137.692, ELBO=-143.928, ESS=2.912, EX_eta=5.797, IN_eta=2.906, EX_z=0.206, IN_z=0.050 (404s)\n",
      "epoch=65, EUBO=-137.688, ELBO=-143.947, ESS=2.910, EX_eta=5.729, IN_eta=2.909, EX_z=0.263, IN_z=0.050 (405s)\n",
      "epoch=66, EUBO=-137.683, ELBO=-143.946, ESS=2.910, EX_eta=5.692, IN_eta=2.909, EX_z=0.208, IN_z=0.051 (405s)\n",
      "epoch=67, EUBO=-137.687, ELBO=-143.925, ESS=2.911, EX_eta=5.746, IN_eta=2.923, EX_z=0.237, IN_z=0.051 (405s)\n",
      "epoch=68, EUBO=-137.685, ELBO=-143.964, ESS=2.910, EX_eta=5.730, IN_eta=2.915, EX_z=0.133, IN_z=0.051 (405s)\n",
      "epoch=69, EUBO=-137.676, ELBO=-143.896, ESS=2.911, EX_eta=5.782, IN_eta=2.907, EX_z=0.191, IN_z=0.051 (405s)\n",
      "epoch=70, EUBO=-137.684, ELBO=-143.865, ESS=2.912, EX_eta=5.730, IN_eta=2.903, EX_z=0.204, IN_z=0.051 (405s)\n",
      "epoch=71, EUBO=-137.689, ELBO=-143.905, ESS=2.919, EX_eta=5.702, IN_eta=2.898, EX_z=0.173, IN_z=0.051 (406s)\n",
      "epoch=72, EUBO=-137.688, ELBO=-143.925, ESS=2.914, EX_eta=5.722, IN_eta=2.897, EX_z=0.127, IN_z=0.051 (406s)\n",
      "epoch=73, EUBO=-137.692, ELBO=-144.000, ESS=2.916, EX_eta=5.779, IN_eta=2.927, EX_z=0.144, IN_z=0.051 (405s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-75f02177292b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         batch_sigma2 = sigma2_true[batch_indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbatch_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_eta_in_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_ex_ag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_z_in_ag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mopt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cbdbcab81035>\u001b[0m in \u001b[0;36mag\u001b[0;34m(x, Pi, N, K, D, num_samples, steps, batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mq_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInit_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_nu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mZ_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cbdbcab81035>\u001b[0m in \u001b[0;36mE_step\u001b[0;34m(X, mus, precisions, N, D, K, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0msigma_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmus_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mzs_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q_z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d0a33b4efc77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, N, K, D, num_samples, batch_size)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mzs_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mlog_qz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## S * B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## S * B * N * K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/distributions/one_hot_categorical.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0msample_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# [JIT WORKAROUND] lack of support for .scatter_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hao/.local/lib/python2.7/site-packages/torch/distributions/categorical.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprobs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0msample_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flog = open('results/log-' + PATH + '.txt', 'w+')\n",
    "flog.write('EUBO_ave, ELBO_ave, ESS, EUBO_os, ELBO_os, EUBO_ag, ELBO_ag, KLs_eta_ex_os, KLs_eta_in_os, KL_z_ex_os, KL_z_in_os, KLs_eta_ex_ag, KLs_eta_in_ag, KL_z_ex_ag, KL_z_in_ag\\n')\n",
    "flog.close()\n",
    "\n",
    "num_batches = int((Xs.shape[0] / BATCH_SIZE))\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    EUBO_os = 0.0\n",
    "    ELBO_os = 0.0\n",
    "    EUBO_ag = 0.0\n",
    "    ELBO_ag = 0.0\n",
    "    \n",
    "    ESS = 0.0\n",
    "    KL_eta_ex_ag = 0.0\n",
    "    KL_eta_in_ag = 0.0\n",
    "    KL_z_ex_ag = 0.0\n",
    "    KL_z_in_ag = 0.0\n",
    "    \n",
    "    KL_eta_ex_os = 0.0\n",
    "    KL_eta_in_os = 0.0\n",
    "    KL_z_ex_os = 0.0\n",
    "    KL_z_in_os = 0.0\n",
    "    \n",
    "    for step in range(num_batches):\n",
    "        opt2.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        batch_Xs = Xs[batch_indices]\n",
    "#         batch_Zs = Zs_true[batch_indices]\n",
    "#         batch_mus = mus_true[batch_indices]\n",
    "#         batch_sigma2 = sigma2_true[batch_indices]\n",
    "        batch_Xs = shuffler(batch_Xs, N, K, D, BATCH_SIZE)\n",
    "        eubo, elbo, ess, eubo_os, elbo_os, eubo_ag, elbo_ag, kl_eta_ex_os, kl_eta_in_os, kl_z_ex_os, kl_z_in_os, kl_eta_ex_ag, kl_eta_in_ag, kl_z_ex_ag, kl_z_in_ag = ag(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)\n",
    "        eubo.backward()\n",
    "        opt2.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        \n",
    "        EUBO_os += eubo_os.item()\n",
    "        ELBO_os += elbo_os.item()\n",
    "        EUBO_ag += eubo_ag.item()\n",
    "        ELBO_ag += elbo_ag.item()\n",
    "        \n",
    "        ESS += ess.item()\n",
    "        KL_eta_ex_ag += kl_eta_ex_ag.item()\n",
    "        KL_eta_in_ag += kl_eta_in_ag.item()\n",
    "        KL_z_ex_ag += kl_z_ex_ag.item()\n",
    "        KL_z_in_ag += kl_z_in_ag.item()\n",
    "        \n",
    "        KL_eta_ex_os += kl_eta_ex_os.item()\n",
    "        KL_eta_in_os += kl_eta_in_os.item()\n",
    "        KL_z_ex_os += kl_z_ex_os.item()\n",
    "        KL_z_in_os += kl_z_in_os.item()\n",
    "        flog = open('results/log-' + PATH + '.txt', 'a+')\n",
    "        flog.write(str(eubo.item()) + ', ' + str(elbo.item()) + ', ' + str(ess.item()) + ', ' + \n",
    "               str(eubo_os.item()) + ', ' + str(elbo_os.item()) + ', ' + str(eubo_ag.item()) + ', ' + str(elbo_ag.item()) + ', ' +\n",
    "               str(kl_eta_ex_os.item()) + ', ' + str(kl_eta_in_os.item()) + ', ' + str(kl_z_ex_os.item()) + ', ' + str(kl_z_in_os.item()) + ', ' +\n",
    "               str(kl_eta_ex_ag.item()) + ', ' + str(kl_eta_in_ag.item()) + ', ' + str(kl_z_ex_ag.item()) + ', ' + str(kl_z_in_ag.item()) + '\\n')\n",
    "        flog.close()\n",
    "             \n",
    "    EUBO /= num_batches\n",
    "    ELBO /= num_batches\n",
    "    \n",
    "    EUBO_os /= num_batches\n",
    "    ELBO_os /= num_batches\n",
    "    EUBO_ag /= num_batches\n",
    "    ELBO_ag /= num_batches\n",
    "    \n",
    "    ESS /= num_batches\n",
    "    KL_eta_ex_ag /= num_batches\n",
    "    KL_eta_in_ag /= num_batches\n",
    "    KL_z_ex_ag /= num_batches\n",
    "    KL_z_in_ag /= num_batches\n",
    "    \n",
    "    KL_eta_ex_os /= num_batches\n",
    "    KL_eta_in_os /= num_batches\n",
    "    KL_z_ex_os /= num_batches\n",
    "    KL_z_in_os /= num_batches \n",
    "\n",
    "    time_end = time.time()  \n",
    "    print('epoch=%d, EUBO=%.3f, ELBO=%.3f, ESS=%.3f, EX_eta=%.3f, IN_eta=%.3f, EX_z=%.3f, IN_z=%.3f (%ds)'\n",
    "            % (epoch, EUBO, ELBO, ESS,  KL_eta_ex_ag, KL_eta_in_ag, KL_z_ex_ag, KL_z_in_ag, time_end - time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in, num_samples):\n",
    "    fig = plt.figure(figsize=(20, 30))\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax1.plot(EUBOs, 'r', label='EUBOs')\n",
    "    ax1.plot(ELBOs, 'b', label='ELBOs')\n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax1.set_ylim([-220, -130])\n",
    "    ax1.legend(fontsize=18)\n",
    "    ##\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax2.plot(KLs_eta_ex, '#66b3ff', label='KLs_eta_ex')\n",
    "    ax2.plot(KLs_eta_in, '#ff9999', label='KLs_eta_in')\n",
    "    ax2.plot(KLs_z_ex, '#99ff99', label='KLs_z_ex')\n",
    "    ax2.plot(KLs_z_in, 'gold', label='KLs_z_in')   \n",
    "    ax2.plot(np.ones(len(KLs_z_in)) * 5, 'k', label='const=5.0')\n",
    "    ax2.legend(fontsize=18)\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax2.set_ylim([-1, 30])\n",
    "    ##\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax3.plot(np.array(ESSs) / num_samples, 'm', label='ESS')\n",
    "    ax3.tick_params(labelsize=18)\n",
    "    ax3.set_xlabel('epochs (%d gradient steps per epoch)'  % num_batches, size=18)\n",
    "    ax3.legend()\n",
    "    plt.savefig('results/train-' + PATH + '.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(EUBOs, ELBOs, ESSs, KLs_eta_ex, KLs_eta_in, KLs_z_ex, KLs_z_in, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 50\n",
    "def reverse(X, z, mus_prev, precisions_prev, N, D, K, batch_size):\n",
    "    data = torch.cat((X, z), dim=-1).view(batch_size*N, -1)\n",
    "    q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions = enc_global(data, K, D, 1, batch_size)  \n",
    "    log_q_eta =  Normal(q_mean[0], q_sigma[0]).log_prob(mus_prev).sum(-1).sum(-1) + Gamma(q_alpha, q_beta).log_prob(precisions_prev).sum(-1).sum(-1)## B\n",
    "    return log_q_eta\n",
    "\n",
    "def test(x, Pi, N, K, D, num_samples, steps, batch_size):\n",
    "    log_increment_weights = torch.zeros((steps, num_samples, batch_size))\n",
    "    log_p_joints = torch.zeros((steps, num_samples, batch_size))\n",
    "    log_qf = torch.zeros((steps-1, num_samples, batch_size))\n",
    "    log_qr = torch.zeros((steps-1, num_samples, batch_size))\n",
    "    Z_samples = torch.zeros((num_samples, batch_size, N, K))\n",
    "    mus_prevs = torch.zeros((num_samples, batch_size, K, D))\n",
    "    precisions_prevs = torch.zeros((num_samples, batch_size, K, D))\n",
    "    \n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            for l in range(num_samples):\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = Init_step(x, N, D, K, batch_size)\n",
    "                mus_prevs[l] = mus\n",
    "                precisions_prevs[l] = precisions\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                labels = z.nonzero()\n",
    "                log_p_z = cat(Pi).log_prob(z).sum(-1)\n",
    "                sigmas = 1. / torch.sqrt(precisions)\n",
    "                log_p_x = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1)\n",
    "                log_increment_weights[m, l] = log_p_x + log_p_z - log_q_z     \n",
    "                log_p_joints[m, l] = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                \n",
    "        else:\n",
    "            for l in range(num_samples):\n",
    "                z_prev = Z_samples[l]\n",
    "                q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z_prev, N, D, K, batch_size)\n",
    "                zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "                Z_samples[l] = z\n",
    "                log_p_joints[m, l] = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_qf[m-1, l] = log_q_eta + log_q_z\n",
    "                \n",
    "                mus_prev = mus_prevs[l]\n",
    "                precisions_prev = precisions_prevs[l]\n",
    "                \n",
    "                log_qr[m-1, l] = reverse(x, z, mus_prev, precisions_prev, N, D, K, batch_size)\n",
    "                log_p_joint = log_joints_gmm(x, z, Pi, mus, precisions, N, D, K, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "                log_increment_weights[m, l] = log_p_joint - log_q_z - log_q_eta\n",
    "                mus_prevs[l] = mus\n",
    "                precisions_prevs[l] = precisions\n",
    "    detail_balances = log_p_joints[1:] - log_p_joints[:-1] -log_qf + log_qr\n",
    "    increment_weights = torch.exp(log_increment_weights - logsumexp(log_increment_weights, 1).unsqueeze(1).repeat(1, num_samples, 1)).detach()\n",
    "    esses = (1./ (increment_weights ** 2).sum(1))                   \n",
    "    log_last_weights = log_increment_weights[-1] ## S * B\n",
    "    ## EUBO and ELBO\n",
    "    eubos = torch.mul(increment_weights, log_increment_weights).sum(1).mean(-1)\n",
    "    elbos = log_increment_weights.mean(1).mean(-1)     \n",
    "    return eubos, elbos, esses, log_increment_weights, detail_balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_batch(num_seqs, N, K, D, batch_size):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    batch_indices = indices[0*batch_size : (0+1)*batch_size]\n",
    "    batch_Xs = Xs[batch_indices]\n",
    "    batch_Xs = shuffler(batch_Xs, N, K, D, batch_size)\n",
    "    return batch_Xs\n",
    "batch_Xs = sample_single_batch(num_seqs, N, K, D, BATCH_SIZE)\n",
    "eubo, elbo, ess, log_increment_weights, detail_balances = test(batch_Xs, Pi, N, K, D, NUM_SAMPLES, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detail_balances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BATCH_SIZE):\n",
    "    log_weights = log_increment_weights[:, :, i]\n",
    "    ess_stepwise = ess[:, i].data.numpy()\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax3 = fig.add_subplot(1,3,3)\n",
    "    weights = torch.exp(log_weights - logsumexp(log_weights, -1)[:, None]).data.numpy()\n",
    "    db = detail_balances[:, :, i].mean(-1)\n",
    "    ax1.plot(db.data.numpy(), 'r-o')\n",
    "    ax1.set_ylim([-20, 20])\n",
    "    for s in range(NUM_SAMPLES):\n",
    "        ax2.plot(ess_stepwise, 'b-o')\n",
    "        ax3.plot(weights[:, s], 'g-o')\n",
    "        ax2.set_ylim([1.0, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(x, num_seqs, Pi, N, K, D, steps, batch_size):\n",
    "    LLs = [] \n",
    "    for m in range(steps):\n",
    "        if m == 0:\n",
    "            mus, precisions, log_p_eta = inti_global(K, D, prior_mean, prior_nu, prior_alpha, prior_beta, batch_size)\n",
    "            zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "        else:\n",
    "            q_mean, q_nu, q_alpha, q_beta, q_sigma, mus, precisions, log_q_eta = M_step(x, z, N, D, K, batch_size)\n",
    "            zs_pi, z, log_q_z = E_step(x, mus, precisions, N, D, K, batch_size)\n",
    "            labels = z.nonzero()\n",
    "            sigmas = 1. / torch.sqrt(precisions)\n",
    "            ll = Normal(mus[labels[:, 0], labels[:, -1], :].view(batch_size, N, D), sigmas[labels[:, 0], labels[:, -1], :].view(batch_size, N, D)).log_prob(x).sum(-1).sum(-1).mean()\n",
    "            LLs.append(ll.item())\n",
    "    E_precisions = q_alpha / q_beta\n",
    "    E_mus = q_mean\n",
    "    E_z = torch.argmax(zs_pi, dim=-1)\n",
    "\n",
    "    return z, mus, precisions, LLs, E_mus, E_precisions, E_z\n",
    "\n",
    "x,z_true = sample_single_batch(num_seqs, N, K, D, BATCH_SIZE)\n",
    "z, mus, precisions, LLs, E_mus, E_precisions, E_z = test(x, num_seqs, Pi, N, K, D, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_samples(Xs, Zs, mus, precisions, steps, batch_size):\n",
    "    colors = ['r', 'b', 'gold']\n",
    "    fig = plt.figure(figsize=(25,100))\n",
    "    for b in range(batch_size):\n",
    "        ax = fig.add_subplot(int(batch_size / 5), 5, b+1)\n",
    "        x = Xs[b].data.numpy()\n",
    "        z = Zs[b].data.numpy()\n",
    "        mu = mus[b].data.numpy()\n",
    "        precision = precisions[b].data.numpy()\n",
    "\n",
    "        covs = np.zeros((K, D, D))\n",
    "        assignments = z\n",
    "        for k in range(K):\n",
    "            covs[k] = np.diag(1. / precision[k])\n",
    "            xk = x[np.where(assignments == k)]\n",
    "            ax.scatter(xk[:, 0], xk[:, 1], c=colors[k])\n",
    "            plot_cov_ellipse(cov=covs[k], pos=mu[k], nstd=2, ax=ax, alpha=0.2, color=colors[k])\n",
    "        ax.set_ylim([-10, 10])\n",
    "        ax.set_xlim([-10, 10])\n",
    "    plt.savefig('results/modes' + PATH + '.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_final_samples(x, E_z, E_mus, E_precisions, STEPS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LLs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(LLs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
