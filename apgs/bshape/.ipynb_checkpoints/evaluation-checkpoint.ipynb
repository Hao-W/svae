{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data and Trained APG Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from apgs.bshape.apg_training import init_models\n",
    "from apgs.bshape.affine_transformer import Affine_Transformer\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda:1')\n",
    "data_dir = '../../data/bshape/'\n",
    "timesteps, num_objects, frame_pixels, mnist_pixels, num_hidden_digit, num_hidden_coor, z_where_dim, z_what_dim = 10, 2, 40, 10, 200, 200, 2, 10\n",
    "data_paths = []\n",
    "for file in os.listdir(data_dir + '%dobjects/test/' % num_objects):\n",
    "    data_paths.append(os.path.join(data_dir, '%dobjects/test' % num_objects, file))\n",
    "model_version = 'apg-bshape-num_objects=%s-num_sweeps=5-num_samples=20' % num_objects\n",
    "# model_version = 'rws-bshape-num_objects=%s-num_samples=100' % num_objects\n",
    "\n",
    "models = init_models(frame_pixels, mnist_pixels, num_hidden_digit, num_hidden_coor, z_where_dim, z_what_dim, CUDA, device, model_version, lr=None)\n",
    "AT = Affine_Transformer(frame_pixels, mnist_pixels, CUDA, device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apgs.resampler import Resampler\n",
    "# from apgs.bshape.objectives import apg_objective\n",
    "# from apgs.bshape.evaluation import viz_samples\n",
    "# from random import shuffle\n",
    "# batch_size, num_sweeps = 5, 10\n",
    "# shuffle(data_paths)\n",
    "# dataset = torch.from_numpy(np.load(data_paths[0])).float()\n",
    "# indices = torch.randperm(len(dataset))\n",
    "# data = dataset[indices[:batch_size]].unsqueeze(0)\n",
    "# shape_mean = torch.from_numpy(np.load('shape_mean.npy')).float()\n",
    "# shape_mean = shape_mean.repeat(batch_size, num_objects, 1, 1).unsqueeze(0)\n",
    "# if CUDA:\n",
    "#     data = data.cuda().to(device)\n",
    "#     shape_mean = shape_mean.cuda().to(device)\n",
    "# result_flags = {'loss_required' : False, 'ess_required' : False, 'mode_required' : True, 'density_required': False}\n",
    "# trace = apg_objective(models, AT, data, num_objects, result_flags, num_sweeps, Resampler('systematic', 1, CUDA, device), shape_mean)\n",
    "# viz_samples(data.squeeze(0).cpu(), trace, num_sweeps, num_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing log joint across all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch=1/5\n"
     ]
    }
   ],
   "source": [
    "from apgs.bshape.evaluation import density_all_instances\n",
    "from random import shuffle\n",
    "sample_size, num_sweeps = 100, 10\n",
    "lf_step_size, lf_num_steps, bpg_factor = 1e-4, [1, 5, 10], 1\n",
    "density_all_instances(models, AT, data_paths, sample_size, num_objects, z_where_dim, z_what_dim, num_sweeps, lf_step_size, lf_num_steps, bpg_factor, CUDA, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Budget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apgs.bshape.evaluation import budget_analysis, plot_budget_analyais_results\n",
    "data = torch.from_numpy(np.load(data_dir + '%dobjects/test/ob-1.npy' % num_objects)).float()\n",
    "budget = 1000\n",
    "num_sweeps = np.array([1, 5, 10 , 20, 25])\n",
    "sample_sizes = 1000 / num_sweeps\n",
    "blocks = ['decomposed', 'joint']\n",
    "df = budget_analysis(models, blocks, num_sweeps, sample_sizes, data, num_objects, CUDA, device)\n",
    "plot_budget_analyais_results(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apgs.bshape.evaluation import density_convergence, plot_convergence\n",
    "seed = 1\n",
    "data = torch.from_numpy(np.load(data_dir + '%dobjects/test/ob-1.npy' % num_objects)).float()\n",
    "sample_size, num_sweeps, num_runs = 100, 30, 3\n",
    "lf_step_size, lf_num_steps, bpg_factor = 1e-1, [1, 5, 10], 100\n",
    "densities = density_convergence(models, AT, data, sample_size, num_objects, num_runs, num_sweeps, lf_step_size, lf_num_steps, bpg_factor, CUDA, device)\n",
    "plot_convergence(densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
