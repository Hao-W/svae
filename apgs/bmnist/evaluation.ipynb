{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data and Trained APG Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from apgs.bmnist.apg_training import init_models\n",
    "from apgs.bmnist.affine_transformer import Affine_Transformer\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda:1')\n",
    "data_dir = '../../data/bmnist/'\n",
    "timesteps, num_digits, frame_pixels, mnist_pixels, num_hidden_digit, num_hidden_coor, z_where_dim, z_what_dim = 10, 3, 96, 28, 400, 400, 2, 10\n",
    "data_paths = []\n",
    "for file in os.listdir(data_dir + 'train/'):\n",
    "    data_paths.append(os.path.join(data_dir, 'train', file))\n",
    "model_version = 'apg-bmnist-num_sweeps=6-num_samples=16'\n",
    "models = init_models(frame_pixels, mnist_pixels, num_hidden_digit, num_hidden_coor, z_where_dim, z_what_dim, CUDA, device, model_version, lr=None)\n",
    "AT = Affine_Transformer(frame_pixels, mnist_pixels, CUDA, device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of Enc_coor(\n",
       "  (enc_hidden): Sequential(\n",
       "    (0): Linear(in_features=4761, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (where_mean): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=200, out_features=2, bias=True)\n",
       "    (3): Tanh()\n",
       "  )\n",
       "  (where_log_std): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_hidden.0.weight Parameter containing:\n",
      "tensor([[ 0.0334,  0.0424,  0.0632,  ...,  0.0444,  0.0370,  0.0373],\n",
      "        [-0.2199, -0.2690, -0.3178,  ...,  0.0028, -0.1610, -0.2897],\n",
      "        [ 0.2490,  0.1562,  0.1423,  ..., -0.0612, -0.0576, -0.0477],\n",
      "        ...,\n",
      "        [ 0.0062, -0.0218, -0.0182,  ...,  0.0676,  0.0982,  0.0584],\n",
      "        [-0.0490, -0.0709, -0.0890,  ...,  0.1896,  0.2327,  0.2719],\n",
      "        [ 0.0649,  0.0938,  0.0653,  ..., -0.0547, -0.0361, -0.0766]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "enc_hidden.0.bias Parameter containing:\n",
      "tensor([-0.0347,  0.0077,  0.0497, -0.0162,  0.0438,  0.0529,  0.0031,  0.0388,\n",
      "         0.0461,  0.0406, -0.0161,  0.0421,  0.0421,  0.0428,  0.0392,  0.0195,\n",
      "         0.0441, -0.0119, -0.0254, -0.0185, -0.0178,  0.0373,  0.0472,  0.0522,\n",
      "         0.0391,  0.0519,  0.0464,  0.0372,  0.0484,  0.0386,  0.0594,  0.0084,\n",
      "         0.0448,  0.0484, -0.0053,  0.0322, -0.0590,  0.0314,  0.0374,  0.0093,\n",
      "         0.0013,  0.0435,  0.0460, -0.0342,  0.0511, -0.0435,  0.0090,  0.0417,\n",
      "         0.0284,  0.0392,  0.0472, -0.0501,  0.0447,  0.0384,  0.0358,  0.0485,\n",
      "         0.0443,  0.0364,  0.0469,  0.0400,  0.0493,  0.0390,  0.0452,  0.0530,\n",
      "         0.0401,  0.0438,  0.0462,  0.0204,  0.0400, -0.0162,  0.0078, -0.0029,\n",
      "         0.0437,  0.0569,  0.0171, -0.0016,  0.0474, -0.0687,  0.0518,  0.0202,\n",
      "        -0.0143,  0.0482,  0.0516,  0.0561, -0.0474,  0.0468,  0.0452, -0.0170,\n",
      "         0.0477,  0.0475,  0.0393,  0.0009, -0.0563,  0.0374,  0.0319,  0.0127,\n",
      "        -0.0194,  0.0399,  0.0429,  0.0473, -0.0171, -0.0193,  0.0439,  0.0379,\n",
      "         0.0444,  0.0138,  0.0434, -0.0195,  0.0618,  0.0412,  0.0452,  0.0356,\n",
      "         0.0482,  0.0453,  0.0360,  0.0427,  0.0436,  0.0407,  0.0265,  0.0402,\n",
      "         0.0072,  0.0472,  0.0386,  0.0021,  0.0334,  0.0528, -0.0150, -0.0258,\n",
      "         0.0424,  0.0028, -0.0145,  0.0465,  0.0381,  0.0086,  0.0028, -0.0151,\n",
      "         0.0029, -0.0457,  0.0368,  0.0441,  0.0550, -0.0158,  0.0440,  0.0417,\n",
      "         0.0056,  0.0510,  0.0352,  0.0419,  0.0224,  0.0643,  0.0090,  0.0527,\n",
      "         0.0104, -0.0149,  0.0405, -0.0043,  0.0379, -0.0158,  0.0369,  0.0461,\n",
      "         0.0461, -0.0319,  0.0377,  0.0501,  0.0303,  0.0561,  0.0520,  0.0312,\n",
      "        -0.0163,  0.0410, -0.0176, -0.0582,  0.0296,  0.0422,  0.0414,  0.0030,\n",
      "         0.0371,  0.0393,  0.0150, -0.0149,  0.0314, -0.0203,  0.0495,  0.0602,\n",
      "         0.0420,  0.0213,  0.0455,  0.0076,  0.0450, -0.0154, -0.0018,  0.0500,\n",
      "        -0.0156,  0.0403, -0.0078,  0.0023,  0.0451,  0.0459, -0.0188,  0.0478,\n",
      "         0.0408,  0.0503,  0.0437,  0.0794,  0.0391,  0.0181,  0.0324,  0.0405,\n",
      "         0.0312,  0.0486,  0.0424,  0.0500,  0.0420,  0.0133,  0.0346,  0.0458,\n",
      "         0.0084,  0.0433,  0.0498,  0.0486,  0.0351,  0.0446,  0.0133,  0.0392,\n",
      "         0.0262, -0.0168,  0.0448,  0.0388,  0.0439,  0.0500,  0.0368,  0.0013,\n",
      "         0.0521, -0.0147,  0.0498,  0.0487,  0.0470, -0.0149,  0.0421,  0.0457,\n",
      "         0.0554,  0.0435,  0.0504,  0.0431,  0.0447,  0.0422, -0.0014,  0.0476,\n",
      "         0.0394, -0.0165,  0.0363,  0.0054,  0.0385, -0.0145,  0.0365,  0.0488,\n",
      "         0.0597,  0.0413,  0.0396,  0.0402,  0.0403,  0.0531, -0.0433,  0.0447,\n",
      "        -0.0497,  0.0460,  0.0487,  0.0560,  0.0332,  0.0547,  0.0041,  0.0408,\n",
      "         0.0509,  0.0497,  0.0311,  0.0079,  0.0483,  0.0467,  0.0419,  0.0116,\n",
      "         0.0479,  0.0332,  0.0324, -0.0164,  0.0214,  0.0116,  0.0471, -0.0206,\n",
      "         0.0360,  0.0421,  0.0218, -0.0607,  0.0583,  0.0527, -0.0043,  0.0462,\n",
      "         0.0438,  0.0369,  0.0235,  0.0263,  0.0014,  0.0131,  0.0450,  0.0471,\n",
      "         0.0348,  0.0220,  0.0335,  0.0472, -0.0167,  0.0392,  0.0391, -0.0454,\n",
      "         0.0050,  0.0447,  0.0479,  0.0466,  0.0438,  0.0016, -0.0460,  0.0458,\n",
      "        -0.0153,  0.0491,  0.0210,  0.0391,  0.0380,  0.0517,  0.0454,  0.0425,\n",
      "         0.0368, -0.0155,  0.0435,  0.0369,  0.0328,  0.0480,  0.0396,  0.0446,\n",
      "         0.0423,  0.0470,  0.0490,  0.0368,  0.0594, -0.0168,  0.0421,  0.0163,\n",
      "         0.0326,  0.0462,  0.0536,  0.0402,  0.0526,  0.0538,  0.0037,  0.0371,\n",
      "         0.0471,  0.0461,  0.0478,  0.0442,  0.0522, -0.0148,  0.0029,  0.0399,\n",
      "         0.0348,  0.0380,  0.0452,  0.0500, -0.0225, -0.0213, -0.0503, -0.0134,\n",
      "         0.0111,  0.0074,  0.0311,  0.0506,  0.0474,  0.0446,  0.0344, -0.0159,\n",
      "         0.0528,  0.0473,  0.0052, -0.0201, -0.0217,  0.0237,  0.0344,  0.0022,\n",
      "         0.0313,  0.0526,  0.0381,  0.0411, -0.0163,  0.0438,  0.0329,  0.0517,\n",
      "         0.0530, -0.0547,  0.0470, -0.0024,  0.0496,  0.0473,  0.0435,  0.0468],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_mean.0.weight Parameter containing:\n",
      "tensor([[ 0.0412,  0.0430, -0.0232,  ..., -0.0070,  0.0264,  0.0234],\n",
      "        [ 0.1239,  0.0200,  0.0128,  ..., -0.0251,  0.0512,  0.0250],\n",
      "        [ 0.1232,  0.0347, -0.0108,  ...,  0.0335,  0.0512,  0.0014],\n",
      "        ...,\n",
      "        [-0.0063,  0.0292,  0.0371,  ..., -0.0615,  0.0078,  0.0266],\n",
      "        [ 0.0314, -0.0310, -0.0052,  ...,  0.0340,  0.0312,  0.0085],\n",
      "        [-0.0483, -0.0445,  0.0003,  ..., -0.0266,  0.0372,  0.0225]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_mean.0.bias Parameter containing:\n",
      "tensor([ 0.0541,  0.0536,  0.0622,  0.0475, -0.0126, -0.0289,  0.0680, -0.0548,\n",
      "         0.0183, -0.0280,  0.0643,  0.0556,  0.0697,  0.0298,  0.0508, -0.0061,\n",
      "         0.0480,  0.0551, -0.0291, -0.0399, -0.0096, -0.0230, -0.0181,  0.0002,\n",
      "         0.0239, -0.0455, -0.0504, -0.0494, -0.0159,  0.0532,  0.0569, -0.0397,\n",
      "         0.0256,  0.0402,  0.0037, -0.0139,  0.0389,  0.0417,  0.0595,  0.0405,\n",
      "         0.0421, -0.0460,  0.0711,  0.0402,  0.0678, -0.0234, -0.0124, -0.0127,\n",
      "        -0.0364, -0.0126,  0.0489, -0.0026, -0.0199,  0.0338, -0.0078, -0.0457,\n",
      "        -0.0486,  0.0621, -0.0080,  0.0468,  0.0517, -0.0551,  0.0490,  0.0494,\n",
      "        -0.0362,  0.0325, -0.0160,  0.0637, -0.0394, -0.0429, -0.0174, -0.0204,\n",
      "         0.0310, -0.0489, -0.0490,  0.0710, -0.0299,  0.0700, -0.0423,  0.0705,\n",
      "         0.0232, -0.0276, -0.0217, -0.0459, -0.0181, -0.0416,  0.0626, -0.0433,\n",
      "        -0.0343, -0.0380, -0.0072,  0.0397,  0.0418,  0.0477, -0.0159,  0.0471,\n",
      "        -0.0281,  0.0422,  0.0594, -0.0466,  0.0267,  0.0694, -0.0263, -0.0364,\n",
      "        -0.0102, -0.0074, -0.0277, -0.0275,  0.0607, -0.0424,  0.0029,  0.0530,\n",
      "         0.0471, -0.0358, -0.0314,  0.0380, -0.0051,  0.0450, -0.0028, -0.0257,\n",
      "        -0.0084,  0.0421, -0.0226,  0.0703,  0.0599,  0.0613,  0.0122,  0.0600,\n",
      "        -0.0023,  0.0460,  0.0264,  0.0600,  0.0533,  0.0657,  0.0569,  0.0472,\n",
      "        -0.0103,  0.0252, -0.0333,  0.0630, -0.0465, -0.0418,  0.0542,  0.0468,\n",
      "         0.0518,  0.0073,  0.0610, -0.0176, -0.0367, -0.0459,  0.0330,  0.0664,\n",
      "         0.0632,  0.0356, -0.0027, -0.0534, -0.0316, -0.0058, -0.0379, -0.0280,\n",
      "         0.0242,  0.0589, -0.0302, -0.0477, -0.0102,  0.0548, -0.0195,  0.0378,\n",
      "        -0.0102, -0.0500, -0.0135,  0.0420,  0.0692, -0.0192,  0.0473,  0.0593,\n",
      "         0.0156, -0.0420, -0.0054, -0.0381,  0.0334,  0.0437,  0.0294,  0.0353,\n",
      "        -0.0168, -0.0520, -0.0516,  0.0450, -0.0473, -0.0160,  0.0638,  0.0647,\n",
      "         0.0304,  0.0670,  0.0496, -0.0174, -0.0192, -0.0302, -0.0336, -0.0505],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_mean.2.weight Parameter containing:\n",
      "tensor([[ 1.0356e-01,  8.9310e-02, -4.3181e-02, -1.1351e-01,  2.3919e-02,\n",
      "          3.9852e-02, -6.2066e-02, -4.1595e-02,  9.9421e-02,  1.9575e-02,\n",
      "         -9.0349e-02, -1.1302e-01,  1.4750e-02,  3.2308e-02,  1.0280e-01,\n",
      "          6.0641e-02,  7.2682e-02, -9.6913e-02,  6.0840e-02, -7.0917e-03,\n",
      "          8.9236e-03, -3.8928e-02, -1.8081e-02, -8.2361e-02, -1.0225e-01,\n",
      "         -5.5071e-02,  2.3423e-02,  7.4894e-02,  1.1228e-03,  1.0163e-01,\n",
      "          9.5705e-02,  4.5132e-02,  1.9898e-02,  9.4034e-02,  4.8299e-02,\n",
      "         -8.6597e-03,  6.6773e-02, -8.8103e-02,  5.1607e-02,  4.4412e-02,\n",
      "          6.4080e-02, -4.0231e-02,  8.1131e-02, -5.9804e-02, -6.4277e-02,\n",
      "          5.2074e-02,  4.9415e-01, -4.1298e-02,  4.4896e-02,  5.7105e-04,\n",
      "         -6.6729e-03, -7.7392e-02,  6.4666e-03, -3.8391e-03,  7.8905e-02,\n",
      "         -6.6094e-02,  3.2702e-02,  8.2240e-02, -4.2786e-02, -5.3138e-02,\n",
      "          1.1012e-01,  8.6141e-03,  6.6676e-02,  3.0985e-02,  3.1052e-03,\n",
      "          6.5127e-02, -4.1181e-03, -9.0428e-02, -3.9602e-02,  3.5259e-02,\n",
      "          3.5522e-02, -1.5553e-02,  1.1259e-01,  3.5484e-02,  5.6480e-02,\n",
      "         -7.2662e-02, -2.3264e-02, -1.0576e-01, -5.3802e-02,  6.2349e-02,\n",
      "          3.5408e-02, -3.3895e-02, -6.5120e-03,  6.9271e-02,  3.5900e-02,\n",
      "          4.7222e-02,  5.1772e-02,  7.9074e-03,  2.7311e-02,  4.7550e-02,\n",
      "          4.4651e-01,  2.7156e-02, -5.4818e-02,  9.7941e-02, -6.0712e-02,\n",
      "          7.0879e-02,  2.4599e-02, -7.3914e-02,  1.8228e-02,  2.0977e-02,\n",
      "          3.9511e-02,  9.1996e-02,  1.3055e-02, -6.3599e-02, -8.8563e-02,\n",
      "          6.1973e-02, -6.4077e-02,  6.3270e-02, -1.2980e-02,  4.9090e-02,\n",
      "         -1.4110e-02, -5.7083e-02, -6.5947e-02,  6.5262e-02,  4.8162e-02,\n",
      "          5.5612e-02,  6.7278e-02,  6.0810e-02, -4.8996e-01, -8.8357e-02,\n",
      "         -2.4322e-02, -7.7929e-02,  3.5834e-02, -3.3021e-02,  7.8350e-02,\n",
      "          1.0122e-01, -9.2784e-02,  2.4088e-02, -1.1536e-02, -1.0358e-01,\n",
      "          3.4064e-02, -9.9455e-02, -1.0470e-01,  9.3335e-02, -2.8527e-02,\n",
      "          5.2518e-02, -5.9602e-02,  9.0301e-02, -2.0459e-02, -6.4114e-02,\n",
      "         -5.4858e-02,  5.0834e-02,  1.0465e-01, -4.3669e-02, -8.2804e-02,\n",
      "          4.6668e-02,  1.4965e-02, -3.2952e-04,  3.9076e-02,  3.8786e-02,\n",
      "         -3.1307e-02, -7.0338e-02, -6.7845e-02,  7.2686e-02, -5.2632e-02,\n",
      "          6.9962e-02,  1.8266e-02,  7.3595e-02,  5.3000e-02, -6.6985e-02,\n",
      "          6.0210e-02,  1.0570e-01, -2.4074e-02, -2.3432e-02, -2.5967e-02,\n",
      "         -8.2337e-02,  2.3527e-02,  7.3847e-02,  3.3365e-02, -2.6651e-02,\n",
      "         -5.7349e-02,  1.0170e-02, -7.9308e-02, -7.4016e-03, -9.4100e-02,\n",
      "         -3.6436e-02, -1.2220e-02,  3.5301e-02,  2.0302e-02, -2.6053e-02,\n",
      "         -7.9264e-02,  9.4371e-02, -1.5925e-02, -7.7349e-02, -8.8116e-03,\n",
      "          2.0255e-03,  3.4473e-02,  3.9973e-02,  4.0868e-02, -8.0202e-03,\n",
      "         -4.7431e-02, -8.3542e-02,  5.1875e-02,  2.7616e-03,  6.0563e-02,\n",
      "          3.8380e-02, -1.7853e-02,  2.7451e-01, -6.1802e-03, -4.0370e-02],\n",
      "        [ 7.5604e-02,  8.2157e-02, -5.9778e-02,  6.4085e-02, -5.4030e-02,\n",
      "          3.7454e-02,  9.1698e-02, -3.9355e-03,  1.0155e-01, -1.5860e-02,\n",
      "         -3.3060e-02,  5.0324e-02,  6.8240e-02,  6.6682e-02, -6.8637e-02,\n",
      "         -1.7361e-02, -9.5879e-02,  1.0346e-01, -1.3306e-02,  3.2681e-02,\n",
      "          6.3412e-02, -2.8290e-02, -1.7963e-02, -8.3604e-02,  7.3674e-02,\n",
      "          3.6117e-02, -5.5207e-02, -6.2482e-02,  4.5908e-01,  8.1456e-02,\n",
      "          7.9450e-02, -6.3510e-02, -1.1569e-01, -1.0784e-01, -8.7078e-02,\n",
      "         -5.2964e-02,  6.5268e-02, -2.7367e-02,  4.7066e-02, -1.0190e-01,\n",
      "          7.1507e-02, -2.5339e-02,  6.7298e-02, -7.6519e-02,  6.2126e-02,\n",
      "         -1.5182e-02,  1.4856e-02, -1.3623e-02, -4.5166e-02,  1.9087e-02,\n",
      "         -6.5176e-02, -4.2927e-02,  4.0622e-02, -9.3327e-02,  7.8531e-03,\n",
      "         -3.6682e-02, -6.6674e-03,  7.8489e-02, -5.0557e-03, -6.9311e-02,\n",
      "          7.0761e-02, -1.5524e-02,  5.7725e-02, -6.1434e-02, -1.3903e-02,\n",
      "         -9.7304e-02,  5.2339e-02, -2.6747e-02,  5.5901e-02, -3.2812e-02,\n",
      "          2.7885e-02, -8.6796e-02,  3.5943e-02, -6.3827e-02,  1.4262e-02,\n",
      "          4.7900e-02, -4.2844e-02,  7.8931e-02,  5.4330e-02, -8.0434e-02,\n",
      "          8.3494e-02, -4.6119e-02, -6.0208e-02,  5.2622e-02, -3.6307e-03,\n",
      "          4.7479e-03, -5.8245e-02,  4.0580e-01,  5.6704e-02,  7.6860e-02,\n",
      "          1.8868e-02,  1.0190e-01, -8.7069e-02,  2.3996e-02,  3.4527e-03,\n",
      "          5.6026e-02,  5.1471e-02,  8.2789e-02, -8.2779e-02,  6.6130e-02,\n",
      "          9.3587e-02, -3.0124e-02, -4.0930e-02, -3.9043e-02, -8.0205e-03,\n",
      "         -3.1244e-02, -2.6464e-03,  8.7923e-03, -6.7740e-02, -4.6733e-02,\n",
      "         -5.9592e-02, -8.7445e-02,  9.1910e-02, -1.9730e-02, -2.6752e-02,\n",
      "          3.2767e-02, -2.5600e-02, -1.0816e-01, -3.2319e-03, -8.2365e-02,\n",
      "          4.9647e-02, -5.5795e-02, -2.9201e-02, -8.7094e-02, -6.8027e-02,\n",
      "         -1.8393e-02,  7.6285e-02, -5.9713e-02, -5.5960e-03, -8.5925e-02,\n",
      "         -9.2362e-02, -1.0358e-02,  9.8987e-02,  9.9417e-02,  9.6121e-02,\n",
      "          6.3050e-02,  6.2348e-02, -9.0394e-02, -4.9708e-02,  7.0740e-02,\n",
      "         -1.0529e-02, -1.3233e-02, -6.8317e-02,  6.0239e-02, -5.2589e-03,\n",
      "          2.7524e-02, -1.0590e-01, -5.2713e-02,  5.2537e-03, -6.3671e-02,\n",
      "          8.2652e-02,  7.0382e-02, -7.2372e-02,  7.3821e-02, -6.2321e-02,\n",
      "          3.2895e-02,  1.4814e-02,  1.6862e-02,  1.5392e-02,  1.0070e-02,\n",
      "          1.0664e-01, -1.4067e-02,  1.0603e-02,  1.6524e-02, -3.3963e-02,\n",
      "         -9.6143e-02,  1.4331e-02,  6.3103e-02, -5.5122e-02,  3.1039e-02,\n",
      "         -3.8515e-03,  9.8595e-02,  5.2456e-02, -9.2265e-03,  9.2769e-02,\n",
      "         -4.1135e-02, -8.2029e-02, -2.8746e-02,  3.6557e-02,  2.9670e-02,\n",
      "         -1.0117e-01,  6.9214e-02,  9.3263e-02,  4.5949e-02, -1.8821e-02,\n",
      "         -2.7580e-02,  1.8319e-02, -7.6858e-02,  6.0644e-02, -3.5676e-02,\n",
      "         -7.5740e-02,  7.9526e-02,  5.7721e-02, -1.0027e-01,  6.2589e-02,\n",
      "         -1.1732e-02, -2.6130e-02, -1.2148e-03, -4.6412e-02,  3.0150e-02]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_mean.2.bias Parameter containing:\n",
      "tensor([ 0.0355, -0.0035], device='cuda:1', requires_grad=True)\n",
      "where_log_std.0.weight Parameter containing:\n",
      "tensor([[ 0.0057, -0.0410, -0.0097,  ...,  0.0139, -0.0007,  0.0270],\n",
      "        [ 0.0235,  0.5065,  0.0007,  ...,  0.0264,  0.0569,  0.0942],\n",
      "        [ 0.0328,  0.0307,  0.0225,  ..., -0.0072,  0.0235,  0.0219],\n",
      "        ...,\n",
      "        [-0.1109,  0.4389,  0.0719,  ..., -0.0638, -0.1163,  0.0523],\n",
      "        [-0.2432,  0.5101,  0.0274,  ...,  0.0316,  0.0553,  0.0719],\n",
      "        [-0.1853,  0.5246,  0.0296,  ...,  0.0008, -0.0232,  0.1102]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_log_std.0.bias Parameter containing:\n",
      "tensor([ 0.0342, -0.0011,  0.0218, -0.0405, -0.0664,  0.0074,  0.0184, -0.0445,\n",
      "        -0.0382, -0.0280, -0.0327, -0.0095, -0.0307,  0.0218,  0.0128, -0.0271,\n",
      "         0.0086, -0.0536,  0.0042, -0.0149, -0.0469, -0.0164, -0.0220, -0.0326,\n",
      "        -0.0386, -0.0648, -0.0167,  0.0031,  0.0045, -0.0228,  0.0052, -0.0220,\n",
      "        -0.0338, -0.0492,  0.0245, -0.0122, -0.0530, -0.0438, -0.0231, -0.0429,\n",
      "         0.0030,  0.0555, -0.0250,  0.0320, -0.0306,  0.0004, -0.0037,  0.0049,\n",
      "        -0.0144,  0.0069, -0.0424, -0.0250,  0.0009,  0.0031, -0.0346, -0.0013,\n",
      "         0.0127,  0.0161, -0.0170,  0.0152, -0.0488,  0.0014, -0.0569, -0.0127,\n",
      "         0.0006, -0.0352, -0.0269, -0.0089, -0.0134, -0.0093,  0.0247, -0.0249,\n",
      "        -0.0029,  0.0173,  0.0164, -0.0095, -0.0479, -0.0120, -0.0409,  0.0135,\n",
      "        -0.0104, -0.0567,  0.0319, -0.0021,  0.0010,  0.0092, -0.0224, -0.0033,\n",
      "         0.0220, -0.0282, -0.0464,  0.0042, -0.0367, -0.0134,  0.0210, -0.0138,\n",
      "        -0.0118,  0.0121, -0.0142,  0.0054, -0.0252, -0.0467,  0.0363, -0.0262,\n",
      "         0.0319,  0.0008,  0.0700, -0.0657,  0.0067, -0.0254,  0.0363,  0.0368,\n",
      "         0.0169, -0.0377, -0.0237, -0.0304, -0.0392,  0.0139,  0.0148, -0.0349,\n",
      "         0.0107,  0.0242, -0.0340, -0.0233,  0.0440, -0.0423, -0.0669,  0.0015,\n",
      "        -0.0255, -0.0217, -0.0008, -0.0077, -0.0212,  0.0054, -0.0132, -0.0174,\n",
      "        -0.0395, -0.0057, -0.0306, -0.0276, -0.0467,  0.0079, -0.0525,  0.0821,\n",
      "         0.0208, -0.0394,  0.0146, -0.0435, -0.0339, -0.0226, -0.0403,  0.0362,\n",
      "        -0.0190,  0.0060, -0.0200, -0.0362, -0.0503,  0.0071, -0.0370,  0.0219,\n",
      "         0.0158, -0.0403,  0.0177, -0.0416, -0.0214, -0.0040, -0.0231, -0.0287,\n",
      "        -0.0181, -0.0088,  0.0118, -0.0039,  0.0288, -0.0014,  0.0010, -0.0141,\n",
      "         0.0020, -0.0111,  0.0035, -0.0383, -0.0215, -0.0457, -0.0297,  0.0147,\n",
      "        -0.0335, -0.0250, -0.0059,  0.0084, -0.0082, -0.0141, -0.0142, -0.0215,\n",
      "        -0.0238, -0.0021,  0.0044,  0.0295,  0.0289, -0.0333,  0.0025,  0.0177],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_log_std.2.weight Parameter containing:\n",
      "tensor([[ 4.8197e-02, -1.0510e-01,  3.7588e-02,  3.3046e-02, -1.4046e-01,\n",
      "         -6.7542e-02,  2.6950e-02, -1.2568e-02, -4.2516e-01, -1.4618e-01,\n",
      "         -2.3650e-01,  5.9801e-02,  4.3996e-02,  5.7080e-02, -2.4935e-02,\n",
      "         -1.3463e-01, -8.3635e-03, -1.5160e-01, -1.9326e-02, -1.4654e-02,\n",
      "         -2.4418e-01, -3.4896e-02, -1.1679e-01,  2.6018e-02,  2.5740e-03,\n",
      "         -1.3004e-01, -2.2729e-01, -1.2491e-01,  6.2881e-02,  1.5781e-02,\n",
      "          5.6102e-02, -3.1197e-01, -8.4601e-02, -4.7170e-01,  5.6067e-02,\n",
      "         -9.9508e-02, -6.2239e-02,  2.4033e-02, -8.4476e-02,  3.1299e-02,\n",
      "          6.0726e-02,  1.7473e-01, -1.3123e-01,  5.4029e-02, -1.3728e-01,\n",
      "         -4.7551e-02,  4.9003e-02, -5.0216e-02, -2.7928e-02,  3.0607e-02,\n",
      "         -6.6145e-03, -1.0281e-01,  5.8638e-02, -7.8473e-02, -8.9373e-02,\n",
      "         -8.6725e-02, -1.5359e-02,  5.3386e-02, -5.5924e-02, -1.5123e-02,\n",
      "         -1.4316e-01,  8.2469e-04, -2.5164e-01,  2.5919e-02, -7.0739e-02,\n",
      "          6.5294e-02, -4.7700e-02, -1.2960e-01, -1.2900e-01, -3.3336e-02,\n",
      "         -4.6695e-02, -6.5846e-02,  1.1848e-02,  6.0912e-02, -1.6883e-02,\n",
      "         -8.6097e-02, -1.4287e-01, -6.7268e-02, -5.5917e-01, -7.2196e-02,\n",
      "         -2.2874e-02, -3.8469e-01, -2.1449e-02,  1.7991e-02, -1.0754e-01,\n",
      "          4.2387e-03, -1.7118e-01,  5.0122e-03, -3.6496e-02, -1.3710e-01,\n",
      "         -5.0184e-02, -1.1957e-01, -1.2503e-01, -1.2123e-01, -3.0943e-02,\n",
      "         -1.1760e-01,  3.3068e-02,  1.3285e-01, -2.0464e-01, -2.3419e-02,\n",
      "         -4.0259e-01, -1.4901e-01,  5.6152e-02, -1.2136e-01,  4.6743e-02,\n",
      "          2.2481e-02,  1.2624e-01, -3.8059e-01,  2.5827e-02, -1.1636e-01,\n",
      "          4.2800e-02,  5.2426e-02, -3.6465e-02,  2.1173e-02,  2.2238e-02,\n",
      "         -9.3781e-02, -2.1772e-01,  4.6412e-02, -3.0188e-02, -5.8699e-02,\n",
      "          5.5902e-02,  3.7557e-02, -1.4014e-01, -1.0607e-02,  6.7618e-02,\n",
      "          4.2314e-02, -1.1869e-01,  5.8400e-02, -1.2796e-01, -1.5053e-01,\n",
      "          2.2854e-02, -1.3702e-01,  7.4521e-02, -1.3860e-01,  4.7316e-02,\n",
      "          1.9105e-02, -1.3085e-01, -1.3207e-01, -9.1680e-02, -8.4509e-02,\n",
      "          2.1141e-02, -1.2479e-01, -3.2989e-01,  2.9170e-01, -4.2114e-02,\n",
      "         -1.4225e-01, -8.6444e-02, -3.5389e-02,  4.5203e-02, -3.3903e-01,\n",
      "          4.3348e-02,  1.0376e-01, -4.8780e-02,  4.9936e-02,  9.7384e-02,\n",
      "          2.7493e-01, -2.9903e-02,  1.6931e-02, -6.4605e-02, -5.7742e-02,\n",
      "          2.0865e-02,  6.1926e-02, -2.0080e-02,  6.3993e-02, -1.0652e-01,\n",
      "         -4.2961e-02, -1.3302e-01, -1.1430e-01,  4.1918e-02, -1.0093e-01,\n",
      "         -1.4216e-01, -1.3245e-01, -2.8881e-02, -9.8856e-02,  1.6992e-02,\n",
      "         -9.6031e-02,  5.9706e-02, -9.0566e-02, -1.1038e-01,  3.8892e-02,\n",
      "         -7.2097e-02, -1.0195e-01,  5.8697e-02, -1.2160e-02, -5.9207e-02,\n",
      "          5.0487e-02, -6.7366e-02,  3.2761e-02, -4.7059e-02,  5.0478e-02,\n",
      "          2.5206e-02, -8.6861e-02, -6.2646e-02,  6.3151e-02,  4.9774e-02,\n",
      "          4.8608e-02,  4.9049e-02, -2.3942e-01, -5.1637e-02, -9.8574e-02],\n",
      "        [-1.5399e-02, -3.6237e-02,  1.2001e-02,  2.3892e-02, -8.7188e-02,\n",
      "         -1.1038e-01, -1.9508e-02,  1.8513e-02,  2.9080e-01, -1.4172e-01,\n",
      "         -8.2551e-02,  5.2462e-02, -6.2631e-03, -2.2533e-03,  3.4056e-02,\n",
      "         -1.8054e-02,  2.8076e-02, -1.6151e-01,  3.1333e-02,  5.5086e-02,\n",
      "         -2.2585e-01, -1.5020e-03, -1.2373e-01, -2.6517e-02,  2.6712e-03,\n",
      "         -1.0796e-01, -1.1308e-01, -1.7681e-02,  5.0506e-03,  2.3651e-02,\n",
      "          5.1524e-02, -1.9816e-01, -9.2320e-02, -1.4230e-01,  3.9693e-02,\n",
      "         -8.8449e-02,  6.5540e-02,  2.6105e-02, -1.1511e-01, -2.9142e-02,\n",
      "          4.4195e-03,  2.7441e-01, -1.6719e-01, -4.1531e-02, -1.6063e-01,\n",
      "         -5.2645e-02,  6.7304e-02, -1.3672e-01,  1.1240e-02,  6.0590e-03,\n",
      "         -6.9584e-02, -1.5500e-01, -3.9179e-02, -1.1695e-01, -2.3350e-01,\n",
      "         -8.0178e-02,  2.6712e-02,  2.7170e-02, -1.2853e-01,  2.1718e-02,\n",
      "         -2.0936e-02,  9.4485e-03, -2.8404e-01, -4.4310e-02, -2.3867e-01,\n",
      "         -2.8567e-02, -3.8368e-02, -1.4903e-01, -1.7498e-02,  1.6761e-02,\n",
      "         -1.3819e-01, -1.1942e-01, -1.1036e-02, -4.0989e-02,  1.5028e-02,\n",
      "         -1.2742e-01, -1.3101e-01, -1.1431e-01,  3.6687e-01, -8.8213e-02,\n",
      "          4.9434e-02, -1.8898e-01,  4.2469e-02,  2.8957e-02, -8.8450e-02,\n",
      "          1.9578e-02, -8.2611e-02,  1.7176e-02, -1.4754e-01, -1.3962e-01,\n",
      "          5.6324e-02, -7.4392e-02, -2.5405e-02, -1.5799e-01, -1.4200e-01,\n",
      "         -8.5978e-02,  3.7601e-02, -3.3999e-01, -2.7780e-01,  1.9873e-02,\n",
      "          2.8963e-02, -2.2932e-01, -3.9282e-01, -5.5810e-02,  3.7375e-02,\n",
      "          4.1412e-02,  3.5888e-01, -1.4625e-01,  4.6619e-02, -4.4294e-02,\n",
      "          5.1072e-02,  3.6717e-02, -1.2340e-01,  3.5504e-02,  4.8484e-02,\n",
      "         -1.6680e-01, -9.2565e-02, -2.4900e-02,  5.8391e-02,  4.1569e-02,\n",
      "          5.5035e-02, -9.1728e-03, -1.5011e-01, -4.0321e-04,  1.8526e-01,\n",
      "          6.1948e-02, -1.1774e-01,  5.1887e-02, -1.4469e-01, -1.5922e-01,\n",
      "         -6.8519e-03, -1.2066e-01, -2.7945e-01, -1.3593e-01,  1.7804e-03,\n",
      "         -3.6590e-02, -7.2305e-02, -1.3611e-01, -2.4704e-02, -8.8488e-02,\n",
      "         -4.6892e-02, -1.2690e-01, -1.4246e-02,  3.2448e-01, -1.2560e-01,\n",
      "         -5.7835e-02, -1.1940e-01,  3.1211e-02,  6.1428e-02, -5.6172e-03,\n",
      "          1.5690e-02,  6.4773e-04, -4.1668e-02, -3.0891e-02, -9.2420e-02,\n",
      "         -2.6896e-01, -5.6875e-02, -1.3633e-02,  6.2049e-03, -1.5069e-01,\n",
      "          3.5823e-02,  5.2902e-02,  6.0625e-02,  1.6856e-02, -1.0052e-01,\n",
      "         -3.8613e-01, -3.3985e-02, -5.0688e-02,  4.7880e-02, -1.1898e-01,\n",
      "         -8.3787e-02, -9.4646e-02,  5.2787e-02, -9.0063e-02,  4.2921e-02,\n",
      "         -6.1313e-02,  3.0541e-02, -1.3112e-01, -1.0648e-01, -8.0339e-06,\n",
      "         -1.1404e-01, -1.5171e-01,  1.0588e-02,  6.0175e-02, -4.8582e-02,\n",
      "         -4.0358e-02, -1.1422e-01, -2.5667e-02,  3.5682e-02, -2.2472e-02,\n",
      "          3.1517e-02, -1.0483e-01, -2.2908e-02,  3.7063e-02,  1.9146e-02,\n",
      "         -9.2541e-03,  1.5518e-02, -3.1339e-01, -1.3387e-01, -1.4844e-01]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "where_log_std.2.bias Parameter containing:\n",
      "tensor([0.0554, 0.0376], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in models[0].named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apgs.resampler import Resampler\n",
    "from apgs.bmnist.objectives import apg_objective\n",
    "from apgs.bmnist.evaluation import viz_samples\n",
    "from random import shuffle\n",
    "batch_size, num_sweeps = 5, 10\n",
    "shuffle(data_paths)\n",
    "data = torch.from_numpy(np.load(data_paths[0])).float()[:batch_size].unsqueeze(0)\n",
    "mnist_mean = torch.from_numpy(np.load('mnist_mean.npy')).float()\n",
    "mnist_mean = mnist_mean.repeat(batch_size, num_digits, 1, 1).unsqueeze(0)\n",
    "if CUDA:\n",
    "    data = data.cuda().to(device)\n",
    "    mnist_mean = mnist_mean.cuda().to(device)\n",
    "result_flags = {'loss_required' : False, 'ess_required' : False, 'mode_required' : True, 'density_required': False}\n",
    "trace = apg_objective(models, AT, data, num_digits, result_flags, num_sweeps, Resampler('systematic', 1, CUDA, device), mnist_mean)\n",
    "viz_samples(data.squeeze(0).cpu(), trace, num_sweeps, num_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing log joint across all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apgs.bmnist.evaluation import density_all_instances\n",
    "from random import shuffle\n",
    "sample_size, num_sweeps = 1000, 10\n",
    "lf_step_size, lf_num_steps, bpg_factor = 1e-4, [1, 5, 10], 100\n",
    "density_all_instances(models, AT, data_paths, sample_size, num_digits, z_where_dim, z_what_dim, num_sweeps, lf_step_size, lf_num_steps, bpg_factor, CUDA, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
