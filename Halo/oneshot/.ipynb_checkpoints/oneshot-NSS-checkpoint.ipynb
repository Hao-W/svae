{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import *\n",
    "from utils import *\n",
    "from objectives import *\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "import time\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "K = 3\n",
    "D = 2\n",
    "\n",
    "## Model Parameters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_GLOBAL = 32\n",
    "NUM_HIDDEN_LOCAL = 64\n",
    "STAT_SIZE = 8\n",
    "NUM_LATENTS =  D\n",
    "## Training Parameters\n",
    "SAMPLE_DIM = 0\n",
    "BATCH_DIM = 1\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'oneshot-nss'\n",
    "\n",
    "gpu = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.from_numpy(np.load('rings_varying_radius/obs.npy')).float()\n",
    "NUM_SEQS = Xs.shape[0]\n",
    "NUM_BATCHES = int((Xs.shape[0] / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enc_mu_rad(nn.Module):\n",
    "    def __init__(self, K, D, num_hidden, num_stats, CUDA, device):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.neural_stats = nn.Sequential(\n",
    "            nn.Linear(D, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_stats))\n",
    "\n",
    "        self.mean_mu = nn.Sequential(\n",
    "            nn.Linear(num_stats+2*D, NUM_HIDDEN_GLOBAL),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(NUM_HIDDEN_GLOBAL, K*D))\n",
    "\n",
    "        self.mean_log_sigma = nn.Sequential(\n",
    "            nn.Linear(num_stats+2*K*D, NUM_HIDDEN_GLOBAL),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(NUM_HIDDEN_GLOBAL, K*D))\n",
    "\n",
    "        self.radius_mu = nn.Sequential(\n",
    "            nn.Linear(num_stats+2, NUM_HIDDEN_GLOBAL),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(NUM_HIDDEN_GLOBAL, K))\n",
    "\n",
    "        self.radius_log_sigma = nn.Sequential(\n",
    "            nn.Linear(num_stats+2, NUM_HIDDEN_GLOBAL),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(NUM_HIDDEN_GLOBAL, K))\n",
    "\n",
    "        self.prior_mean_mu = torch.zeros(K*D)\n",
    "        self.prior_mean_sigma = torch.ones(K*D) * 4.0\n",
    "\n",
    "        self.prior_radius_mu = torch.ones(K) * 2.0\n",
    "        self.prior_radius_sigma = torch.ones(K)\n",
    "        if CUDA:\n",
    "            self.prior_mean_mu = self.prior_mean_mu.cuda().to(device)\n",
    "            self.prior_mean_sigma = self.prior_mean_sigma.cuda().to(device)\n",
    "\n",
    "            self.prior_radius_mu = self.prior_radius_mu.cuda().to(device)\n",
    "            self.prior_radius_sigma = self.prior_radius_sigma.cuda().to(device)\n",
    "\n",
    "    def forward(self, obs, K, D, sample_size, batch_size):\n",
    "        q = probtorch.Trace()\n",
    "        p = probtorch.Trace()\n",
    "\n",
    "        neural_stats = self.neural_stats(obs)\n",
    "        mean_stats = neural_stats.mean(-2) # S * B * STAT_DIM\n",
    "    \n",
    "        stat_mu = torch.cat((self.prior_mean_mu.repeat(sample_size, batch_size, 1), self.prior_mean_sigma.repeat(sample_size, batch_size, 1), mean_stats), -1)\n",
    "        stat_radius = torch.cat((self.prior_radius_mu.repeat(sample_size, batch_size, 1), self.prior_radius_sigma.repeat(sample_size, batch_size, 1), mean_stats), -1)\n",
    "        #\n",
    "        q_mean_mu = self.mean_mu(stat_mu).view(sample_size, batch_size, K, D)\n",
    "        q_mean_sigma = self.mean_log_sigma(stat_mu).exp().view(sample_size, batch_size, K, D)\n",
    "\n",
    "        q_radius_mu = self.radius_mu(stat_radius)\n",
    "        q_radius_sigma = self.radius_log_sigma(stat_radius).exp()\n",
    "\n",
    "        means = Normal(q_mean_mu, q_mean_sigma).sample()\n",
    "        q.normal(q_mean_mu,\n",
    "                 q_mean_sigma,\n",
    "                 value=means,\n",
    "                 name='means')\n",
    "        p.normal(self.prior_mean_mu,\n",
    "                 self.prior_mean_sigma,\n",
    "                 value=q['means'],\n",
    "                 name='means')\n",
    "\n",
    "        rads = Normal(q_radius_mu, q_radius_sigma).sample()\n",
    "        q.normal(q_radius_mu,\n",
    "                 q_radius_sigma,\n",
    "                 value=rads,\n",
    "                 name='radius')\n",
    "        p.normal(self.prior_radius_mu,\n",
    "                 self.prior_radius_sigma,\n",
    "                 value=q['radius'],\n",
    "                 name='radius')\n",
    "\n",
    "        return q, p\n",
    "\n",
    "class Enc_z(nn.Module):\n",
    "    def __init__(self, K, D, num_hidden, CUDA, device):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.log_prob = nn.Sequential(\n",
    "            nn.Linear(2*D+2, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, 1))\n",
    "\n",
    "        self.prior_pi = torch.ones(K) * (1./ K)\n",
    "        if CUDA:\n",
    "            self.prior_pi = self.prior_pi.cuda().to(device)\n",
    "\n",
    "    def forward(self, obs, obs_mu, obs_rad, N, sample_size, batch_size, noise_sigma, device):\n",
    "        q = probtorch.Trace()\n",
    "        p = probtorch.Trace()\n",
    "        noise_sigmas = torch.ones((sample_size, batch_size, N, 1)).cuda().to(device) * noise_sigma\n",
    "\n",
    "        prob1 = self.log_prob(torch.cat((obs, obs_mu[:, :, 0, :].unsqueeze(-2).repeat(1,1,N,1), obs_rad[:, :, 0, :].unsqueeze(-2).repeat(1,1,N,1), noise_sigmas), -1))\n",
    "        prob2 = self.log_prob(torch.cat((obs, obs_mu[:, :, 1, :].unsqueeze(-2).repeat(1,1,N,1), obs_rad[:, :, 1, :].unsqueeze(-2).repeat(1,1,N,1), noise_sigmas), -1))\n",
    "        prob3 = self.log_prob(torch.cat((obs, obs_mu[:, :, 2, :].unsqueeze(-2).repeat(1,1,N,1), obs_rad[:, :, 2, :].unsqueeze(-2).repeat(1,1,N,1), noise_sigmas), -1))\n",
    "\n",
    "        probs = torch.cat((prob1, prob2, prob3), -1) # S * B * N * K\n",
    "        q_pi = F.softmax(probs, -1)\n",
    "        z = cat(q_pi).sample()\n",
    "\n",
    "        _ = q.variable(cat, probs=q_pi, value=z, name='zs')\n",
    "        _ = p.variable(cat, probs=self.prior_pi, value=z, name='zs')\n",
    "        return q, p\n",
    "\n",
    "def initialize(NUM_HIDDEN_GLOBAL, STAT_SIZE, NUM_HIDDEN_LOCAL, K, D, CUDA, DEVICE, LR):\n",
    "    enc_mu_rad = Enc_mu_rad(K, D, num_hidden=NUM_HIDDEN_GLOBAL, num_stats=STAT_SIZE, CUDA=CUDA, device=DEVICE)\n",
    "    enc_z = Enc_z(K, D, num_hidden=NUM_HIDDEN_LOCAL, CUDA=CUDA, device=DEVICE)\n",
    "    if CUDA:\n",
    "        enc_mu_rad.cuda().to(DEVICE)\n",
    "        enc_z.cuda().to(DEVICE)\n",
    "    optimizer =  torch.optim.Adam(list(enc_z.parameters())+list(enc_mu_rad.parameters()),lr=LR, betas=(0.9, 0.99))\n",
    "    return enc_mu_rad, enc_z, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_pi = torch.ones(K) * (1./ K)\n",
    "# if CUDA:\n",
    "#     prior_pi = prior_pi.cuda().to(gpu)\n",
    "    \n",
    "# def enc_z(obs, obs_mu, radius, noise_sigma, sample_size, batch_size):\n",
    "#     obs_mu_expand = obs_mu.unsqueeze(-2).repeat(1, 1, 1, N, 1) # S * B * K * N * D\n",
    "#     obs_expand = obs.unsqueeze(2).repeat(1, 1, K, 1, 1) #  S * B * K * N * D\n",
    "#     distance = ((obs_expand - obs_mu_expand)**2).sum(-1).sqrt()\n",
    "#     perihelion = distance - radius #  S * B * K * N \n",
    "#     obs_dist = Normal(torch.zeros(1).cuda().to(gpu), torch.ones(1).cuda().to(gpu) * noise_sigma)\n",
    "#     log_perihelion = obs_dist.log_prob(perihelion).transpose(-1, -2) # S * B * N * K   \n",
    "\n",
    "#     q_pi = F.softmax(log_perihelion, -1)\n",
    "#     q = probtorch.Trace()\n",
    "#     p = probtorch.Trace()\n",
    "#     z = cat(q_pi).sample()\n",
    "#     _ = q.variable(cat, probs=q_pi, value=z, name='zs')\n",
    "#     p = probtorch.Trace()\n",
    "#     _ = p.variable(cat, probs=prior_pi, value=z, name='zs')\n",
    "#     return q, p\n",
    "def Eubo_oneshot_nss(enc_mu, enc_z, obs, N, K, D, sample_size, batch_size, gpu):\n",
    "    \"\"\"\n",
    "    objective for oneshot encoder with joint importance weight, might need to figure out local importance weight\n",
    "    \n",
    "    \"\"\"\n",
    "    q_eta, p_eta = enc_mu_rad(obs, K, D, sample_size, batch_size)\n",
    "    log_q_eta = q_eta['means'].log_prob.sum(-1) + q_eta['radius'].log_prob.sum(-1)\n",
    "    log_p_eta = p_eta['means'].log_prob.sum(-1) + p_eta['radius'].log_prob.sum(-1)# S * B * K\n",
    "    obs_mu = q_eta['means'].value\n",
    "    obs_rad = q_eta['radius'].value\n",
    "    ## update z -- cluster assignments\n",
    "    q_z, p_z = enc_z(obs, obs_mu, obs_rad, N, sample_size, batch_size, noise_sigma, DEVICE)\n",
    "    log_p_z = p_z['zs'].log_prob\n",
    "    log_q_z = q_z['zs'].log_prob\n",
    "    states = q_z['zs'].value\n",
    "    log_obs_n = True_Log_likelihood(obs, states, obs_mu, obs_rad, K, D, noise_sigma, DEVICE, cluster_flag=False)\n",
    "    log_weights = log_obs_n.sum(-1) + log_p_z.sum(-1) - log_q_z.sum(-1) + log_p_eta.sum(-1) - log_q_eta.sum(-1)\n",
    "    weights = F.softmax(log_weights, 0).detach()\n",
    "    eubo =(weights * log_weights).sum(0).mean()\n",
    "    elbo = log_weights.mean()\n",
    "    ess = (1. / (weights**2).sum(0)).mean() \n",
    "    return eubo, elbo, ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, EUBO=-54849.266, ELBO=-118258.983, ESS=1.000 (0s)\n",
      "epoch=1, EUBO=-46707.918, ELBO=-109774.229, ESS=1.000 (1s)\n",
      "epoch=2, EUBO=-42518.832, ELBO=-104844.678, ESS=1.000 (0s)\n",
      "epoch=3, EUBO=-40042.711, ELBO=-99127.542, ESS=1.000 (0s)\n",
      "epoch=4, EUBO=-38817.159, ELBO=-92934.404, ESS=1.000 (0s)\n",
      "epoch=5, EUBO=-35854.855, ELBO=-85223.064, ESS=1.000 (0s)\n",
      "epoch=6, EUBO=-34833.646, ELBO=-79987.647, ESS=1.000 (0s)\n",
      "epoch=7, EUBO=-34162.907, ELBO=-75071.605, ESS=1.000 (0s)\n",
      "epoch=8, EUBO=-33094.263, ELBO=-70988.469, ESS=1.000 (0s)\n",
      "epoch=9, EUBO=-32928.943, ELBO=-68818.058, ESS=1.000 (0s)\n",
      "epoch=10, EUBO=-31921.467, ELBO=-64841.663, ESS=1.000 (0s)\n",
      "epoch=11, EUBO=-31421.557, ELBO=-61560.540, ESS=1.000 (0s)\n",
      "epoch=12, EUBO=-30803.512, ELBO=-59034.454, ESS=1.000 (0s)\n",
      "epoch=13, EUBO=-30782.096, ELBO=-58656.974, ESS=1.000 (0s)\n",
      "epoch=14, EUBO=-30562.950, ELBO=-57662.190, ESS=1.000 (0s)\n",
      "epoch=15, EUBO=-30849.315, ELBO=-57695.230, ESS=1.001 (0s)\n",
      "epoch=16, EUBO=-29647.168, ELBO=-57772.958, ESS=1.001 (0s)\n",
      "epoch=17, EUBO=-30242.186, ELBO=-57520.484, ESS=1.001 (0s)\n",
      "epoch=18, EUBO=-29692.084, ELBO=-57286.130, ESS=1.000 (0s)\n",
      "epoch=19, EUBO=-29114.741, ELBO=-56788.266, ESS=1.000 (0s)\n",
      "epoch=20, EUBO=-28882.471, ELBO=-56877.276, ESS=1.000 (0s)\n",
      "epoch=21, EUBO=-29478.186, ELBO=-57722.826, ESS=1.000 (0s)\n",
      "epoch=22, EUBO=-28758.105, ELBO=-56786.193, ESS=1.000 (0s)\n",
      "epoch=23, EUBO=-28885.079, ELBO=-57226.528, ESS=1.000 (0s)\n",
      "epoch=24, EUBO=-28916.186, ELBO=-56156.349, ESS=1.001 (0s)\n",
      "epoch=25, EUBO=-28423.722, ELBO=-54666.767, ESS=1.001 (0s)\n",
      "epoch=26, EUBO=-28779.809, ELBO=-54789.703, ESS=1.000 (0s)\n",
      "epoch=27, EUBO=-29023.595, ELBO=-54414.404, ESS=1.000 (0s)\n",
      "epoch=28, EUBO=-28111.497, ELBO=-52940.322, ESS=1.001 (0s)\n",
      "epoch=29, EUBO=-29443.539, ELBO=-53595.317, ESS=1.000 (0s)\n",
      "epoch=30, EUBO=-29506.172, ELBO=-54021.055, ESS=1.000 (0s)\n",
      "epoch=31, EUBO=-28901.833, ELBO=-54005.619, ESS=1.000 (0s)\n",
      "epoch=32, EUBO=-29466.208, ELBO=-55873.880, ESS=1.000 (0s)\n",
      "epoch=33, EUBO=-28931.751, ELBO=-54605.574, ESS=1.001 (0s)\n",
      "epoch=34, EUBO=-29097.331, ELBO=-55408.280, ESS=1.000 (0s)\n",
      "epoch=35, EUBO=-29324.174, ELBO=-54943.401, ESS=1.001 (0s)\n",
      "epoch=36, EUBO=-29165.456, ELBO=-55491.723, ESS=1.001 (0s)\n",
      "epoch=37, EUBO=-28208.065, ELBO=-53831.342, ESS=1.001 (0s)\n",
      "epoch=38, EUBO=-28336.235, ELBO=-53625.662, ESS=1.000 (0s)\n",
      "epoch=39, EUBO=-28061.394, ELBO=-53756.063, ESS=1.000 (0s)\n",
      "epoch=40, EUBO=-28083.023, ELBO=-53107.263, ESS=1.000 (0s)\n",
      "epoch=41, EUBO=-28256.322, ELBO=-53331.997, ESS=1.000 (0s)\n",
      "epoch=42, EUBO=-28660.268, ELBO=-52944.575, ESS=1.000 (0s)\n",
      "epoch=43, EUBO=-28556.062, ELBO=-52019.738, ESS=1.001 (0s)\n",
      "epoch=44, EUBO=-28314.265, ELBO=-52407.068, ESS=1.000 (0s)\n",
      "epoch=45, EUBO=-27838.102, ELBO=-51526.060, ESS=1.000 (0s)\n",
      "epoch=46, EUBO=-28535.200, ELBO=-52568.238, ESS=1.000 (0s)\n",
      "epoch=47, EUBO=-28041.272, ELBO=-52000.381, ESS=1.001 (0s)\n",
      "epoch=48, EUBO=-27833.524, ELBO=-51925.108, ESS=1.001 (0s)\n",
      "epoch=49, EUBO=-27693.433, ELBO=-52074.625, ESS=1.001 (0s)\n",
      "epoch=50, EUBO=-27561.896, ELBO=-51677.389, ESS=1.001 (0s)\n",
      "epoch=51, EUBO=-27656.592, ELBO=-52113.433, ESS=1.000 (0s)\n",
      "epoch=52, EUBO=-27700.768, ELBO=-52459.002, ESS=1.000 (0s)\n",
      "epoch=53, EUBO=-27530.598, ELBO=-52472.516, ESS=1.000 (0s)\n",
      "epoch=54, EUBO=-27948.953, ELBO=-52624.841, ESS=1.001 (0s)\n",
      "epoch=55, EUBO=-28208.569, ELBO=-53450.259, ESS=1.000 (0s)\n",
      "epoch=56, EUBO=-28274.940, ELBO=-52689.526, ESS=1.000 (0s)\n",
      "epoch=57, EUBO=-28051.512, ELBO=-52672.437, ESS=1.000 (0s)\n",
      "epoch=58, EUBO=-27853.937, ELBO=-52036.095, ESS=1.001 (0s)\n",
      "epoch=59, EUBO=-27901.908, ELBO=-51990.266, ESS=1.000 (0s)\n",
      "epoch=60, EUBO=-28657.219, ELBO=-52471.695, ESS=1.000 (0s)\n",
      "epoch=61, EUBO=-28272.839, ELBO=-52598.842, ESS=1.000 (0s)\n",
      "epoch=62, EUBO=-28302.189, ELBO=-52126.944, ESS=1.001 (0s)\n",
      "epoch=63, EUBO=-28207.002, ELBO=-52560.846, ESS=1.000 (0s)\n",
      "epoch=64, EUBO=-28310.738, ELBO=-53087.570, ESS=1.000 (0s)\n",
      "epoch=65, EUBO=-28491.529, ELBO=-52867.375, ESS=1.000 (0s)\n",
      "epoch=66, EUBO=-28339.005, ELBO=-53023.865, ESS=1.000 (0s)\n",
      "epoch=67, EUBO=-27686.355, ELBO=-52611.219, ESS=1.000 (0s)\n",
      "epoch=68, EUBO=-27340.650, ELBO=-51477.850, ESS=1.000 (0s)\n",
      "epoch=69, EUBO=-27149.025, ELBO=-51889.859, ESS=1.001 (0s)\n",
      "epoch=70, EUBO=-26820.148, ELBO=-52183.352, ESS=1.000 (0s)\n",
      "epoch=71, EUBO=-26958.264, ELBO=-52881.532, ESS=1.000 (0s)\n",
      "epoch=72, EUBO=-27316.367, ELBO=-52302.808, ESS=1.000 (0s)\n",
      "epoch=73, EUBO=-27587.666, ELBO=-53052.760, ESS=1.001 (0s)\n",
      "epoch=74, EUBO=-27180.932, ELBO=-52465.949, ESS=1.000 (0s)\n",
      "epoch=75, EUBO=-27699.644, ELBO=-52596.814, ESS=1.001 (0s)\n",
      "epoch=76, EUBO=-28480.128, ELBO=-53268.827, ESS=1.000 (0s)\n",
      "epoch=77, EUBO=-28905.459, ELBO=-53547.330, ESS=1.000 (0s)\n",
      "epoch=78, EUBO=-28264.147, ELBO=-53272.868, ESS=1.000 (0s)\n",
      "epoch=79, EUBO=-27495.184, ELBO=-52390.191, ESS=1.000 (0s)\n",
      "epoch=80, EUBO=-27505.209, ELBO=-52352.121, ESS=1.000 (0s)\n",
      "epoch=81, EUBO=-27346.843, ELBO=-52398.393, ESS=1.001 (0s)\n",
      "epoch=82, EUBO=-27308.735, ELBO=-52080.280, ESS=1.000 (0s)\n",
      "epoch=83, EUBO=-27573.270, ELBO=-52302.243, ESS=1.000 (0s)\n",
      "epoch=84, EUBO=-27447.936, ELBO=-52415.661, ESS=1.001 (0s)\n",
      "epoch=85, EUBO=-27252.725, ELBO=-52031.070, ESS=1.000 (0s)\n",
      "epoch=86, EUBO=-27229.389, ELBO=-51986.856, ESS=1.000 (0s)\n",
      "epoch=87, EUBO=-27208.395, ELBO=-51912.543, ESS=1.001 (0s)\n",
      "epoch=88, EUBO=-27658.300, ELBO=-52497.829, ESS=1.001 (0s)\n",
      "epoch=89, EUBO=-27371.222, ELBO=-52480.766, ESS=1.001 (0s)\n",
      "epoch=90, EUBO=-27959.172, ELBO=-52635.478, ESS=1.000 (0s)\n",
      "epoch=91, EUBO=-27858.203, ELBO=-53274.108, ESS=1.000 (1s)\n",
      "epoch=92, EUBO=-27648.270, ELBO=-51728.123, ESS=1.000 (0s)\n",
      "epoch=93, EUBO=-27532.264, ELBO=-51513.354, ESS=1.000 (0s)\n",
      "epoch=94, EUBO=-27561.740, ELBO=-52203.889, ESS=1.000 (0s)\n",
      "epoch=95, EUBO=-27901.430, ELBO=-53377.535, ESS=1.000 (0s)\n",
      "epoch=96, EUBO=-28032.692, ELBO=-54220.064, ESS=1.000 (0s)\n",
      "epoch=97, EUBO=-28024.394, ELBO=-53435.545, ESS=1.001 (0s)\n",
      "epoch=98, EUBO=-28464.245, ELBO=-54261.680, ESS=1.000 (0s)\n",
      "epoch=99, EUBO=-27648.464, ELBO=-54030.041, ESS=1.000 (0s)\n",
      "epoch=100, EUBO=-27484.643, ELBO=-52904.390, ESS=1.000 (0s)\n",
      "epoch=101, EUBO=-27383.244, ELBO=-53013.148, ESS=1.001 (0s)\n",
      "epoch=102, EUBO=-27844.089, ELBO=-53522.013, ESS=1.000 (0s)\n",
      "epoch=103, EUBO=-27218.138, ELBO=-52713.150, ESS=1.000 (0s)\n",
      "epoch=104, EUBO=-27640.126, ELBO=-52534.623, ESS=1.001 (0s)\n",
      "epoch=105, EUBO=-27354.973, ELBO=-51704.524, ESS=1.001 (0s)\n",
      "epoch=106, EUBO=-27534.791, ELBO=-52162.718, ESS=1.000 (0s)\n",
      "epoch=107, EUBO=-27358.673, ELBO=-52067.602, ESS=1.000 (0s)\n",
      "epoch=108, EUBO=-27707.283, ELBO=-52497.503, ESS=1.001 (0s)\n",
      "epoch=109, EUBO=-27562.035, ELBO=-52553.716, ESS=1.001 (0s)\n",
      "epoch=110, EUBO=-27932.614, ELBO=-51726.684, ESS=1.001 (1s)\n",
      "epoch=111, EUBO=-27453.862, ELBO=-52470.939, ESS=1.000 (1s)\n",
      "epoch=112, EUBO=-27497.195, ELBO=-52571.286, ESS=1.000 (0s)\n",
      "epoch=113, EUBO=-27822.563, ELBO=-52295.417, ESS=1.001 (0s)\n",
      "epoch=114, EUBO=-27806.526, ELBO=-52502.161, ESS=1.001 (0s)\n",
      "epoch=115, EUBO=-28676.499, ELBO=-53902.619, ESS=1.001 (0s)\n",
      "epoch=116, EUBO=-28688.947, ELBO=-53633.948, ESS=1.000 (0s)\n",
      "epoch=117, EUBO=-28938.789, ELBO=-54434.554, ESS=1.000 (0s)\n",
      "epoch=118, EUBO=-28749.364, ELBO=-53679.962, ESS=1.001 (0s)\n",
      "epoch=119, EUBO=-28547.754, ELBO=-53890.954, ESS=1.001 (0s)\n",
      "epoch=120, EUBO=-27995.986, ELBO=-54216.279, ESS=1.001 (0s)\n",
      "epoch=121, EUBO=-28151.595, ELBO=-53857.950, ESS=1.000 (0s)\n",
      "epoch=122, EUBO=-27851.911, ELBO=-53215.476, ESS=1.001 (0s)\n",
      "epoch=123, EUBO=-28178.624, ELBO=-53296.091, ESS=1.000 (0s)\n",
      "epoch=124, EUBO=-28621.878, ELBO=-53832.763, ESS=1.000 (0s)\n",
      "epoch=125, EUBO=-28644.488, ELBO=-54386.132, ESS=1.000 (0s)\n",
      "epoch=126, EUBO=-28675.097, ELBO=-53138.477, ESS=1.000 (0s)\n",
      "epoch=127, EUBO=-28489.816, ELBO=-53809.979, ESS=1.001 (0s)\n",
      "epoch=128, EUBO=-28699.276, ELBO=-53666.465, ESS=1.001 (0s)\n",
      "epoch=129, EUBO=-28214.263, ELBO=-53261.774, ESS=1.000 (0s)\n",
      "epoch=130, EUBO=-27886.149, ELBO=-53299.539, ESS=1.000 (0s)\n",
      "epoch=131, EUBO=-27857.777, ELBO=-53155.407, ESS=1.000 (0s)\n",
      "epoch=132, EUBO=-27756.341, ELBO=-52762.926, ESS=1.000 (0s)\n",
      "epoch=133, EUBO=-27920.399, ELBO=-53026.456, ESS=1.000 (0s)\n",
      "epoch=134, EUBO=-28221.581, ELBO=-53270.222, ESS=1.000 (0s)\n",
      "epoch=135, EUBO=-28241.414, ELBO=-53507.131, ESS=1.000 (0s)\n",
      "epoch=136, EUBO=-28050.345, ELBO=-54340.574, ESS=1.000 (0s)\n",
      "epoch=137, EUBO=-28447.543, ELBO=-55102.286, ESS=1.000 (0s)\n",
      "epoch=138, EUBO=-28496.166, ELBO=-54353.367, ESS=1.000 (0s)\n",
      "epoch=139, EUBO=-29016.499, ELBO=-54833.718, ESS=1.000 (0s)\n",
      "epoch=140, EUBO=-29176.645, ELBO=-53997.426, ESS=1.001 (0s)\n",
      "epoch=141, EUBO=-29554.564, ELBO=-54695.173, ESS=1.001 (0s)\n",
      "epoch=142, EUBO=-29612.924, ELBO=-56232.392, ESS=1.001 (0s)\n",
      "epoch=143, EUBO=-29199.168, ELBO=-54651.603, ESS=1.001 (0s)\n",
      "epoch=144, EUBO=-29673.726, ELBO=-54777.671, ESS=1.000 (0s)\n",
      "epoch=145, EUBO=-28924.344, ELBO=-54371.043, ESS=1.000 (0s)\n",
      "epoch=146, EUBO=-29036.448, ELBO=-54828.773, ESS=1.000 (0s)\n",
      "epoch=147, EUBO=-29402.917, ELBO=-55127.021, ESS=1.000 (0s)\n",
      "epoch=148, EUBO=-29933.208, ELBO=-54727.743, ESS=1.000 (0s)\n",
      "epoch=149, EUBO=-29066.198, ELBO=-54556.434, ESS=1.000 (0s)\n",
      "epoch=150, EUBO=-29035.954, ELBO=-53911.288, ESS=1.000 (0s)\n",
      "epoch=151, EUBO=-29098.972, ELBO=-54230.801, ESS=1.000 (0s)\n",
      "epoch=152, EUBO=-28553.907, ELBO=-53788.818, ESS=1.000 (0s)\n",
      "epoch=153, EUBO=-28643.725, ELBO=-53993.283, ESS=1.001 (0s)\n",
      "epoch=154, EUBO=-28688.059, ELBO=-53594.403, ESS=1.001 (0s)\n",
      "epoch=155, EUBO=-28732.313, ELBO=-53320.920, ESS=1.000 (0s)\n",
      "epoch=156, EUBO=-29225.953, ELBO=-52743.827, ESS=1.000 (0s)\n",
      "epoch=157, EUBO=-28859.223, ELBO=-52230.244, ESS=1.001 (0s)\n",
      "epoch=158, EUBO=-28820.147, ELBO=-52309.940, ESS=1.000 (0s)\n",
      "epoch=159, EUBO=-29034.712, ELBO=-52773.116, ESS=1.000 (0s)\n",
      "epoch=160, EUBO=-28430.227, ELBO=-52803.106, ESS=1.000 (0s)\n",
      "epoch=161, EUBO=-28771.455, ELBO=-53375.943, ESS=1.000 (0s)\n",
      "epoch=162, EUBO=-28695.530, ELBO=-52602.080, ESS=1.000 (0s)\n",
      "epoch=163, EUBO=-28097.966, ELBO=-52339.033, ESS=1.001 (0s)\n",
      "epoch=164, EUBO=-28121.129, ELBO=-52221.677, ESS=1.000 (0s)\n",
      "epoch=165, EUBO=-27810.486, ELBO=-52737.820, ESS=1.001 (0s)\n",
      "epoch=166, EUBO=-29668.321, ELBO=-54782.575, ESS=1.000 (0s)\n",
      "epoch=167, EUBO=-27929.321, ELBO=-52542.406, ESS=1.000 (0s)\n",
      "epoch=168, EUBO=-29133.042, ELBO=-53118.537, ESS=1.000 (0s)\n",
      "epoch=169, EUBO=-28459.970, ELBO=-52719.821, ESS=1.000 (0s)\n",
      "epoch=170, EUBO=-28285.982, ELBO=-51786.246, ESS=1.000 (0s)\n",
      "epoch=171, EUBO=-28523.067, ELBO=-51729.725, ESS=1.000 (0s)\n",
      "epoch=172, EUBO=-28331.879, ELBO=-51496.697, ESS=1.000 (0s)\n",
      "epoch=173, EUBO=-28191.322, ELBO=-51229.293, ESS=1.000 (0s)\n",
      "epoch=174, EUBO=-28673.437, ELBO=-51076.207, ESS=1.001 (0s)\n",
      "epoch=175, EUBO=-28838.255, ELBO=-51477.818, ESS=1.001 (0s)\n",
      "epoch=176, EUBO=-28573.321, ELBO=-52029.785, ESS=1.000 (0s)\n",
      "epoch=177, EUBO=-28490.752, ELBO=-51896.467, ESS=1.000 (0s)\n",
      "epoch=178, EUBO=-28938.067, ELBO=-52544.638, ESS=1.000 (0s)\n",
      "epoch=179, EUBO=-28236.554, ELBO=-51950.884, ESS=1.000 (0s)\n",
      "epoch=180, EUBO=-28116.805, ELBO=-51600.234, ESS=1.001 (0s)\n",
      "epoch=181, EUBO=-28578.841, ELBO=-52126.394, ESS=1.001 (0s)\n",
      "epoch=182, EUBO=-28355.501, ELBO=-51243.900, ESS=1.000 (0s)\n",
      "epoch=183, EUBO=-28275.368, ELBO=-51599.750, ESS=1.000 (0s)\n",
      "epoch=184, EUBO=-28471.804, ELBO=-51669.952, ESS=1.000 (0s)\n",
      "epoch=185, EUBO=-28447.872, ELBO=-51670.139, ESS=1.000 (0s)\n",
      "epoch=186, EUBO=-28861.353, ELBO=-51766.009, ESS=1.000 (0s)\n",
      "epoch=187, EUBO=-28347.707, ELBO=-51311.237, ESS=1.000 (1s)\n",
      "epoch=188, EUBO=-28360.578, ELBO=-51484.713, ESS=1.001 (1s)\n",
      "epoch=189, EUBO=-28454.742, ELBO=-51732.087, ESS=1.000 (0s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d1212d176daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0meubo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEubo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m## gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mEUBO\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meubo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EUBOs = []\n",
    "ELBOs = []\n",
    "ESSs = []\n",
    "\n",
    "flog = open('results/log-' + PATH + '.txt', 'w+')\n",
    "flog.write('EUBO\\tELBO\\tESS\\n')\n",
    "flog.close()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    indices = torch.randperm(NUM_SEQS)\n",
    "    EUBO = 0.0\n",
    "    ELBO = 0.0\n",
    "    ESS = 0.0\n",
    "    for step in range(NUM_BATCHES):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "        obs = Xs[batch_indices]\n",
    "        obs = shuffler(obs).repeat(SAMPLE_SIZE, 1, 1, 1)\n",
    "        if CUDA:\n",
    "            obs = obs.cuda().to(gpu)\n",
    "        eubo, elbo, ess = Eubo(enc_mu, enc_z, obs, N, K, D, SAMPLE_SIZE, BATCH_SIZE, gpu)\n",
    "        ## gradient step\n",
    "        eubo.backward()\n",
    "        optimizer.step()\n",
    "        EUBO += eubo.item()\n",
    "        ELBO += elbo.item()\n",
    "        ESS += ess.item()\n",
    "    EUBOs.append(EUBO / NUM_BATCHES)\n",
    "    ELBOs.append(ELBO / NUM_BATCHES)\n",
    "    ESSs.append(ESS / NUM_BATCHES) \n",
    "    flog = open('results/log-' + PATH + '.txt', 'a+')\n",
    "    print('%.3f\\t%.3f\\t%.3f'\n",
    "            % (EUBO/NUM_BATCHES, ELBO/NUM_BATCHES, ESS/NUM_BATCHES), file=flog)\n",
    "    flog.close()\n",
    "    time_end = time.time()\n",
    "    print('epoch=%d, EUBO=%.3f, ELBO=%.3f, ESS=%.3f (%ds)'\n",
    "            % (epoch, EUBO/NUM_BATCHES, ELBO/NUM_BATCHES, ESS/NUM_BATCHES, \n",
    "               time_end - time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST = 50\n",
    "\n",
    "def sample_single_batch(num_seqs, N, K, D, sample_size, batch_size, gpu):\n",
    "    indices = torch.randperm(num_seqs)\n",
    "    batch_indices = indices[0*batch_size : (0+1)*batch_size]\n",
    "    obs = Xs[batch_indices]\n",
    "    obs = shuffler(obs).repeat(sample_size, 1, 1, 1)\n",
    "    if CUDA:\n",
    "        obs = obs.cuda().to(gpu)\n",
    "    return obs\n",
    "\n",
    "def test(enc_mu, enc_z, obs, N, K, D, mcmc_size, sample_size, batch_size, gpu):\n",
    "    p_init_z = cat(prior_pi)\n",
    "    states = p_init_z.sample((sample_size, batch_size, N,))\n",
    "    log_p_z = p_init_z.log_prob(states)## S * B * N\n",
    "    log_q_z = p_init_z.log_prob(states)\n",
    "    for m in range(mcmc_size):\n",
    "        q_mu, p_mu = enc_mu(obs, states, sample_size, batch_size)\n",
    "        log_q_mu = q_mu['means'].log_prob.sum(-1)\n",
    "        log_p_mu = p_mu['means'].log_prob.sum(-1) # S * B * K\n",
    "        obs_mu = q_mu['means'].value\n",
    "        log_obs_k = Log_likelihood(obs, states, obs_mu, K, D, radius=1.5, noise_sigma = 0.05, gpu=gpu, cluster_flag=True)\n",
    "        log_weights_global = log_obs_k + log_p_mu - log_q_mu\n",
    "        weights_global = F.softmax(log_weights_global, 0).detach()\n",
    "        ## resample mu\n",
    "        obs_mu = resample_mu(obs_mu, weights_global)\n",
    "        ## update z -- cluster assignments\n",
    "        q_z, p_z = enc_z(obs, obs_mu, 1.5, 0.05, sample_size, batch_size)\n",
    "        log_p_z = p_z['zs'].log_prob\n",
    "        log_q_z = q_z['zs'].log_prob ## S * B * N\n",
    "        states = q_z['zs'].value\n",
    "        log_obs_n = Log_likelihood(obs, states, obs_mu, K, D, radius=1.5, noise_sigma = 0.05, gpu=gpu, cluster_flag=False)\n",
    "        log_weights_local = log_obs_n + log_p_z - log_q_z\n",
    "        weights_local = F.softmax(log_weights_local, 0).detach()\n",
    "\n",
    "    return q_mu, q_z\n",
    "\n",
    "def plot_samples(obs, q_eta, q_z, K, batch_size, PATH):\n",
    "    colors = ['r', 'b', 'g']\n",
    "    fig = plt.figure(figsize=(25,50))\n",
    "    xs = obs[0].cpu()\n",
    "    mu_mu = q_eta['means'].dist.loc[0].cpu().data.numpy()\n",
    "    mu_sigma = q_eta['means'].dist.scale[0].cpu().data.numpy()\n",
    "    zs = q_z['zs'].dist.probs[0].cpu().data.numpy()\n",
    "    for b in range(batch_size):\n",
    "        ax = fig.add_subplot(int(batch_size / 5), 5, b+1)\n",
    "        x = xs[b]\n",
    "        z = zs[b]\n",
    "        mu_mu_b = mu_mu[b]\n",
    "        mu_sigma_b = mu_sigma[b]\n",
    "        assignments = z.argmax(-1)\n",
    "        for k in range(K):\n",
    "            cov_k = np.diag(mu_sigma_b[k]**2)\n",
    "            xk = x[np.where(assignments == k)]\n",
    "            ax.scatter(xk[:, 0], xk[:, 1], c=colors[k], alpha=0.2)\n",
    "            plot_cov_ellipse(cov=cov_k, pos=mu_mu_b[k], nstd=2, ax=ax, alpha=1.0, color=colors[k])\n",
    "        ax.set_ylim([-5, 5])\n",
    "        ax.set_xlim([-5, 5])\n",
    "    plt.savefig('results/modes-' + PATH + '.svg')\n",
    "    \n",
    "obs = sample_single_batch(NUM_SEQS, N, K, D, SAMPLE_SIZE, BATCH_SIZE_TEST, gpu)\n",
    "q_mu, q_z = test(enc_mu, enc_z, obs, N, K, D, MCMC_SIZE, SAMPLE_SIZE, BATCH_SIZE_TEST, gpu)\n",
    "%time plot_samples(obs, q_mu, q_z, K, BATCH_SIZE_TEST, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
