{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.4.1 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../../../rings_fixed_radius\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "FIXED_RADIUS = 1.5\n",
    "\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 5 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_GLOBAL = 32\n",
    "NUM_HIDDEN_LOCAL = 64\n",
    "NUM_STATS = 16\n",
    "\n",
    "MCMC_SIZE = 10\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'AG-5rings-%dsteps-%dsamples' % (MCMC_SIZE, SAMPLE_SIZE)\n",
    "DEVICE = torch.device('cuda:1')\n",
    "\n",
    "obs_rad = torch.ones(1) * FIXED_RADIUS\n",
    "noise_sigma = torch.ones(1) * 0.05\n",
    "if CUDA:\n",
    "    obs_rad = obs_rad.cuda().to(DEVICE)\n",
    "    noise_sigma = noise_sigma.cuda().to(DEVICE)\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (obs_rad, noise_sigma, N, K, D, MCMC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc_mu import *\n",
    "from global_oneshot_mu import *\n",
    "from global_enc_mu_v1 import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_mu = Enc_mu(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "oneshot_mu = Oneshot_mu(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "if CUDA:\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_mu.cuda().to(DEVICE)\n",
    "    oneshot_mu.cuda().to(DEVICE)\n",
    "optimizer =  torch.optim.Adam(list(oneshot_mu.parameters())+list(enc_mu.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_mu, enc_mu, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_z.load_state_dict(torch.load(\"../weights/enc-z-%s\" % PATH))\n",
    "# enc_mu.load_state_dict(torch.load(\"../weights/enc-mu-%s\" % PATH))\n",
    "# oneshot_mu.load_state_dict(torch.load(\"../weights/oneshot-mu-%s\" % PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\500 (286s),  symKL_DB_eta: 610272.133,  symKL_DB_z: 1175882.313,  gap_eta: 610239.291,  gap_z: 1175427.469,  loss: -324203.777,  ess: 1.944\n",
      "epoch: 1\\500 (287s),  symKL_DB_eta: 41475.502,  symKL_DB_z: 524788.335,  gap_eta: 41477.705,  gap_z: 524674.737,  loss: -47177.493,  ess: 3.054\n",
      "epoch: 2\\500 (286s),  symKL_DB_eta: 12503.463,  symKL_DB_z: 117742.674,  gap_eta: 12504.476,  gap_z: 117690.386,  loss: -19323.881,  ess: 4.043\n",
      "epoch: 3\\500 (286s),  symKL_DB_eta: 4461.124,  symKL_DB_z: 27963.023,  gap_eta: 4461.881,  gap_z: 27930.502,  loss: -12893.469,  ess: 4.505\n",
      "epoch: 4\\500 (286s),  symKL_DB_eta: 2249.331,  symKL_DB_z: 11077.235,  gap_eta: 2249.635,  gap_z: 11051.890,  loss: -11687.064,  ess: 4.675\n",
      "epoch: 5\\500 (287s),  symKL_DB_eta: 1323.650,  symKL_DB_z: 7812.937,  gap_eta: 1323.559,  gap_z: 7790.745,  loss: -11289.405,  ess: 4.740\n",
      "epoch: 6\\500 (289s),  symKL_DB_eta: 903.397,  symKL_DB_z: 6875.072,  gap_eta: 902.739,  gap_z: 6855.280,  loss: -11155.594,  ess: 4.778\n",
      "epoch: 7\\500 (290s),  symKL_DB_eta: 710.482,  symKL_DB_z: 6401.773,  gap_eta: 708.027,  gap_z: 6379.912,  loss: -10713.484,  ess: 4.808\n",
      "epoch: 8\\500 (288s),  symKL_DB_eta: 613.422,  symKL_DB_z: 6068.271,  gap_eta: 611.719,  gap_z: 6051.392,  loss: -10661.625,  ess: 4.830\n",
      "epoch: 9\\500 (287s),  symKL_DB_eta: 558.996,  symKL_DB_z: 5840.394,  gap_eta: 556.277,  gap_z: 5821.704,  loss: -10644.362,  ess: 4.847\n",
      "epoch: 10\\500 (286s),  symKL_DB_eta: 521.319,  symKL_DB_z: 5705.959,  gap_eta: 517.716,  gap_z: 5688.279,  loss: -10401.226,  ess: 4.864\n",
      "epoch: 11\\500 (282s),  symKL_DB_eta: 498.068,  symKL_DB_z: 5528.300,  gap_eta: 493.800,  gap_z: 5511.688,  loss: -10434.229,  ess: 4.877\n",
      "epoch: 12\\500 (282s),  symKL_DB_eta: 478.775,  symKL_DB_z: 5412.199,  gap_eta: 473.571,  gap_z: 5395.693,  loss: -10181.841,  ess: 4.889\n",
      "epoch: 13\\500 (282s),  symKL_DB_eta: 464.531,  symKL_DB_z: 5299.610,  gap_eta: 459.158,  gap_z: 5281.699,  loss: -10076.042,  ess: 4.901\n",
      "epoch: 14\\500 (281s),  symKL_DB_eta: 459.256,  symKL_DB_z: 5201.961,  gap_eta: 453.424,  gap_z: 5184.122,  loss: -9836.345,  ess: 4.909\n",
      "epoch: 15\\500 (281s),  symKL_DB_eta: 445.587,  symKL_DB_z: 5133.254,  gap_eta: 438.094,  gap_z: 5113.637,  loss: -9623.037,  ess: 4.919\n",
      "epoch: 16\\500 (281s),  symKL_DB_eta: 438.896,  symKL_DB_z: 5022.280,  gap_eta: 431.563,  gap_z: 5006.692,  loss: -9376.744,  ess: 4.930\n",
      "epoch: 17\\500 (281s),  symKL_DB_eta: 439.273,  symKL_DB_z: 4935.297,  gap_eta: 427.063,  gap_z: 4914.416,  loss: -9260.182,  ess: 4.939\n",
      "epoch: 18\\500 (282s),  symKL_DB_eta: 421.324,  symKL_DB_z: 4848.401,  gap_eta: 412.403,  gap_z: 4826.485,  loss: -9037.237,  ess: 4.952\n",
      "epoch: 19\\500 (281s),  symKL_DB_eta: 426.678,  symKL_DB_z: 4699.686,  gap_eta: 414.653,  gap_z: 4675.728,  loss: -9018.523,  ess: 4.966\n",
      "epoch: 20\\500 (280s),  symKL_DB_eta: 416.820,  symKL_DB_z: 4504.957,  gap_eta: 403.039,  gap_z: 4480.086,  loss: -8795.293,  ess: 4.986\n",
      "epoch: 21\\500 (280s),  symKL_DB_eta: 420.582,  symKL_DB_z: 4271.603,  gap_eta: 395.727,  gap_z: 4224.333,  loss: -8758.089,  ess: 5.013\n",
      "epoch: 22\\500 (281s),  symKL_DB_eta: 408.467,  symKL_DB_z: 3920.247,  gap_eta: 384.687,  gap_z: 3889.997,  loss: -8520.810,  ess: 5.045\n",
      "epoch: 23\\500 (280s),  symKL_DB_eta: 480.281,  symKL_DB_z: 3498.591,  gap_eta: 380.533,  gap_z: 3458.040,  loss: -8393.035,  ess: 5.077\n",
      "epoch: 24\\500 (280s),  symKL_DB_eta: 427.770,  symKL_DB_z: 3027.906,  gap_eta: 375.863,  gap_z: 2964.707,  loss: -8388.051,  ess: 5.120\n",
      "epoch: 25\\500 (280s),  symKL_DB_eta: 561.153,  symKL_DB_z: 2541.200,  gap_eta: 379.870,  gap_z: 2465.577,  loss: -8457.828,  ess: 5.160\n",
      "epoch: 26\\500 (281s),  symKL_DB_eta: 515.213,  symKL_DB_z: 2104.680,  gap_eta: 375.400,  gap_z: 2040.284,  loss: -8488.304,  ess: 5.203\n",
      "epoch: 27\\500 (281s),  symKL_DB_eta: 644.196,  symKL_DB_z: 1748.811,  gap_eta: 377.452,  gap_z: 1658.648,  loss: -8403.405,  ess: 5.244\n",
      "epoch: 28\\500 (280s),  symKL_DB_eta: 806.728,  symKL_DB_z: 1451.969,  gap_eta: 375.739,  gap_z: 1366.796,  loss: -8280.729,  ess: 5.280\n",
      "epoch: 29\\500 (280s),  symKL_DB_eta: 589.189,  symKL_DB_z: 1233.117,  gap_eta: 381.962,  gap_z: 1147.370,  loss: -8410.918,  ess: 5.307\n",
      "epoch: 30\\500 (281s),  symKL_DB_eta: 824.085,  symKL_DB_z: 1004.458,  gap_eta: 372.954,  gap_z: 946.746,  loss: -8353.127,  ess: 5.334\n",
      "epoch: 31\\500 (280s),  symKL_DB_eta: 595.508,  symKL_DB_z: 907.107,  gap_eta: 372.436,  gap_z: 824.528,  loss: -8387.953,  ess: 5.362\n",
      "epoch: 32\\500 (280s),  symKL_DB_eta: 699.911,  symKL_DB_z: 843.114,  gap_eta: 378.647,  gap_z: 721.488,  loss: -8264.073,  ess: 5.377\n",
      "epoch: 33\\500 (280s),  symKL_DB_eta: 696.388,  symKL_DB_z: 755.258,  gap_eta: 373.716,  gap_z: 641.319,  loss: -8301.091,  ess: 5.403\n",
      "epoch: 34\\500 (280s),  symKL_DB_eta: 552.669,  symKL_DB_z: 694.833,  gap_eta: 372.042,  gap_z: 582.454,  loss: -8408.918,  ess: 5.417\n",
      "epoch: 35\\500 (280s),  symKL_DB_eta: 738.558,  symKL_DB_z: 632.476,  gap_eta: 369.193,  gap_z: 542.230,  loss: -8375.074,  ess: 5.437\n",
      "epoch: 36\\500 (280s),  symKL_DB_eta: 874.619,  symKL_DB_z: 596.675,  gap_eta: 379.006,  gap_z: 477.753,  loss: -8508.705,  ess: 5.445\n",
      "epoch: 37\\500 (281s),  symKL_DB_eta: 813.014,  symKL_DB_z: 523.186,  gap_eta: 374.028,  gap_z: 439.170,  loss: -8269.334,  ess: 5.461\n",
      "epoch: 38\\500 (280s),  symKL_DB_eta: 587.475,  symKL_DB_z: 499.043,  gap_eta: 372.129,  gap_z: 409.937,  loss: -8301.318,  ess: 5.469\n",
      "epoch: 39\\500 (281s),  symKL_DB_eta: 682.031,  symKL_DB_z: 538.966,  gap_eta: 371.585,  gap_z: 404.530,  loss: -8125.660,  ess: 5.483\n",
      "epoch: 40\\500 (280s),  symKL_DB_eta: 698.296,  symKL_DB_z: 481.531,  gap_eta: 375.429,  gap_z: 391.289,  loss: -8448.138,  ess: 5.491\n",
      "epoch: 41\\500 (281s),  symKL_DB_eta: 761.718,  symKL_DB_z: 434.179,  gap_eta: 368.825,  gap_z: 361.705,  loss: -8386.605,  ess: 5.509\n",
      "epoch: 42\\500 (281s),  symKL_DB_eta: 656.263,  symKL_DB_z: 422.059,  gap_eta: 369.621,  gap_z: 317.189,  loss: -8443.318,  ess: 5.515\n",
      "epoch: 43\\500 (281s),  symKL_DB_eta: 716.445,  symKL_DB_z: 389.388,  gap_eta: 375.326,  gap_z: 323.150,  loss: -8873.874,  ess: 5.513\n",
      "epoch: 44\\500 (281s),  symKL_DB_eta: 740.522,  symKL_DB_z: 398.667,  gap_eta: 372.765,  gap_z: 303.557,  loss: -8385.756,  ess: 5.528\n",
      "epoch: 45\\500 (280s),  symKL_DB_eta: 681.636,  symKL_DB_z: 357.895,  gap_eta: 371.973,  gap_z: 274.039,  loss: -8383.767,  ess: 5.534\n",
      "epoch: 46\\500 (280s),  symKL_DB_eta: 588.754,  symKL_DB_z: 402.106,  gap_eta: 365.654,  gap_z: 266.832,  loss: -8486.996,  ess: 5.542\n",
      "epoch: 47\\500 (281s),  symKL_DB_eta: 635.356,  symKL_DB_z: 318.786,  gap_eta: 359.154,  gap_z: 234.491,  loss: -8180.182,  ess: 5.555\n",
      "epoch: 48\\500 (280s),  symKL_DB_eta: 530.233,  symKL_DB_z: 298.116,  gap_eta: 366.749,  gap_z: 240.890,  loss: -8349.813,  ess: 5.552\n",
      "epoch: 49\\500 (281s),  symKL_DB_eta: 912.121,  symKL_DB_z: 336.076,  gap_eta: 368.913,  gap_z: 216.849,  loss: -8484.388,  ess: 5.561\n",
      "epoch: 50\\500 (280s),  symKL_DB_eta: 835.767,  symKL_DB_z: 318.796,  gap_eta: 370.719,  gap_z: 216.101,  loss: -8558.920,  ess: 5.564\n",
      "epoch: 51\\500 (281s),  symKL_DB_eta: 1072.481,  symKL_DB_z: 329.990,  gap_eta: 367.124,  gap_z: 208.753,  loss: -8410.675,  ess: 5.570\n",
      "epoch: 52\\500 (280s),  symKL_DB_eta: 743.280,  symKL_DB_z: 273.729,  gap_eta: 364.719,  gap_z: 196.433,  loss: -8519.127,  ess: 5.584\n",
      "epoch: 53\\500 (281s),  symKL_DB_eta: 627.988,  symKL_DB_z: 269.558,  gap_eta: 362.750,  gap_z: 190.176,  loss: -8352.526,  ess: 5.584\n",
      "epoch: 54\\500 (281s),  symKL_DB_eta: 739.682,  symKL_DB_z: 242.469,  gap_eta: 363.393,  gap_z: 178.388,  loss: -8312.149,  ess: 5.591\n",
      "epoch: 55\\500 (281s),  symKL_DB_eta: 676.257,  symKL_DB_z: 236.273,  gap_eta: 364.079,  gap_z: 158.664,  loss: -8331.457,  ess: 5.591\n",
      "epoch: 56\\500 (280s),  symKL_DB_eta: 927.575,  symKL_DB_z: 240.630,  gap_eta: 365.617,  gap_z: 157.101,  loss: -8567.699,  ess: 5.597\n",
      "epoch: 57\\500 (280s),  symKL_DB_eta: 793.669,  symKL_DB_z: 262.237,  gap_eta: 367.539,  gap_z: 150.805,  loss: -8296.280,  ess: 5.598\n",
      "epoch: 58\\500 (281s),  symKL_DB_eta: 643.140,  symKL_DB_z: 224.184,  gap_eta: 370.008,  gap_z: 150.720,  loss: -8555.221,  ess: 5.602\n",
      "epoch: 59\\500 (283s),  symKL_DB_eta: 707.877,  symKL_DB_z: 251.785,  gap_eta: 372.698,  gap_z: 142.773,  loss: -8668.864,  ess: 5.603\n",
      "epoch: 60\\500 (283s),  symKL_DB_eta: 637.267,  symKL_DB_z: 256.173,  gap_eta: 370.834,  gap_z: 136.571,  loss: -8491.850,  ess: 5.608\n",
      "epoch: 61\\500 (284s),  symKL_DB_eta: 963.502,  symKL_DB_z: 236.895,  gap_eta: 365.052,  gap_z: 129.307,  loss: -8444.790,  ess: 5.617\n",
      "epoch: 62\\500 (282s),  symKL_DB_eta: 840.645,  symKL_DB_z: 225.932,  gap_eta: 369.100,  gap_z: 125.045,  loss: -8493.967,  ess: 5.617\n",
      "epoch: 63\\500 (281s),  symKL_DB_eta: 723.132,  symKL_DB_z: 203.821,  gap_eta: 370.521,  gap_z: 123.486,  loss: -8642.954,  ess: 5.622\n"
     ]
    }
   ],
   "source": [
    "from ag_ep import *\n",
    "train(models, EUBO_fixed_radi, optimizer, Data, Model_Params, Train_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(enc_z.state_dict(), \"../weights/enc-z-%s\" % PATH)\n",
    "# torch.save(enc_mu.state_dict(), \"../weights/enc-mu-%s\" % PATH)\n",
    "# torch.save(oneshot_mu.state_dict(), \"../weights/oneshot-mu-%s\" % PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ag_ep import *\n",
    "BATCH_SIZE_TEST = 50\n",
    "Train_Params_Test = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE_TEST, CUDA, DEVICE, PATH)\n",
    "\n",
    "obs, metric_step, reused = test(models, EUBO_fixed_radi, Data, Model_Params, Train_Params_Test)\n",
    "(q_mu, _, q_z, _) = reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time plot_samples(obs, q_mu, q_z, K, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
