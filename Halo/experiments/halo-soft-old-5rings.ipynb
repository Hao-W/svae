{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.4.1 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../../../rings_fixed_radius\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "FIXED_RADIUS = 1.5\n",
    "\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 5 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_GLOBAL = 128\n",
    "NUM_HIDDEN_LOCAL = 64\n",
    "NUM_STATS = 64\n",
    "\n",
    "MCMC_SIZE = 10\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 5 * 1e-4\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'soft-5rings-%dsteps-%dsamples' % (MCMC_SIZE, SAMPLE_SIZE)\n",
    "DEVICE = torch.device('cuda:1')\n",
    "\n",
    "obs_rad = torch.ones(1) * FIXED_RADIUS\n",
    "noise_sigma = torch.ones(1) * 0.05\n",
    "if CUDA:\n",
    "    obs_rad = obs_rad.cuda().to(DEVICE)\n",
    "    noise_sigma = noise_sigma.cuda().to(DEVICE)\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (obs_rad, noise_sigma, N, K, D, MCMC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc_mu import *\n",
    "from global_oneshot_mu_v2 import *\n",
    "from global_enc_mu_v2 import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_mu = Enc_mu(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "oneshot_mu = Oneshot_mu(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "if CUDA:\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_mu.cuda().to(DEVICE)\n",
    "    oneshot_mu.cuda().to(DEVICE)\n",
    "optimizer =  torch.optim.Adam(list(oneshot_mu.parameters())+list(enc_mu.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_mu, enc_mu, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_z.load_state_dict(torch.load(\"../weights/enc-z-%s\" % PATH))\n",
    "# enc_mu.load_state_dict(torch.load(\"../weights/enc-mu-%s\" % PATH))\n",
    "# oneshot_mu.load_state_dict(torch.load(\"../weights/oneshot-mu-%s\" % PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\100 (205s),  symKL_DB_eta: 174293.544,  symKL_DB_z: 837953.084,  gap_eta: 174189.445,  gap_z: 837725.119,  loss: -112545.520,  ess: 2.669\n",
      "epoch: 1\\100 (206s),  symKL_DB_eta: 45749.752,  symKL_DB_z: 82385.582,  gap_eta: 45714.251,  gap_z: 82241.010,  loss: -41350.094,  ess: 4.158\n",
      "epoch: 2\\100 (207s),  symKL_DB_eta: 17280.132,  symKL_DB_z: 15578.319,  gap_eta: 17270.907,  gap_z: 15476.452,  loss: -26646.518,  ess: 4.573\n",
      "epoch: 3\\100 (206s),  symKL_DB_eta: 11342.409,  symKL_DB_z: 8251.699,  gap_eta: 11335.425,  gap_z: 8166.728,  loss: -20051.505,  ess: 4.676\n",
      "epoch: 4\\100 (205s),  symKL_DB_eta: 8651.696,  symKL_DB_z: 6768.798,  gap_eta: 8647.467,  gap_z: 6692.402,  loss: -16690.096,  ess: 4.712\n",
      "epoch: 5\\100 (205s),  symKL_DB_eta: 6968.922,  symKL_DB_z: 6140.915,  gap_eta: 6952.200,  gap_z: 6063.610,  loss: -14480.888,  ess: 4.730\n",
      "epoch: 6\\100 (205s),  symKL_DB_eta: 5776.094,  symKL_DB_z: 5780.427,  gap_eta: 5759.877,  gap_z: 5690.884,  loss: -12838.696,  ess: 4.741\n",
      "epoch: 7\\100 (205s),  symKL_DB_eta: 5012.959,  symKL_DB_z: 5510.435,  gap_eta: 4927.508,  gap_z: 5400.515,  loss: -11652.555,  ess: 4.752\n",
      "epoch: 8\\100 (204s),  symKL_DB_eta: 4652.310,  symKL_DB_z: 5231.893,  gap_eta: 4481.667,  gap_z: 5115.240,  loss: -11261.009,  ess: 4.768\n",
      "epoch: 9\\100 (204s),  symKL_DB_eta: 4456.896,  symKL_DB_z: 5008.414,  gap_eta: 3971.573,  gap_z: 4834.668,  loss: -10339.538,  ess: 4.783\n",
      "epoch: 10\\100 (204s),  symKL_DB_eta: 4181.446,  symKL_DB_z: 4529.613,  gap_eta: 3549.423,  gap_z: 4354.810,  loss: -9651.191,  ess: 4.809\n",
      "epoch: 11\\100 (204s),  symKL_DB_eta: 4152.041,  symKL_DB_z: 3697.818,  gap_eta: 3126.554,  gap_z: 3451.514,  loss: -9147.196,  ess: 4.872\n",
      "epoch: 12\\100 (202s),  symKL_DB_eta: 4106.127,  symKL_DB_z: 2565.233,  gap_eta: 2938.412,  gap_z: 2326.073,  loss: -8907.238,  ess: 4.956\n",
      "epoch: 13\\100 (202s),  symKL_DB_eta: 4344.356,  symKL_DB_z: 1862.955,  gap_eta: 2768.286,  gap_z: 1482.770,  loss: -8944.854,  ess: 5.037\n",
      "epoch: 14\\100 (202s),  symKL_DB_eta: 4092.397,  symKL_DB_z: 1175.475,  gap_eta: 2665.329,  gap_z: 986.841,  loss: -8826.642,  ess: 5.097\n",
      "epoch: 15\\100 (202s),  symKL_DB_eta: 6409.119,  symKL_DB_z: 1089.432,  gap_eta: 2575.862,  gap_z: 754.064,  loss: -8830.768,  ess: 5.138\n",
      "epoch: 16\\100 (202s),  symKL_DB_eta: 4798.616,  symKL_DB_z: 958.810,  gap_eta: 2546.031,  gap_z: 592.942,  loss: -8832.371,  ess: 5.168\n",
      "epoch: 17\\100 (202s),  symKL_DB_eta: 3697.545,  symKL_DB_z: 813.938,  gap_eta: 2415.695,  gap_z: 479.309,  loss: -8663.705,  ess: 5.192\n",
      "epoch: 18\\100 (202s),  symKL_DB_eta: 3396.322,  symKL_DB_z: 742.982,  gap_eta: 2367.317,  gap_z: 447.247,  loss: -8579.135,  ess: 5.212\n",
      "epoch: 19\\100 (202s),  symKL_DB_eta: 3847.254,  symKL_DB_z: 661.223,  gap_eta: 2386.176,  gap_z: 379.682,  loss: -8771.881,  ess: 5.224\n",
      "epoch: 20\\100 (202s),  symKL_DB_eta: 3641.966,  symKL_DB_z: 641.127,  gap_eta: 2294.402,  gap_z: 387.134,  loss: -9068.317,  ess: 5.238\n",
      "epoch: 21\\100 (203s),  symKL_DB_eta: 2808.687,  symKL_DB_z: 682.441,  gap_eta: 2190.603,  gap_z: 300.796,  loss: -8467.888,  ess: 5.251\n",
      "epoch: 22\\100 (203s),  symKL_DB_eta: 4712.289,  symKL_DB_z: 693.215,  gap_eta: 2183.822,  gap_z: 325.361,  loss: -8823.270,  ess: 5.261\n",
      "epoch: 23\\100 (206s),  symKL_DB_eta: 4220.194,  symKL_DB_z: 527.915,  gap_eta: 2162.335,  gap_z: 226.890,  loss: -8513.482,  ess: 5.270\n",
      "epoch: 24\\100 (203s),  symKL_DB_eta: 3365.375,  symKL_DB_z: 520.967,  gap_eta: 2146.689,  gap_z: 251.944,  loss: -8703.008,  ess: 5.276\n",
      "epoch: 25\\100 (203s),  symKL_DB_eta: 3428.764,  symKL_DB_z: 539.976,  gap_eta: 2160.850,  gap_z: 224.644,  loss: -8709.985,  ess: 5.284\n",
      "epoch: 26\\100 (203s),  symKL_DB_eta: 3260.895,  symKL_DB_z: 652.742,  gap_eta: 2138.096,  gap_z: 211.507,  loss: -8909.086,  ess: 5.292\n",
      "epoch: 27\\100 (204s),  symKL_DB_eta: 5556.055,  symKL_DB_z: 549.965,  gap_eta: 2131.458,  gap_z: 171.792,  loss: -8716.167,  ess: 5.297\n",
      "epoch: 28\\100 (203s),  symKL_DB_eta: 4109.618,  symKL_DB_z: 444.320,  gap_eta: 2098.140,  gap_z: 170.815,  loss: -9057.481,  ess: 5.303\n",
      "epoch: 29\\100 (202s),  symKL_DB_eta: 3887.773,  symKL_DB_z: 426.234,  gap_eta: 2069.411,  gap_z: 143.222,  loss: -8617.565,  ess: 5.309\n",
      "epoch: 30\\100 (202s),  symKL_DB_eta: 4842.109,  symKL_DB_z: 365.420,  gap_eta: 2123.460,  gap_z: 126.335,  loss: -8822.036,  ess: 5.312\n",
      "epoch: 31\\100 (204s),  symKL_DB_eta: 4836.345,  symKL_DB_z: 528.317,  gap_eta: 2057.529,  gap_z: 112.880,  loss: -8787.643,  ess: 5.319\n",
      "epoch: 32\\100 (204s),  symKL_DB_eta: 4881.789,  symKL_DB_z: 400.790,  gap_eta: 1955.459,  gap_z: 118.762,  loss: -8513.583,  ess: 5.324\n",
      "epoch: 33\\100 (204s),  symKL_DB_eta: 6209.481,  symKL_DB_z: 433.366,  gap_eta: 1945.582,  gap_z: 105.746,  loss: -8633.753,  ess: 5.329\n",
      "epoch: 34\\100 (203s),  symKL_DB_eta: 4953.203,  symKL_DB_z: 566.937,  gap_eta: 1931.962,  gap_z: 100.274,  loss: -8778.266,  ess: 5.333\n",
      "epoch: 35\\100 (202s),  symKL_DB_eta: 3336.675,  symKL_DB_z: 555.087,  gap_eta: 1953.011,  gap_z: 90.193,  loss: -8663.267,  ess: 5.336\n",
      "epoch: 36\\100 (203s),  symKL_DB_eta: 4084.885,  symKL_DB_z: 473.230,  gap_eta: 1903.021,  gap_z: 90.729,  loss: -8556.465,  ess: 5.341\n",
      "epoch: 37\\100 (203s),  symKL_DB_eta: 5725.629,  symKL_DB_z: 629.904,  gap_eta: 1866.907,  gap_z: 95.038,  loss: -8650.748,  ess: 5.346\n",
      "epoch: 38\\100 (202s),  symKL_DB_eta: 4118.811,  symKL_DB_z: 417.900,  gap_eta: 1865.861,  gap_z: 77.192,  loss: -8414.880,  ess: 5.348\n",
      "epoch: 39\\100 (202s),  symKL_DB_eta: 4195.870,  symKL_DB_z: 505.137,  gap_eta: 1885.419,  gap_z: 81.386,  loss: -8512.176,  ess: 5.350\n",
      "epoch: 40\\100 (202s),  symKL_DB_eta: 4519.573,  symKL_DB_z: 455.792,  gap_eta: 1835.459,  gap_z: 76.993,  loss: -8582.410,  ess: 5.355\n",
      "epoch: 41\\100 (202s),  symKL_DB_eta: 4258.376,  symKL_DB_z: 446.511,  gap_eta: 1851.392,  gap_z: 66.102,  loss: -8857.179,  ess: 5.357\n",
      "epoch: 42\\100 (203s),  symKL_DB_eta: 4673.746,  symKL_DB_z: 418.393,  gap_eta: 1868.595,  gap_z: 67.046,  loss: -8796.304,  ess: 5.360\n",
      "epoch: 43\\100 (204s),  symKL_DB_eta: 5309.619,  symKL_DB_z: 506.755,  gap_eta: 1804.146,  gap_z: 56.726,  loss: -8627.085,  ess: 5.364\n",
      "epoch: 44\\100 (206s),  symKL_DB_eta: 6967.091,  symKL_DB_z: 438.734,  gap_eta: 1747.243,  gap_z: 54.268,  loss: -8379.343,  ess: 5.368\n",
      "epoch: 45\\100 (206s),  symKL_DB_eta: 3873.187,  symKL_DB_z: 453.786,  gap_eta: 1754.074,  gap_z: 56.295,  loss: -8533.724,  ess: 5.369\n",
      "epoch: 46\\100 (207s),  symKL_DB_eta: 4699.371,  symKL_DB_z: 519.533,  gap_eta: 1685.347,  gap_z: 53.564,  loss: -8585.493,  ess: 5.373\n",
      "epoch: 47\\100 (207s),  symKL_DB_eta: 5950.307,  symKL_DB_z: 457.569,  gap_eta: 1665.766,  gap_z: 53.129,  loss: -8609.561,  ess: 5.375\n",
      "epoch: 48\\100 (207s),  symKL_DB_eta: 4514.277,  symKL_DB_z: 390.132,  gap_eta: 1679.493,  gap_z: 49.020,  loss: -8526.446,  ess: 5.376\n",
      "epoch: 49\\100 (207s),  symKL_DB_eta: 4337.232,  symKL_DB_z: 477.636,  gap_eta: 1688.296,  gap_z: 49.141,  loss: -8723.594,  ess: 5.378\n"
     ]
    }
   ],
   "source": [
    "from ag_ep import *\n",
    "train(models, EUBO_fixed_radi, optimizer, Data, Model_Params, Train_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(enc_z.state_dict(), \"../weights/enc-z-%s\" % PATH)\n",
    "# torch.save(enc_mu.state_dict(), \"../weights/enc-mu-%s\" % PATH)\n",
    "# torch.save(oneshot_mu.state_dict(), \"../weights/oneshot-mu-%s\" % PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ag_ep import *\n",
    "BATCH_SIZE_TEST = 50\n",
    "Train_Params_Test = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE_TEST, CUDA, DEVICE, PATH)\n",
    "\n",
    "obs, metric_step, reused = test(models, EUBO_fixed_radi, Data, Model_Params, Train_Params_Test)\n",
    "(q_mu, _, q_z, _) = reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time plot_samples(obs, q_mu, q_z, K, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
