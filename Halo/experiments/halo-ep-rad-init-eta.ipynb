{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.1.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../../../rings_varying_radius_c2k\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 3 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_GLOBAL = 16\n",
    "NUM_HIDDEN_LOCAL = 64\n",
    "NUM_STATS = 16\n",
    "\n",
    "MCMC_SIZE = 50\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'ep-rad-init-eta'\n",
    "DEVICE = torch.device('cuda:0')\n",
    "\n",
    "noise_sigma = torch.ones(1) * 0.05\n",
    "if CUDA:\n",
    "    noise_sigma = noise_sigma.cuda().to(DEVICE)\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (noise_sigma, N, K, D, MCMC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc import *\n",
    "from global_oneshot import *\n",
    "from global_enc import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "oneshot_eta = Oneshot_eta(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_eta = Enc_eta(K, D, NUM_HIDDEN_GLOBAL, NUM_STATS, CUDA, DEVICE, Reparameterized)\n",
    "if CUDA:\n",
    "    oneshot_eta.cuda().to(DEVICE)\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_eta.cuda().to(DEVICE)\n",
    "\n",
    "optimizer =  torch.optim.Adam(list(oneshot_eta.parameters())+list(enc_eta.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_eta, enc_eta, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_z.load_state_dict(torch.load(\"../weights/enc-z-%s\" % PATH))\n",
    "# enc_eta.load_state_dict(torch.load(\"../weights/enc-mu-%s\" % PATH))\n",
    "# oneshot_eta.load_state_dict(torch.load(\"../weights/oneshot-mu-%s\" % PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\1000 (116s),  symKL_DB_eta: 378219.768,  symKL_DB_z: 183424.157,  gap: 561319.422,  loss: -95856.770,  ess: 2.348\n",
      "epoch: 1\\1000 (114s),  symKL_DB_eta: 130937.893,  symKL_DB_z: 139181.093,  gap: 270015.733,  loss: -47145.227,  ess: 2.728\n",
      "epoch: 2\\1000 (114s),  symKL_DB_eta: 47855.182,  symKL_DB_z: 94375.288,  gap: 142176.955,  loss: -33846.869,  ess: 3.392\n",
      "epoch: 3\\1000 (114s),  symKL_DB_eta: 31886.123,  symKL_DB_z: 45865.406,  gap: 77703.048,  loss: -28320.518,  ess: 3.891\n",
      "epoch: 4\\1000 (114s),  symKL_DB_eta: 26208.121,  symKL_DB_z: 29102.649,  gap: 55257.629,  loss: -26647.406,  ess: 4.132\n",
      "epoch: 5\\1000 (114s),  symKL_DB_eta: 24264.864,  symKL_DB_z: 19257.556,  gap: 43474.115,  loss: -25718.781,  ess: 4.326\n",
      "epoch: 6\\1000 (114s),  symKL_DB_eta: 22423.486,  symKL_DB_z: 13550.641,  gap: 35932.785,  loss: -25056.917,  ess: 4.484\n",
      "epoch: 7\\1000 (114s),  symKL_DB_eta: 21955.730,  symKL_DB_z: 10072.207,  gap: 31980.595,  loss: -25228.878,  ess: 4.594\n",
      "epoch: 8\\1000 (114s),  symKL_DB_eta: 21770.922,  symKL_DB_z: 7724.615,  gap: 29453.660,  loss: -24918.796,  ess: 4.687\n",
      "epoch: 9\\1000 (114s),  symKL_DB_eta: 20622.298,  symKL_DB_z: 5832.509,  gap: 26414.313,  loss: -24383.681,  ess: 4.774\n",
      "epoch: 10\\1000 (114s),  symKL_DB_eta: 20404.210,  symKL_DB_z: 4742.765,  gap: 25109.283,  loss: -23750.249,  ess: 4.816\n",
      "epoch: 11\\1000 (113s),  symKL_DB_eta: 20167.743,  symKL_DB_z: 3902.143,  gap: 24021.138,  loss: -23711.241,  ess: 4.854\n",
      "epoch: 12\\1000 (113s),  symKL_DB_eta: 19558.253,  symKL_DB_z: 3202.488,  gap: 22714.256,  loss: -23611.069,  ess: 4.901\n",
      "epoch: 13\\1000 (114s),  symKL_DB_eta: 19410.383,  symKL_DB_z: 2777.341,  gap: 22140.505,  loss: -23946.321,  ess: 4.921\n",
      "epoch: 14\\1000 (114s),  symKL_DB_eta: 18896.628,  symKL_DB_z: 2320.832,  gap: 21172.821,  loss: -23944.207,  ess: 4.966\n",
      "epoch: 15\\1000 (114s),  symKL_DB_eta: 19114.704,  symKL_DB_z: 2057.986,  gap: 21123.308,  loss: -24384.874,  ess: 4.990\n",
      "epoch: 16\\1000 (114s),  symKL_DB_eta: 18624.356,  symKL_DB_z: 1774.017,  gap: 20348.406,  loss: -24552.931,  ess: 5.017\n",
      "epoch: 17\\1000 (113s),  symKL_DB_eta: 17759.737,  symKL_DB_z: 1553.637,  gap: 19251.437,  loss: -24311.270,  ess: 5.046\n",
      "epoch: 18\\1000 (114s),  symKL_DB_eta: 17116.141,  symKL_DB_z: 1362.786,  gap: 18425.411,  loss: -24251.215,  ess: 5.068\n",
      "epoch: 19\\1000 (114s),  symKL_DB_eta: 16403.057,  symKL_DB_z: 1192.967,  gap: 17543.923,  loss: -23272.779,  ess: 5.085\n",
      "epoch: 20\\1000 (114s),  symKL_DB_eta: 15961.102,  symKL_DB_z: 1075.649,  gap: 16989.880,  loss: -23427.588,  ess: 5.105\n",
      "epoch: 21\\1000 (114s),  symKL_DB_eta: 15337.265,  symKL_DB_z: 971.062,  gap: 16267.002,  loss: -23446.545,  ess: 5.120\n",
      "epoch: 22\\1000 (114s),  symKL_DB_eta: 14546.800,  symKL_DB_z: 887.782,  gap: 15388.589,  loss: -23688.253,  ess: 5.135\n",
      "epoch: 23\\1000 (114s),  symKL_DB_eta: 14139.563,  symKL_DB_z: 826.264,  gap: 14920.596,  loss: -24124.664,  ess: 5.148\n",
      "epoch: 24\\1000 (113s),  symKL_DB_eta: 13819.071,  symKL_DB_z: 769.084,  gap: 14540.019,  loss: -24288.511,  ess: 5.158\n",
      "epoch: 25\\1000 (114s),  symKL_DB_eta: 12611.316,  symKL_DB_z: 715.997,  gap: 13285.072,  loss: -23928.544,  ess: 5.166\n",
      "epoch: 26\\1000 (114s),  symKL_DB_eta: 11733.907,  symKL_DB_z: 636.608,  gap: 12334.333,  loss: -23149.058,  ess: 5.180\n",
      "epoch: 27\\1000 (113s),  symKL_DB_eta: 11303.238,  symKL_DB_z: 609.113,  gap: 11866.382,  loss: -23924.327,  ess: 5.189\n",
      "epoch: 28\\1000 (114s),  symKL_DB_eta: 10538.864,  symKL_DB_z: 575.483,  gap: 11058.234,  loss: -23935.160,  ess: 5.200\n",
      "epoch: 29\\1000 (114s),  symKL_DB_eta: 9791.760,  symKL_DB_z: 535.639,  gap: 10292.256,  loss: -24064.055,  ess: 5.207\n",
      "epoch: 30\\1000 (113s),  symKL_DB_eta: 9143.732,  symKL_DB_z: 512.763,  gap: 9614.325,  loss: -23335.696,  ess: 5.206\n",
      "epoch: 31\\1000 (112s),  symKL_DB_eta: 8624.229,  symKL_DB_z: 476.307,  gap: 9057.367,  loss: -23519.916,  ess: 5.220\n",
      "epoch: 32\\1000 (113s),  symKL_DB_eta: 8250.409,  symKL_DB_z: 444.608,  gap: 8661.429,  loss: -22794.516,  ess: 5.227\n",
      "epoch: 33\\1000 (113s),  symKL_DB_eta: 7816.683,  symKL_DB_z: 427.455,  gap: 8205.389,  loss: -22818.959,  ess: 5.225\n",
      "epoch: 34\\1000 (114s),  symKL_DB_eta: 7683.910,  symKL_DB_z: 405.721,  gap: 8051.193,  loss: -22999.627,  ess: 5.239\n",
      "epoch: 35\\1000 (115s),  symKL_DB_eta: 7525.705,  symKL_DB_z: 387.919,  gap: 7871.981,  loss: -22890.503,  ess: 5.240\n",
      "epoch: 36\\1000 (113s),  symKL_DB_eta: 7039.218,  symKL_DB_z: 375.286,  gap: 7367.051,  loss: -22870.676,  ess: 5.249\n",
      "epoch: 37\\1000 (113s),  symKL_DB_eta: 6986.703,  symKL_DB_z: 364.433,  gap: 7309.272,  loss: -22567.943,  ess: 5.248\n",
      "epoch: 38\\1000 (113s),  symKL_DB_eta: 6805.984,  symKL_DB_z: 350.867,  gap: 7118.802,  loss: -22553.478,  ess: 5.253\n",
      "epoch: 39\\1000 (114s),  symKL_DB_eta: 6469.480,  symKL_DB_z: 320.592,  gap: 6751.895,  loss: -22244.800,  ess: 5.264\n",
      "epoch: 40\\1000 (114s),  symKL_DB_eta: 6266.799,  symKL_DB_z: 321.519,  gap: 6544.990,  loss: -21260.219,  ess: 5.258\n",
      "epoch: 41\\1000 (113s),  symKL_DB_eta: 6034.065,  symKL_DB_z: 303.014,  gap: 6299.478,  loss: -21598.439,  ess: 5.267\n",
      "epoch: 42\\1000 (113s),  symKL_DB_eta: 5925.806,  symKL_DB_z: 295.489,  gap: 6182.098,  loss: -20620.117,  ess: 5.269\n",
      "epoch: 43\\1000 (114s),  symKL_DB_eta: 5804.599,  symKL_DB_z: 281.157,  gap: 6056.424,  loss: -21116.371,  ess: 5.272\n",
      "epoch: 44\\1000 (114s),  symKL_DB_eta: 5650.180,  symKL_DB_z: 270.184,  gap: 5892.667,  loss: -20728.579,  ess: 5.276\n",
      "epoch: 45\\1000 (114s),  symKL_DB_eta: 5618.965,  symKL_DB_z: 267.440,  gap: 5846.588,  loss: -20071.989,  ess: 5.276\n",
      "epoch: 46\\1000 (113s),  symKL_DB_eta: 5614.322,  symKL_DB_z: 251.200,  gap: 5818.491,  loss: -21045.492,  ess: 5.287\n",
      "epoch: 47\\1000 (113s),  symKL_DB_eta: 5648.576,  symKL_DB_z: 288.710,  gap: 5873.075,  loss: -21419.391,  ess: 5.289\n",
      "epoch: 48\\1000 (103s),  symKL_DB_eta: 5597.920,  symKL_DB_z: 251.274,  gap: 5816.891,  loss: -21275.543,  ess: 5.290\n",
      "epoch: 49\\1000 (83s),  symKL_DB_eta: 5765.121,  symKL_DB_z: 260.340,  gap: 5982.953,  loss: -21892.559,  ess: 5.294\n",
      "epoch: 50\\1000 (84s),  symKL_DB_eta: 5648.948,  symKL_DB_z: 240.900,  gap: 5851.774,  loss: -21552.905,  ess: 5.294\n",
      "epoch: 51\\1000 (90s),  symKL_DB_eta: 5359.978,  symKL_DB_z: 233.628,  gap: 5559.580,  loss: -20692.275,  ess: 5.298\n",
      "epoch: 52\\1000 (91s),  symKL_DB_eta: 5213.149,  symKL_DB_z: 223.589,  gap: 5410.054,  loss: -21242.202,  ess: 5.302\n",
      "epoch: 53\\1000 (91s),  symKL_DB_eta: 5153.640,  symKL_DB_z: 221.803,  gap: 5344.271,  loss: -20555.040,  ess: 5.301\n",
      "epoch: 54\\1000 (91s),  symKL_DB_eta: 5255.923,  symKL_DB_z: 218.183,  gap: 5444.671,  loss: -20998.791,  ess: 5.306\n",
      "epoch: 55\\1000 (91s),  symKL_DB_eta: 5470.731,  symKL_DB_z: 281.562,  gap: 5665.890,  loss: -21660.584,  ess: 5.304\n"
     ]
    }
   ],
   "source": [
    "from ag_ep_rad import *\n",
    "train(models, EUBO_init_eta, optimizer, Data, Model_Params, Train_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc_z.state_dict(), \"../weights/enc-z-ep-rad-init-eta\")\n",
    "torch.save(enc_eta.state_dict(), \"../weights/enc-mu-ep-rad-init-eta\")\n",
    "torch.save(oneshot_eta.state_dict(), \"../weights/oneshot-mu-ep-rad-init-eta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ag_ep_rad import *\n",
    "\n",
    "BATCH_SIZE_TEST = 25\n",
    "Train_Params_Test = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE_TEST, CUDA, DEVICE, PATH)\n",
    "Model_Params_Test = (noise_sigma, N, K, D, 20)\n",
    "obs, metric_step, reused = test(models, EUBO_init_eta, Data, Model_Params_Test, Train_Params_Test)\n",
    "(q_mu, _, q_z, _) = reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time plot_samples(obs, q_mu, q_z, K, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_gap = symkls_test.cpu().data.numpy()[1:]\n",
    "M = incremental_gap.shape[0]\n",
    "overall_gap = np.zeros(M)\n",
    "for m in range(M):\n",
    "    overall_gap[m] = incremental_gap[:m+1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.yscale(\"log\")\n",
    "ax.plot(incremental_gap, label=\"incremental gap\")\n",
    "ax.plot(overall_gap, label='overall gap')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_xlabel('Steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
