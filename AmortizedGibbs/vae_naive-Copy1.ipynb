{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.5.0a0+3bb8c5e cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from random import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from util_data_pixels import *\n",
    "from amorgibbs_v import *\n",
    "from smc_v import *\n",
    "from util_plots import *\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "from torch.distributions.normal import Normal\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "from probtorch.util import expand_inputs\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "NUM_PIXELS = 64*64\n",
    "NUM_HIDDEN = 256\n",
    "NUM_LATENT = 2  \n",
    "\n",
    "pixels=64\n",
    "# training parameters\n",
    "NUM_SAMPLES = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "BETA1 = 0.90\n",
    "EPS = 1e-9\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# path parameters\n",
    "MODEL_NAME = 'highvarprior'\n",
    "DATA_PATH = './data'\n",
    "WEIGHTS_PATH = 'experiment/'\n",
    "RESTORE = False\n",
    "\n",
    "ALPHA = 0.1\n",
    "BETA = (2.0, 2.0, 1.0, 0.0, 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_path = '/home/hao/Research/amortized/AmortizedGibbs/'\n",
    "ToGrayscaleTensor = transforms.Compose([transforms.Grayscale(), transforms.Resize(pixels), transforms.ToTensor()])\n",
    "train_data = datasets.ImageFolder(root = pixels_path, transform=ToGrayscaleTensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        self.enc_hidden = nn.Sequential( \n",
    "                            nn.Linear(num_pixels, num_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(num_hidden, num_hidden),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "        self.z_mean = nn.Linear(num_hidden, num_latent)\n",
    "        self.z_log_std = nn.Linear(num_hidden, num_latent)\n",
    "    @expand_inputs\n",
    "    def forward(self, images, labels=None, num_samples=NUM_SAMPLES):\n",
    "        q = probtorch.Trace()\n",
    "        hiddens = self.enc_hidden(images)\n",
    "        q.normal(self.z_mean(hiddens),\n",
    "                 self.z_log_std(hiddens).exp(),\n",
    "                 name='z')\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(x_mean, x, EPS=1e-9):\n",
    "    return - (torch.log(x_mean + EPS) * x + \n",
    "              torch.log(1 - x_mean + EPS) * (1 - x)).sum(-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.dec_image = nn.Sequential(\n",
    "                           nn.Linear(num_latent, num_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(num_hidden, num_pixels),\n",
    "                           nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images, q=None, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE, num_latent=NUM_LATENT):\n",
    "        p = probtorch.Trace()\n",
    "        z_mean = torch.zeros(num_samples, batch_size, num_latent)\n",
    "        z_std = torch.ones(num_samples, batch_size, num_latent)*210\n",
    "        \n",
    "        if CUDA:\n",
    "            z_mean = z_mean.cuda()\n",
    "            z_std = z_std.cuda()\n",
    "        \n",
    "        z = p.normal(z_mean, \n",
    "                     z_std,\n",
    "                     value=q['z'],\n",
    "                     name='z')\n",
    "        \n",
    "        images_mean = self.dec_image(z)\n",
    "        p.loss(binary_cross_entropy, images_mean, images, name='images')\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(q, p, alpha=ALPHA, beta=BETA, bias=1.0):\n",
    "    return probtorch.objectives.marginal.elbo(q, p, sample_dim=0, batch_dim=1,\n",
    "                                              alpha=alpha, beta=beta, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "if CUDA:\n",
    "    enc.cuda()\n",
    "    dec.cuda()\n",
    "\n",
    "optimizer =  torch.optim.Adam(list(enc.parameters())+list(dec.parameters()),\n",
    "                              lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, enc, dec, optimizer):\n",
    "    epoch_elbo = 0.0\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    N = 0\n",
    "    for b, (images, labels) in enumerate(data):\n",
    "        if images.size()[0] == BATCH_SIZE:\n",
    "            N += BATCH_SIZE\n",
    "            images = images.view(-1, NUM_PIXELS)\n",
    "            images = torch.where(images == 1.0, torch.FloatTensor([0.0]), torch.FloatTensor([1.0]))\n",
    "            if CUDA:\n",
    "                images = images.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            q = enc(images, num_samples=NUM_SAMPLES)\n",
    "            p = dec(images, q, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE)\n",
    "            loss = -elbo(q, p)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if CUDA:\n",
    "                loss = loss.cpu()\n",
    "            epoch_elbo -= float(loss.item())\n",
    "    return epoch_elbo / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train: ELBO -5.8635e+00 (5s)\n",
      "[Epoch 1] Train: ELBO -2.9225e+00 (5s)\n",
      "[Epoch 2] Train: ELBO -2.2846e+00 (5s)\n",
      "[Epoch 3] Train: ELBO -1.8933e+00 (5s)\n",
      "[Epoch 4] Train: ELBO -1.6135e+00 (6s)\n",
      "[Epoch 5] Train: ELBO -1.4667e+00 (7s)\n",
      "[Epoch 6] Train: ELBO -1.3730e+00 (5s)\n",
      "[Epoch 7] Train: ELBO -1.3063e+00 (4s)\n",
      "[Epoch 8] Train: ELBO -1.2728e+00 (4s)\n",
      "[Epoch 9] Train: ELBO -1.2179e+00 (4s)\n",
      "[Epoch 10] Train: ELBO -1.1810e+00 (4s)\n",
      "[Epoch 11] Train: ELBO -1.1540e+00 (4s)\n",
      "[Epoch 12] Train: ELBO -1.1200e+00 (4s)\n",
      "[Epoch 13] Train: ELBO -1.0939e+00 (4s)\n",
      "[Epoch 14] Train: ELBO -1.0758e+00 (4s)\n",
      "[Epoch 15] Train: ELBO -1.0555e+00 (4s)\n",
      "[Epoch 16] Train: ELBO -1.0370e+00 (4s)\n",
      "[Epoch 17] Train: ELBO -1.0120e+00 (4s)\n",
      "[Epoch 18] Train: ELBO -1.0007e+00 (4s)\n",
      "[Epoch 19] Train: ELBO -9.8531e-01 (4s)\n",
      "[Epoch 20] Train: ELBO -9.6491e-01 (4s)\n",
      "[Epoch 21] Train: ELBO -9.5217e-01 (4s)\n",
      "[Epoch 22] Train: ELBO -9.4131e-01 (4s)\n",
      "[Epoch 23] Train: ELBO -9.2875e-01 (4s)\n",
      "[Epoch 24] Train: ELBO -9.1821e-01 (4s)\n",
      "[Epoch 25] Train: ELBO -9.0210e-01 (4s)\n",
      "[Epoch 26] Train: ELBO -8.9060e-01 (4s)\n",
      "[Epoch 27] Train: ELBO -8.7875e-01 (4s)\n",
      "[Epoch 28] Train: ELBO -8.6428e-01 (5s)\n",
      "[Epoch 29] Train: ELBO -8.5318e-01 (5s)\n",
      "[Epoch 30] Train: ELBO -8.4487e-01 (6s)\n",
      "[Epoch 31] Train: ELBO -8.3719e-01 (7s)\n",
      "[Epoch 32] Train: ELBO -8.2786e-01 (7s)\n",
      "[Epoch 33] Train: ELBO -8.2068e-01 (7s)\n",
      "[Epoch 34] Train: ELBO -8.0135e-01 (7s)\n",
      "[Epoch 35] Train: ELBO -7.9530e-01 (6s)\n",
      "[Epoch 36] Train: ELBO -7.8905e-01 (6s)\n",
      "[Epoch 37] Train: ELBO -7.7960e-01 (7s)\n",
      "[Epoch 38] Train: ELBO -7.6982e-01 (7s)\n",
      "[Epoch 39] Train: ELBO -7.5766e-01 (7s)\n",
      "[Epoch 40] Train: ELBO -7.4848e-01 (7s)\n",
      "[Epoch 41] Train: ELBO -7.3918e-01 (6s)\n",
      "[Epoch 42] Train: ELBO -7.3381e-01 (6s)\n",
      "[Epoch 43] Train: ELBO -7.2002e-01 (5s)\n",
      "[Epoch 44] Train: ELBO -7.1187e-01 (5s)\n",
      "[Epoch 45] Train: ELBO -7.0735e-01 (6s)\n",
      "[Epoch 46] Train: ELBO -6.9229e-01 (7s)\n",
      "[Epoch 47] Train: ELBO -6.8524e-01 (7s)\n",
      "[Epoch 48] Train: ELBO -6.8054e-01 (7s)\n",
      "[Epoch 49] Train: ELBO -6.7478e-01 (6s)\n",
      "[Epoch 50] Train: ELBO -6.6892e-01 (5s)\n",
      "[Epoch 51] Train: ELBO -6.6003e-01 (4s)\n",
      "[Epoch 52] Train: ELBO -6.5383e-01 (4s)\n",
      "[Epoch 53] Train: ELBO -6.4797e-01 (5s)\n",
      "[Epoch 54] Train: ELBO -6.3551e-01 (5s)\n",
      "[Epoch 55] Train: ELBO -6.2881e-01 (4s)\n",
      "[Epoch 56] Train: ELBO -6.2792e-01 (4s)\n",
      "[Epoch 57] Train: ELBO -6.2238e-01 (4s)\n",
      "[Epoch 58] Train: ELBO -6.1177e-01 (4s)\n",
      "[Epoch 59] Train: ELBO -6.0469e-01 (4s)\n",
      "[Epoch 60] Train: ELBO -6.0143e-01 (4s)\n",
      "[Epoch 61] Train: ELBO -5.9633e-01 (5s)\n",
      "[Epoch 62] Train: ELBO -5.8732e-01 (5s)\n",
      "[Epoch 63] Train: ELBO -5.8493e-01 (5s)\n",
      "[Epoch 64] Train: ELBO -5.7342e-01 (5s)\n",
      "[Epoch 65] Train: ELBO -5.7598e-01 (5s)\n",
      "[Epoch 66] Train: ELBO -5.7077e-01 (5s)\n",
      "[Epoch 67] Train: ELBO -5.6300e-01 (5s)\n",
      "[Epoch 68] Train: ELBO -5.6450e-01 (5s)\n",
      "[Epoch 69] Train: ELBO -5.6199e-01 (5s)\n",
      "[Epoch 70] Train: ELBO -5.5425e-01 (4s)\n",
      "[Epoch 71] Train: ELBO -5.5347e-01 (5s)\n",
      "[Epoch 72] Train: ELBO -5.4697e-01 (5s)\n",
      "[Epoch 73] Train: ELBO -5.3983e-01 (5s)\n",
      "[Epoch 74] Train: ELBO -5.3433e-01 (7s)\n",
      "[Epoch 75] Train: ELBO -5.3566e-01 (7s)\n",
      "[Epoch 76] Train: ELBO -5.2879e-01 (6s)\n",
      "[Epoch 77] Train: ELBO -5.2961e-01 (5s)\n",
      "[Epoch 78] Train: ELBO -5.1911e-01 (5s)\n",
      "[Epoch 79] Train: ELBO -5.1882e-01 (5s)\n",
      "[Epoch 80] Train: ELBO -5.1743e-01 (5s)\n",
      "[Epoch 81] Train: ELBO -5.1285e-01 (4s)\n",
      "[Epoch 82] Train: ELBO -5.0688e-01 (5s)\n",
      "[Epoch 83] Train: ELBO -5.0469e-01 (4s)\n",
      "[Epoch 84] Train: ELBO -5.0025e-01 (5s)\n",
      "[Epoch 85] Train: ELBO -4.9688e-01 (7s)\n",
      "[Epoch 86] Train: ELBO -4.9763e-01 (7s)\n",
      "[Epoch 87] Train: ELBO -4.9226e-01 (7s)\n",
      "[Epoch 88] Train: ELBO -4.8940e-01 (8s)\n",
      "[Epoch 89] Train: ELBO -4.9259e-01 (7s)\n",
      "[Epoch 90] Train: ELBO -4.8867e-01 (6s)\n",
      "[Epoch 91] Train: ELBO -4.8186e-01 (5s)\n",
      "[Epoch 92] Train: ELBO -4.7911e-01 (5s)\n",
      "[Epoch 93] Train: ELBO -4.8207e-01 (7s)\n",
      "[Epoch 94] Train: ELBO -4.7868e-01 (7s)\n",
      "[Epoch 95] Train: ELBO -4.7580e-01 (7s)\n",
      "[Epoch 96] Train: ELBO -4.7332e-01 (6s)\n",
      "[Epoch 97] Train: ELBO -4.7178e-01 (7s)\n",
      "[Epoch 98] Train: ELBO -4.6694e-01 (7s)\n",
      "[Epoch 99] Train: ELBO -4.6751e-01 (6s)\n",
      "[Epoch 100] Train: ELBO -4.6295e-01 (6s)\n",
      "[Epoch 101] Train: ELBO -4.6633e-01 (7s)\n",
      "[Epoch 102] Train: ELBO -4.5568e-01 (6s)\n",
      "[Epoch 103] Train: ELBO -4.5479e-01 (5s)\n",
      "[Epoch 104] Train: ELBO -4.5718e-01 (5s)\n",
      "[Epoch 105] Train: ELBO -4.5736e-01 (5s)\n",
      "[Epoch 106] Train: ELBO -4.4813e-01 (6s)\n",
      "[Epoch 107] Train: ELBO -4.4911e-01 (7s)\n",
      "[Epoch 108] Train: ELBO -4.4925e-01 (7s)\n",
      "[Epoch 109] Train: ELBO -4.4693e-01 (7s)\n",
      "[Epoch 110] Train: ELBO -4.4452e-01 (7s)\n",
      "[Epoch 111] Train: ELBO -4.4185e-01 (7s)\n",
      "[Epoch 112] Train: ELBO -4.4142e-01 (7s)\n",
      "[Epoch 113] Train: ELBO -4.3793e-01 (7s)\n",
      "[Epoch 114] Train: ELBO -4.3528e-01 (7s)\n",
      "[Epoch 115] Train: ELBO -4.3514e-01 (7s)\n",
      "[Epoch 116] Train: ELBO -4.3173e-01 (7s)\n",
      "[Epoch 117] Train: ELBO -4.3206e-01 (7s)\n",
      "[Epoch 118] Train: ELBO -4.2839e-01 (7s)\n",
      "[Epoch 119] Train: ELBO -4.3251e-01 (6s)\n",
      "[Epoch 120] Train: ELBO -4.3209e-01 (4s)\n",
      "[Epoch 121] Train: ELBO -4.2653e-01 (4s)\n",
      "[Epoch 122] Train: ELBO -4.2277e-01 (4s)\n",
      "[Epoch 123] Train: ELBO -4.2232e-01 (5s)\n",
      "[Epoch 124] Train: ELBO -4.2159e-01 (5s)\n",
      "[Epoch 125] Train: ELBO -4.1748e-01 (5s)\n",
      "[Epoch 126] Train: ELBO -4.2407e-01 (5s)\n",
      "[Epoch 127] Train: ELBO -4.2677e-01 (5s)\n",
      "[Epoch 128] Train: ELBO -4.1770e-01 (5s)\n",
      "[Epoch 129] Train: ELBO -4.1525e-01 (5s)\n",
      "[Epoch 130] Train: ELBO -4.1700e-01 (5s)\n",
      "[Epoch 131] Train: ELBO -4.1153e-01 (5s)\n",
      "[Epoch 132] Train: ELBO -4.0931e-01 (5s)\n",
      "[Epoch 133] Train: ELBO -4.0984e-01 (5s)\n",
      "[Epoch 134] Train: ELBO -4.0721e-01 (5s)\n",
      "[Epoch 135] Train: ELBO -4.0752e-01 (5s)\n",
      "[Epoch 136] Train: ELBO -4.0474e-01 (5s)\n",
      "[Epoch 137] Train: ELBO -4.0357e-01 (5s)\n",
      "[Epoch 138] Train: ELBO -4.0451e-01 (5s)\n",
      "[Epoch 139] Train: ELBO -4.0699e-01 (5s)\n",
      "[Epoch 140] Train: ELBO -4.0489e-01 (5s)\n",
      "[Epoch 141] Train: ELBO -4.0133e-01 (5s)\n",
      "[Epoch 142] Train: ELBO -4.0149e-01 (5s)\n",
      "[Epoch 143] Train: ELBO -3.9969e-01 (4s)\n",
      "[Epoch 144] Train: ELBO -3.9731e-01 (4s)\n",
      "[Epoch 145] Train: ELBO -3.9430e-01 (4s)\n",
      "[Epoch 146] Train: ELBO -3.9553e-01 (6s)\n",
      "[Epoch 147] Train: ELBO -3.9323e-01 (7s)\n",
      "[Epoch 148] Train: ELBO -3.9074e-01 (7s)\n",
      "[Epoch 149] Train: ELBO -3.8939e-01 (7s)\n",
      "[Epoch 150] Train: ELBO -3.9020e-01 (6s)\n",
      "[Epoch 151] Train: ELBO -3.9072e-01 (5s)\n",
      "[Epoch 152] Train: ELBO -3.8920e-01 (5s)\n",
      "[Epoch 153] Train: ELBO -3.9090e-01 (5s)\n",
      "[Epoch 154] Train: ELBO -3.8814e-01 (7s)\n",
      "[Epoch 155] Train: ELBO -3.8761e-01 (6s)\n",
      "[Epoch 156] Train: ELBO -3.9035e-01 (5s)\n",
      "[Epoch 157] Train: ELBO -3.8376e-01 (4s)\n",
      "[Epoch 158] Train: ELBO -3.8100e-01 (5s)\n",
      "[Epoch 159] Train: ELBO -3.8078e-01 (5s)\n",
      "[Epoch 160] Train: ELBO -3.7997e-01 (5s)\n",
      "[Epoch 161] Train: ELBO -3.8137e-01 (5s)\n",
      "[Epoch 162] Train: ELBO -3.7786e-01 (5s)\n",
      "[Epoch 163] Train: ELBO -3.7736e-01 (5s)\n",
      "[Epoch 164] Train: ELBO -3.7899e-01 (7s)\n",
      "[Epoch 165] Train: ELBO -3.7864e-01 (7s)\n",
      "[Epoch 166] Train: ELBO -3.7648e-01 (6s)\n",
      "[Epoch 167] Train: ELBO -3.7735e-01 (6s)\n",
      "[Epoch 168] Train: ELBO -3.7546e-01 (7s)\n",
      "[Epoch 169] Train: ELBO -3.7421e-01 (7s)\n",
      "[Epoch 170] Train: ELBO -3.7574e-01 (7s)\n",
      "[Epoch 171] Train: ELBO -3.7454e-01 (7s)\n",
      "[Epoch 172] Train: ELBO -3.7459e-01 (7s)\n",
      "[Epoch 173] Train: ELBO -3.7606e-01 (7s)\n",
      "[Epoch 174] Train: ELBO -3.6741e-01 (6s)\n",
      "[Epoch 175] Train: ELBO -3.7073e-01 (6s)\n",
      "[Epoch 176] Train: ELBO -3.7407e-01 (7s)\n",
      "[Epoch 177] Train: ELBO -3.7092e-01 (7s)\n",
      "[Epoch 178] Train: ELBO -3.6383e-01 (7s)\n",
      "[Epoch 179] Train: ELBO -3.6313e-01 (7s)\n",
      "[Epoch 180] Train: ELBO -3.6451e-01 (7s)\n",
      "[Epoch 181] Train: ELBO -3.6464e-01 (7s)\n",
      "[Epoch 182] Train: ELBO -3.6575e-01 (7s)\n",
      "[Epoch 183] Train: ELBO -3.6589e-01 (7s)\n",
      "[Epoch 184] Train: ELBO -3.6609e-01 (7s)\n",
      "[Epoch 185] Train: ELBO -3.6522e-01 (7s)\n",
      "[Epoch 186] Train: ELBO -3.6342e-01 (7s)\n",
      "[Epoch 187] Train: ELBO -3.5828e-01 (7s)\n",
      "[Epoch 188] Train: ELBO -3.6067e-01 (7s)\n",
      "[Epoch 189] Train: ELBO -3.5770e-01 (6s)\n",
      "[Epoch 190] Train: ELBO -3.5800e-01 (5s)\n",
      "[Epoch 191] Train: ELBO -3.6143e-01 (4s)\n",
      "[Epoch 192] Train: ELBO -3.5801e-01 (4s)\n",
      "[Epoch 193] Train: ELBO -3.5952e-01 (4s)\n",
      "[Epoch 194] Train: ELBO -3.5639e-01 (4s)\n",
      "[Epoch 195] Train: ELBO -3.5989e-01 (4s)\n",
      "[Epoch 196] Train: ELBO -3.6083e-01 (4s)\n",
      "[Epoch 197] Train: ELBO -3.6081e-01 (5s)\n",
      "[Epoch 198] Train: ELBO -3.5564e-01 (5s)\n",
      "[Epoch 199] Train: ELBO -3.5506e-01 (5s)\n"
     ]
    }
   ],
   "source": [
    "if not RESTORE:\n",
    "    mask = {}\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        train_start = time.time()\n",
    "        train_elbo = train(train_loader, enc, dec, optimizer)\n",
    "        train_end = time.time()\n",
    "        print('[Epoch %d] Train: ELBO %.4e (%ds)' % (\n",
    "                e, train_elbo, train_end - train_start))\n",
    "\n",
    "    if not os.path.isdir(WEIGHTS_PATH):\n",
    "        os.mkdir(WEIGHTS_PATH)\n",
    "    torch.save(enc.state_dict(),\n",
    "               '%s-pretrained-vae-enc' % MODEL_NAME)\n",
    "    torch.save(dec.state_dict(),\n",
    "               '%s-pretrained-vae-dec' % MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b7db77086912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minit_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_velocity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0malpha_trans_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_trans_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSTATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_ks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZs_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_seq_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerate_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "init_v = init_velocity(dt)\n",
    "alpha_trans_0 = initial_trans_prior(K)\n",
    "noise_cov = np.array([[1, 0], [0, 1]]) * noise_ratio\n",
    "STATE, mu_ks, cov_ks, Pi, Y_true, A_true, Zs_true = generate_seq_T(T, K, dt, Boundary, init_v, noise_cov, radius)\n",
    "generate_frames(STATE, Boundary, pixels, dpi, radius, 0)    \n",
    "X_imgs = sample_pixels(T, pixels, 0).view(-1, NUM_PIXELS)\n",
    "q = enc(X_imgs,num_samples=NUM_SAMPLES)\n",
    "p = dec(X_imgs, q, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE)\n",
    "z_means = q['z'].dist.mean.detach().squeeze(0).data.numpy()\n",
    "\n",
    "coor = q['z'].value.squeeze(0)\n",
    "Y = coor[1:] - coor[:-1]\n",
    "cov_true = np.tile(noise_cov, (K, 1, 1))\n",
    "dirs = np.array([[1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "mu_true = np.tile(np.absolute(init_v), (K, 1)) * dirs\n",
    "plot_clusters(Y_true.data.numpy(), mu_true, cov_true, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
