{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.5.0a0+3bb8c5e cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from random import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from util_data_pixels import *\n",
    "from amorgibbs_v import *\n",
    "from smc_v import *\n",
    "from util_plots import *\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "from probtorch.util import expand_inputs\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "NUM_PIXELS = 64*64\n",
    "NUM_HIDDEN = 256\n",
    "NUM_LATENT = 2  \n",
    "\n",
    "pixels=64\n",
    "# training parameters\n",
    "NUM_SAMPLES = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-3\n",
    "BETA1 = 0.90\n",
    "EPS = 1e-9\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# path parameters\n",
    "MODEL_NAME = 'bbal-%02ddim' % NUM_LATENT\n",
    "DATA_PATH = './data'\n",
    "WEIGHTS_PATH = 'experiment/'\n",
    "RESTORE = False\n",
    "\n",
    "ALPHA = 0.1\n",
    "BETA = (2.0, 2.0, 1.0, 0.0, 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_path = '/home/hao/Research/amortized/AmortizedGibbs/'\n",
    "ToGrayscaleTensor = transforms.Compose([transforms.Grayscale(), transforms.Resize(pixels), transforms.ToTensor()])\n",
    "train_data = datasets.ImageFolder(root = pixels_path, transform=ToGrayscaleTensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        self.enc_hidden = nn.Sequential( \n",
    "                            nn.Linear(num_pixels, num_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(num_hidden, num_hidden),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "        self.z_mean = nn.Linear(num_hidden, num_latent)\n",
    "        self.z_log_std = nn.Linear(num_hidden, num_latent)\n",
    "    @expand_inputs\n",
    "    def forward(self, images, labels=None, num_samples=NUM_SAMPLES):\n",
    "        q = probtorch.Trace()\n",
    "        hiddens = self.enc_hidden(images)\n",
    "        q.normal(self.z_mean(hiddens),\n",
    "                 self.z_log_std(hiddens).exp(),\n",
    "                 name='z')\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(x_mean, x, EPS=1e-9):\n",
    "    return - (torch.log(x_mean + EPS) * x + \n",
    "              torch.log(1 - x_mean + EPS) * (1 - x)).sum(-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.dec_image = nn.Sequential(\n",
    "                           nn.Linear(num_latent, num_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(num_hidden, num_pixels),\n",
    "                           nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images, q=None, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE, num_latent=NUM_LATENT):\n",
    "        p = probtorch.Trace()\n",
    "        z_mean = torch.zeros(num_samples, batch_size, num_latent)\n",
    "        z_std = torch.ones(num_samples, batch_size, num_latent)\n",
    "        \n",
    "        if CUDA:\n",
    "            z_mean = z_mean.cuda()\n",
    "            z_std = z_std.cuda()\n",
    "        \n",
    "        z = p.normal(z_mean, \n",
    "                     z_std,\n",
    "                     value=q['z'],\n",
    "                     name='z')\n",
    "        \n",
    "        images_mean = self.dec_image(z)\n",
    "        p.loss(binary_cross_entropy, images_mean, images, name='images')\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(q, p, alpha=ALPHA, beta=BETA, bias=1.0):\n",
    "    return probtorch.objectives.marginal.elbo(q, p, sample_dim=0, batch_dim=1,\n",
    "                                              alpha=alpha, beta=beta, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "if CUDA:\n",
    "    enc.cuda()\n",
    "    dec.cuda()\n",
    "\n",
    "optimizer =  torch.optim.Adam(list(enc.parameters())+list(dec.parameters()),\n",
    "                              lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, enc, dec, optimizer):\n",
    "    epoch_elbo = 0.0\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    N = 0\n",
    "    for b, (images, labels) in enumerate(data):\n",
    "        if images.size()[0] == BATCH_SIZE:\n",
    "            N += BATCH_SIZE\n",
    "            images = images.view(-1, NUM_PIXELS)\n",
    "            images = torch.where(images == 1.0, torch.FloatTensor([0.0]), torch.FloatTensor([1.0]))\n",
    "            if CUDA:\n",
    "                images = images.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            q = enc(images, num_samples=NUM_SAMPLES)\n",
    "            p = dec(images, q, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE)\n",
    "            loss = -elbo(q, p)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if CUDA:\n",
    "                loss = loss.cpu()\n",
    "            epoch_elbo -= float(loss.item())\n",
    "    return epoch_elbo / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train: ELBO -6.0680e+00 (5s)\n",
      "[Epoch 1] Train: ELBO -2.9463e+00 (4s)\n",
      "[Epoch 2] Train: ELBO -2.7381e+00 (6s)\n",
      "[Epoch 3] Train: ELBO -2.2282e+00 (6s)\n",
      "[Epoch 4] Train: ELBO -1.9662e+00 (6s)\n",
      "[Epoch 5] Train: ELBO -1.8047e+00 (6s)\n",
      "[Epoch 6] Train: ELBO -1.6809e+00 (6s)\n",
      "[Epoch 7] Train: ELBO -1.5816e+00 (6s)\n",
      "[Epoch 8] Train: ELBO -1.5034e+00 (6s)\n",
      "[Epoch 9] Train: ELBO -1.4395e+00 (6s)\n",
      "[Epoch 10] Train: ELBO -1.3834e+00 (6s)\n",
      "[Epoch 11] Train: ELBO -1.3354e+00 (5s)\n",
      "[Epoch 12] Train: ELBO -1.2933e+00 (4s)\n",
      "[Epoch 13] Train: ELBO -1.2557e+00 (4s)\n",
      "[Epoch 14] Train: ELBO -1.2208e+00 (4s)\n",
      "[Epoch 15] Train: ELBO -1.1863e+00 (4s)\n",
      "[Epoch 16] Train: ELBO -1.1584e+00 (4s)\n",
      "[Epoch 17] Train: ELBO -1.1316e+00 (4s)\n",
      "[Epoch 18] Train: ELBO -1.1020e+00 (4s)\n",
      "[Epoch 19] Train: ELBO -1.0802e+00 (4s)\n",
      "[Epoch 20] Train: ELBO -1.0559e+00 (4s)\n",
      "[Epoch 21] Train: ELBO -1.0406e+00 (4s)\n",
      "[Epoch 22] Train: ELBO -1.0166e+00 (4s)\n",
      "[Epoch 23] Train: ELBO -9.9509e-01 (4s)\n",
      "[Epoch 24] Train: ELBO -9.7663e-01 (4s)\n",
      "[Epoch 25] Train: ELBO -9.5899e-01 (4s)\n",
      "[Epoch 26] Train: ELBO -9.4498e-01 (4s)\n",
      "[Epoch 27] Train: ELBO -9.3036e-01 (4s)\n",
      "[Epoch 28] Train: ELBO -9.1292e-01 (4s)\n",
      "[Epoch 29] Train: ELBO -9.0018e-01 (4s)\n",
      "[Epoch 30] Train: ELBO -8.8534e-01 (4s)\n",
      "[Epoch 31] Train: ELBO -8.7200e-01 (4s)\n",
      "[Epoch 32] Train: ELBO -8.6014e-01 (4s)\n",
      "[Epoch 33] Train: ELBO -8.4897e-01 (4s)\n",
      "[Epoch 34] Train: ELBO -8.3726e-01 (4s)\n",
      "[Epoch 35] Train: ELBO -8.2511e-01 (5s)\n",
      "[Epoch 36] Train: ELBO -8.1144e-01 (6s)\n",
      "[Epoch 37] Train: ELBO -8.0040e-01 (6s)\n",
      "[Epoch 38] Train: ELBO -7.9118e-01 (6s)\n",
      "[Epoch 39] Train: ELBO -7.7953e-01 (6s)\n",
      "[Epoch 40] Train: ELBO -7.6947e-01 (6s)\n",
      "[Epoch 41] Train: ELBO -7.5877e-01 (6s)\n",
      "[Epoch 42] Train: ELBO -7.4925e-01 (6s)\n",
      "[Epoch 43] Train: ELBO -7.4118e-01 (6s)\n",
      "[Epoch 44] Train: ELBO -7.2933e-01 (6s)\n",
      "[Epoch 45] Train: ELBO -7.2131e-01 (6s)\n",
      "[Epoch 46] Train: ELBO -7.1394e-01 (6s)\n",
      "[Epoch 47] Train: ELBO -7.0213e-01 (6s)\n",
      "[Epoch 48] Train: ELBO -6.9383e-01 (6s)\n",
      "[Epoch 49] Train: ELBO -6.8611e-01 (6s)\n",
      "[Epoch 50] Train: ELBO -6.7875e-01 (6s)\n",
      "[Epoch 51] Train: ELBO -6.6965e-01 (6s)\n",
      "[Epoch 52] Train: ELBO -6.6166e-01 (6s)\n",
      "[Epoch 53] Train: ELBO -6.5392e-01 (6s)\n",
      "[Epoch 54] Train: ELBO -6.4629e-01 (6s)\n",
      "[Epoch 55] Train: ELBO -6.3856e-01 (6s)\n",
      "[Epoch 56] Train: ELBO -6.3602e-01 (6s)\n",
      "[Epoch 57] Train: ELBO -6.2490e-01 (6s)\n",
      "[Epoch 58] Train: ELBO -6.2287e-01 (6s)\n",
      "[Epoch 59] Train: ELBO -6.1333e-01 (6s)\n",
      "[Epoch 60] Train: ELBO -6.0650e-01 (6s)\n",
      "[Epoch 61] Train: ELBO -6.0081e-01 (6s)\n",
      "[Epoch 62] Train: ELBO -5.9238e-01 (6s)\n",
      "[Epoch 63] Train: ELBO -5.8740e-01 (6s)\n",
      "[Epoch 64] Train: ELBO -5.8278e-01 (6s)\n",
      "[Epoch 65] Train: ELBO -5.7666e-01 (6s)\n",
      "[Epoch 66] Train: ELBO -5.7039e-01 (6s)\n",
      "[Epoch 67] Train: ELBO -5.6554e-01 (6s)\n",
      "[Epoch 68] Train: ELBO -5.6182e-01 (5s)\n",
      "[Epoch 69] Train: ELBO -5.5552e-01 (6s)\n",
      "[Epoch 70] Train: ELBO -5.5150e-01 (6s)\n",
      "[Epoch 71] Train: ELBO -5.4715e-01 (6s)\n",
      "[Epoch 72] Train: ELBO -5.4286e-01 (6s)\n",
      "[Epoch 73] Train: ELBO -5.3950e-01 (6s)\n",
      "[Epoch 74] Train: ELBO -5.3147e-01 (6s)\n",
      "[Epoch 75] Train: ELBO -5.2647e-01 (6s)\n",
      "[Epoch 76] Train: ELBO -5.2185e-01 (5s)\n",
      "[Epoch 77] Train: ELBO -5.1975e-01 (6s)\n",
      "[Epoch 78] Train: ELBO -5.1708e-01 (6s)\n",
      "[Epoch 79] Train: ELBO -5.1058e-01 (5s)\n",
      "[Epoch 80] Train: ELBO -5.0663e-01 (4s)\n",
      "[Epoch 81] Train: ELBO -5.0304e-01 (4s)\n",
      "[Epoch 82] Train: ELBO -5.0051e-01 (4s)\n",
      "[Epoch 83] Train: ELBO -4.9681e-01 (4s)\n",
      "[Epoch 84] Train: ELBO -4.9307e-01 (5s)\n",
      "[Epoch 85] Train: ELBO -4.8936e-01 (6s)\n",
      "[Epoch 86] Train: ELBO -4.8689e-01 (5s)\n",
      "[Epoch 87] Train: ELBO -4.8198e-01 (4s)\n",
      "[Epoch 88] Train: ELBO -4.7950e-01 (4s)\n",
      "[Epoch 89] Train: ELBO -4.7686e-01 (4s)\n",
      "[Epoch 90] Train: ELBO -4.7373e-01 (4s)\n",
      "[Epoch 91] Train: ELBO -4.6968e-01 (4s)\n",
      "[Epoch 92] Train: ELBO -4.6725e-01 (4s)\n",
      "[Epoch 93] Train: ELBO -4.6320e-01 (4s)\n",
      "[Epoch 94] Train: ELBO -4.5995e-01 (4s)\n",
      "[Epoch 95] Train: ELBO -4.5902e-01 (4s)\n",
      "[Epoch 96] Train: ELBO -4.5592e-01 (5s)\n",
      "[Epoch 97] Train: ELBO -4.5221e-01 (5s)\n",
      "[Epoch 98] Train: ELBO -4.5058e-01 (4s)\n",
      "[Epoch 99] Train: ELBO -4.4595e-01 (4s)\n",
      "[Epoch 100] Train: ELBO -4.4387e-01 (4s)\n",
      "[Epoch 101] Train: ELBO -4.4158e-01 (6s)\n",
      "[Epoch 102] Train: ELBO -4.4015e-01 (6s)\n",
      "[Epoch 103] Train: ELBO -4.3643e-01 (6s)\n",
      "[Epoch 104] Train: ELBO -4.3537e-01 (6s)\n",
      "[Epoch 105] Train: ELBO -4.3512e-01 (6s)\n",
      "[Epoch 106] Train: ELBO -4.3115e-01 (6s)\n",
      "[Epoch 107] Train: ELBO -4.2899e-01 (5s)\n",
      "[Epoch 108] Train: ELBO -4.2798e-01 (5s)\n",
      "[Epoch 109] Train: ELBO -4.2302e-01 (5s)\n",
      "[Epoch 110] Train: ELBO -4.2125e-01 (5s)\n",
      "[Epoch 111] Train: ELBO -4.1962e-01 (5s)\n",
      "[Epoch 112] Train: ELBO -4.1615e-01 (5s)\n",
      "[Epoch 113] Train: ELBO -4.1361e-01 (5s)\n",
      "[Epoch 114] Train: ELBO -4.1298e-01 (5s)\n",
      "[Epoch 115] Train: ELBO -4.1251e-01 (4s)\n",
      "[Epoch 116] Train: ELBO -4.1158e-01 (4s)\n",
      "[Epoch 117] Train: ELBO -4.0927e-01 (4s)\n",
      "[Epoch 118] Train: ELBO -4.0545e-01 (4s)\n",
      "[Epoch 119] Train: ELBO -4.0425e-01 (4s)\n",
      "[Epoch 120] Train: ELBO -4.0293e-01 (4s)\n",
      "[Epoch 121] Train: ELBO -3.9959e-01 (4s)\n",
      "[Epoch 122] Train: ELBO -3.9896e-01 (4s)\n",
      "[Epoch 123] Train: ELBO -3.9775e-01 (4s)\n",
      "[Epoch 124] Train: ELBO -3.9398e-01 (4s)\n",
      "[Epoch 125] Train: ELBO -3.9502e-01 (4s)\n",
      "[Epoch 126] Train: ELBO -3.9155e-01 (4s)\n",
      "[Epoch 127] Train: ELBO -3.8939e-01 (4s)\n",
      "[Epoch 128] Train: ELBO -3.8873e-01 (4s)\n",
      "[Epoch 129] Train: ELBO -3.8641e-01 (4s)\n",
      "[Epoch 130] Train: ELBO -3.8450e-01 (4s)\n",
      "[Epoch 131] Train: ELBO -3.8406e-01 (4s)\n",
      "[Epoch 132] Train: ELBO -3.8173e-01 (4s)\n",
      "[Epoch 133] Train: ELBO -3.8095e-01 (4s)\n",
      "[Epoch 134] Train: ELBO -3.7979e-01 (4s)\n",
      "[Epoch 135] Train: ELBO -3.7856e-01 (5s)\n",
      "[Epoch 136] Train: ELBO -3.7602e-01 (4s)\n",
      "[Epoch 137] Train: ELBO -3.7590e-01 (4s)\n",
      "[Epoch 138] Train: ELBO -3.7447e-01 (4s)\n",
      "[Epoch 139] Train: ELBO -3.7477e-01 (4s)\n",
      "[Epoch 140] Train: ELBO -3.7262e-01 (4s)\n",
      "[Epoch 141] Train: ELBO -3.7106e-01 (4s)\n",
      "[Epoch 142] Train: ELBO -3.6864e-01 (4s)\n",
      "[Epoch 143] Train: ELBO -3.7055e-01 (6s)\n",
      "[Epoch 144] Train: ELBO -3.6780e-01 (6s)\n",
      "[Epoch 145] Train: ELBO -3.6676e-01 (6s)\n",
      "[Epoch 146] Train: ELBO -3.6474e-01 (6s)\n",
      "[Epoch 147] Train: ELBO -3.6277e-01 (5s)\n",
      "[Epoch 148] Train: ELBO -3.6126e-01 (4s)\n",
      "[Epoch 149] Train: ELBO -3.6047e-01 (4s)\n",
      "[Epoch 150] Train: ELBO -3.5923e-01 (4s)\n",
      "[Epoch 151] Train: ELBO -3.5872e-01 (4s)\n",
      "[Epoch 152] Train: ELBO -3.5641e-01 (4s)\n",
      "[Epoch 153] Train: ELBO -3.5746e-01 (4s)\n",
      "[Epoch 154] Train: ELBO -3.5493e-01 (4s)\n",
      "[Epoch 155] Train: ELBO -3.5333e-01 (4s)\n",
      "[Epoch 156] Train: ELBO -3.5194e-01 (4s)\n",
      "[Epoch 157] Train: ELBO -3.5189e-01 (4s)\n",
      "[Epoch 158] Train: ELBO -3.5306e-01 (4s)\n",
      "[Epoch 159] Train: ELBO -3.4908e-01 (4s)\n",
      "[Epoch 160] Train: ELBO -3.4864e-01 (4s)\n",
      "[Epoch 161] Train: ELBO -3.4624e-01 (5s)\n",
      "[Epoch 162] Train: ELBO -3.4637e-01 (6s)\n",
      "[Epoch 163] Train: ELBO -3.5160e-01 (4s)\n",
      "[Epoch 164] Train: ELBO -3.4807e-01 (4s)\n",
      "[Epoch 165] Train: ELBO -3.4398e-01 (4s)\n",
      "[Epoch 166] Train: ELBO -3.4285e-01 (4s)\n",
      "[Epoch 167] Train: ELBO -3.4071e-01 (4s)\n",
      "[Epoch 168] Train: ELBO -3.4239e-01 (4s)\n",
      "[Epoch 169] Train: ELBO -3.3967e-01 (4s)\n",
      "[Epoch 170] Train: ELBO -3.3941e-01 (4s)\n",
      "[Epoch 171] Train: ELBO -3.3882e-01 (4s)\n",
      "[Epoch 172] Train: ELBO -3.3595e-01 (4s)\n",
      "[Epoch 173] Train: ELBO -3.3608e-01 (4s)\n",
      "[Epoch 174] Train: ELBO -3.3605e-01 (4s)\n",
      "[Epoch 175] Train: ELBO -3.3488e-01 (5s)\n",
      "[Epoch 176] Train: ELBO -3.3469e-01 (6s)\n",
      "[Epoch 177] Train: ELBO -3.3355e-01 (6s)\n",
      "[Epoch 178] Train: ELBO -3.3589e-01 (6s)\n",
      "[Epoch 179] Train: ELBO -3.3404e-01 (6s)\n",
      "[Epoch 180] Train: ELBO -3.3346e-01 (6s)\n",
      "[Epoch 181] Train: ELBO -3.2990e-01 (5s)\n",
      "[Epoch 182] Train: ELBO -3.2808e-01 (6s)\n",
      "[Epoch 183] Train: ELBO -3.2773e-01 (6s)\n",
      "[Epoch 184] Train: ELBO -3.2694e-01 (6s)\n",
      "[Epoch 185] Train: ELBO -3.2570e-01 (6s)\n",
      "[Epoch 186] Train: ELBO -3.2477e-01 (6s)\n",
      "[Epoch 187] Train: ELBO -3.2428e-01 (4s)\n",
      "[Epoch 188] Train: ELBO -3.2557e-01 (5s)\n",
      "[Epoch 189] Train: ELBO -3.2230e-01 (6s)\n",
      "[Epoch 190] Train: ELBO -3.2293e-01 (6s)\n",
      "[Epoch 191] Train: ELBO -3.2301e-01 (6s)\n",
      "[Epoch 192] Train: ELBO -3.2106e-01 (6s)\n",
      "[Epoch 193] Train: ELBO -3.2219e-01 (6s)\n",
      "[Epoch 194] Train: ELBO -3.2035e-01 (6s)\n",
      "[Epoch 195] Train: ELBO -3.1973e-01 (6s)\n",
      "[Epoch 196] Train: ELBO -3.2019e-01 (6s)\n",
      "[Epoch 197] Train: ELBO -3.1677e-01 (6s)\n",
      "[Epoch 198] Train: ELBO -3.1795e-01 (6s)\n",
      "[Epoch 199] Train: ELBO -3.1668e-01 (6s)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4b4bc26466f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                 e, train_elbo, train_end - train_start))\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     torch.save(enc.state_dict(),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "if not RESTORE:\n",
    "    mask = {}\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        train_start = time.time()\n",
    "        train_elbo = train(train_loader, enc, dec, optimizer)\n",
    "        train_end = time.time()\n",
    "        print('[Epoch %d] Train: ELBO %.4e (%ds)' % (\n",
    "                e, train_elbo, train_end - train_start))\n",
    "\n",
    "    if not os.path.isdir(WEIGHTS_PATH):\n",
    "        os.mkdir(WEIGHTS_PATH)\n",
    "    torch.save(enc.state_dict(),\n",
    "               '%s/%s-%s-%s-enc.rar' % (WEIGHTS_PATH, MODEL_NAME, probtorch.__version__, torch.__version__))\n",
    "    torch.save(dec.state_dict(),\n",
    "               '%s/%s-%s-%s-dec.rar' % (WEIGHTS_PATH, MODEL_NAME, probtorch.__version__, torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not os.path.isdir(WEIGHTS_PATH):\n",
    "        os.mkdir(WEIGHTS_PATH)\n",
    "    torch.save(enc.state_dict(),\n",
    "               'pretrained-vae-enc')\n",
    "    torch.save(dec.state_dict(),\n",
    "               'pretrained-vae-dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
