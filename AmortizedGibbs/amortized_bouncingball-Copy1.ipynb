{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.5.0a0+3bb8c5e cuda: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from util_data import *\n",
    "from util_hmm_variational_gibbs import *\n",
    "from smc import *\n",
    "from util_plots import *\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "from probtorch.util import expand_inputs\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset parameters\n",
    "num_series = 1\n",
    "T = 5\n",
    "K = 4\n",
    "D = 2\n",
    "dt = 10\n",
    "Boundary = 30\n",
    "noise_ratio = 0.5\n",
    "\n",
    "## Model Parameters\n",
    "num_particles_rws = 50\n",
    "mcmc_steps = 3\n",
    "num_particles_smc = 50\n",
    "NUM_HIDDEN = 128\n",
    "NUM_LATENTS = K*K\n",
    "NUM_OBS = 2 * K\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.67948559  2.51148536]\n",
      " [ 9.67948559 -2.51148536]\n",
      " [-9.67948559 -2.51148536]\n",
      " [-9.67948559  2.51148536]]\n"
     ]
    }
   ],
   "source": [
    "noise_cov = np.array([[1, 0], [0, 1]]) * noise_ratio\n",
    "init_v = np.random.random(2) * np.random.choice([-1,1], size=2)\n",
    "v_norm = ((init_v ** 2 ).sum()) ** 0.5 ## compute norm for each initial velocity\n",
    "init_v = init_v / v_norm * dt ## to make the velocity lying on a circle\n",
    "\n",
    "STATE, Disp, A_true, Zs_true = generate_seq(T, dt, Boundary, init_v, noise_cov)\n",
    "## true global variables\n",
    "cov_true = np.tile(noise_cov, (K, 1, 1))\n",
    "dirs = np.array([[1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "mu_true = np.tile(np.absolute(init_v), (K, 1)) * dirs\n",
    "Pi_true = np.ones(K) * (1/K)\n",
    "\n",
    "plot_clusters(Disp, mu_true, cov_true, K)\n",
    "Zs_true = torch.from_numpy(Zs_true).float()\n",
    "cov_ks = torch.from_numpy(cov_true).float()\n",
    "mu_ks = torch.from_numpy(mu_true).float()\n",
    "Pi = torch.from_numpy(Pi_true).float()\n",
    "A_init = torch.from_numpy(A_true).float()\n",
    "## piror of A\n",
    "alpha_trans_0 = initial_trans_prior(K)\n",
    "## Y\n",
    "Y = torch.from_numpy(Disp).float()\n",
    "print(mu_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_joint(alpha_trans_0, Zs_true, Pi, A_init, mu_ks, cov_ks, Y, T, D, K)\n",
    "# labels = Zs_true.nonzero()[:, 1]\n",
    "p = torch.eye(4)\n",
    "Zs_true\n",
    "labels = torch.Tensor([2,2,2,1,1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions.one_hot_categorical import OneHotCategorical as cat\n",
    "Zs_true[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return samples in order to compute the weights and \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=NUM_OBS,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=NUM_LATENTS):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_hidden = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU())\n",
    "        self.latent_dir = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    def forward(self, obs, prior_sum, T):\n",
    "        A_samples = torch.zeros((K, K))\n",
    "        hidden = self.enc_hidden(obs)\n",
    "        latents_dirs = torch.exp(self.latent_dir(hidden)).sum(0).view(K, K)\n",
    "        latents_dirs_norm = latents_dirs / latents_dirs.sum() * (prior_sum + T-1)\n",
    "        for k in range(K):\n",
    "            A_samples[k] = Dirichlet(latents_dirs_norm[k]).sample()\n",
    "        return latents_dirs_norm, A_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters()),lr=LEARNING_RATE)    \n",
    "    return enc, optimizer\n",
    "enc, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLs = []\n",
    "EUBOs = []\n",
    "log_p_conds = []\n",
    "log_qs = []\n",
    "ESSs = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    init_v = np.random.random(2) * np.random.choice([-1,1], size=2)\n",
    "    v_norm = ((init_v ** 2 ).sum()) ** 0.5 ## compute norm for each initial velocity\n",
    "    init_v = init_v / v_norm * dt ## to make the velocity lying on a circle\n",
    "    T = np.random.randint(30, 50)\n",
    "    STATE, Disp, A_true, Zs_true = generate_seq(T, dt, Boundary, init_v, noise_cov)\n",
    "    ## true global variables\n",
    "    cov_true = np.tile(noise_cov, (K, 1, 1))\n",
    "    dirs = np.array([[1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "    mu_true = np.tile(np.absolute(init_v), (K, 1)) * dirs\n",
    "    Pi_true = np.ones(K) * (1/K)\n",
    "    cov_ks = torch.from_numpy(cov_true).float()\n",
    "    mu_ks = torch.from_numpy(mu_true).float()\n",
    "    Pi = torch.from_numpy(Pi_true).float()\n",
    "    A_init = initial_trans(alpha_trans_0, K)\n",
    "#     A_init = torch.from_numpy(A_true).float()\n",
    "    alpha_trans_0 = initial_trans_prior(K)\n",
    "    Y = torch.from_numpy(Disp).float()\n",
    "    \n",
    "\n",
    "    enc, loss_infer, eubo, kl, ess, latents_dirs, Z_ret = rws(enc, A_init, alpha_trans_0, Pi, mu_ks, cov_ks, Y, T, D, K, num_particles_rws, num_particles_smc, mcmc_steps)\n",
    "#     kl_est = torch.mul(weights_rws, log_p_conds - log_qs).sum().detach().item()\n",
    "    log_q = - loss_infer\n",
    "    eubo.backward()\n",
    "    KLs.append(kl.item())\n",
    "    EUBOs.append(eubo)\n",
    "    ESSs.append(ess)\n",
    "    log_qs.append(log_q)\n",
    "    optimizer.step()\n",
    "#     A_samples = A_samples.detach()\n",
    "    time_end = time.time()\n",
    "    print('epoch : %d, eubo : %f, log_q : %f, KL : %f (%ds)' % (epoch, eubo, log_q, kl, time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_dicichlet_post = latents_dirs\n",
    "true_dirichlet_post = alpha_trans_0 + pairwise(torch.from_numpy(Zs_true).float(), T).sum(0)\n",
    "print('variational : ')\n",
    "print(learned_dicichlet_post)\n",
    "print('conjugate posterior :')\n",
    "print(true_dirichlet_post)\n",
    "plot_dirs(learned_dicichlet_post.data.numpy(), true_dirichlet_post.data.numpy(), vmax=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(ESSs) / num_particles_rws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_dicichlet_post.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
