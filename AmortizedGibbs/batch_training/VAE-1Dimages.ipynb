{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.0.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from data import *\n",
    "from objectives import *\n",
    "from plots import *\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "from torchvision import datasets, transforms\n",
    "import probtorch\n",
    "from probtorch.util import expand_inputs\n",
    "\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "D = 2\n",
    "NUM_PIXELS = 32*32\n",
    "pixels=32\n",
    "## Model Parameters\n",
    "NUM_SAMPLES = 10\n",
    "NUM_HIDDEN = 256\n",
    "NUM_LATENT = 2\n",
    "NUM_OBS = NUM_PIXELS\n",
    "BATCH_SIZE = T\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EPS = 1e-9\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "ALPHA = 0.1\n",
    "BETA = (2.0, 2.0, 1.0, 0.0, 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        self.enc_hidden = nn.Sequential( \n",
    "                            nn.Linear(num_pixels, num_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(num_hidden, num_hidden),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "        self.z_mean = nn.Linear(num_hidden, num_latent)\n",
    "        self.z_log_std = nn.Linear(num_hidden, num_latent)\n",
    "    @expand_inputs\n",
    "    def forward(self, images, labels=None, num_samples=NUM_SAMPLES):\n",
    "        q = probtorch.Trace()\n",
    "        hiddens = self.enc_hidden(images)\n",
    "        q.normal(self.z_mean(hiddens),\n",
    "                 self.z_log_std(hiddens).exp(),\n",
    "                 name='z')\n",
    "        return q\n",
    "    \n",
    "def binary_cross_entropy(x_mean, x, EPS=1e-9):\n",
    "    return - (torch.log(x_mean + EPS) * x + \n",
    "              torch.log(1 - x_mean + EPS) * (1 - x)).sum(-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_pixels=NUM_PIXELS, \n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latent=NUM_LATENT):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.dec_image = nn.Sequential(\n",
    "                           nn.Linear(num_latent, num_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(num_hidden, num_pixels),\n",
    "                           nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images, q=None, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE, num_latent=NUM_LATENT):\n",
    "        p = probtorch.Trace()\n",
    "        z_mean = torch.zeros(num_samples, batch_size, num_latent)\n",
    "        z_std = torch.ones(num_samples, batch_size, num_latent)\n",
    "        \n",
    "        if CUDA:\n",
    "            z_mean = z_mean.cuda()\n",
    "            z_std = z_std.cuda()\n",
    "        \n",
    "        z = p.normal(z_mean, \n",
    "                     z_std,\n",
    "                     value=q['z'],\n",
    "                     name='z')\n",
    "        \n",
    "        images_mean = self.dec_image(z)\n",
    "        p.loss(binary_cross_entropy, images_mean, images, name='images')\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo(q, p, alpha=ALPHA, beta=BETA, bias=1.0):\n",
    "    return probtorch.objectives.marginal.elbo(q, p, sample_dim=0, batch_dim=1,\n",
    "                                              alpha=alpha, beta=beta, bias=bias)\n",
    "\n",
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "if CUDA:\n",
    "    enc.cuda()\n",
    "    dec.cuda()\n",
    "\n",
    "optimizer =  torch.optim.Adam(list(enc.parameters())+list(dec.parameters()),\n",
    "                              lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_path = '/home/hao/Research/amortized/AmortizedGibbs/batch_training/images/'\n",
    "ToGrayscaleTensor = transforms.Compose([transforms.Grayscale(), transforms.Resize(pixels), transforms.ToTensor()])\n",
    "train_data = datasets.ImageFolder(root = pixels_path, transform=ToGrayscaleTensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train: ELBO -3.9619e+00 (4s)\n",
      "[Epoch 1] Train: ELBO -2.5422e+00 (4s)\n",
      "[Epoch 2] Train: ELBO -2.4678e+00 (4s)\n",
      "[Epoch 3] Train: ELBO -2.0009e+00 (4s)\n",
      "[Epoch 4] Train: ELBO -1.6914e+00 (4s)\n",
      "[Epoch 5] Train: ELBO -1.5457e+00 (3s)\n",
      "[Epoch 6] Train: ELBO -1.4481e+00 (3s)\n",
      "[Epoch 7] Train: ELBO -1.3743e+00 (3s)\n",
      "[Epoch 8] Train: ELBO -1.3158e+00 (3s)\n",
      "[Epoch 9] Train: ELBO -1.2651e+00 (3s)\n",
      "[Epoch 10] Train: ELBO -1.2256e+00 (3s)\n",
      "[Epoch 11] Train: ELBO -1.1890e+00 (3s)\n",
      "[Epoch 12] Train: ELBO -1.1562e+00 (3s)\n",
      "[Epoch 13] Train: ELBO -1.1272e+00 (3s)\n",
      "[Epoch 14] Train: ELBO -1.0994e+00 (3s)\n",
      "[Epoch 15] Train: ELBO -1.0763e+00 (3s)\n",
      "[Epoch 16] Train: ELBO -1.0552e+00 (3s)\n",
      "[Epoch 17] Train: ELBO -1.0357e+00 (3s)\n",
      "[Epoch 18] Train: ELBO -1.0153e+00 (3s)\n",
      "[Epoch 19] Train: ELBO -9.9740e-01 (3s)\n",
      "[Epoch 20] Train: ELBO -9.8265e-01 (3s)\n",
      "[Epoch 21] Train: ELBO -9.6566e-01 (3s)\n",
      "[Epoch 22] Train: ELBO -9.5023e-01 (3s)\n",
      "[Epoch 23] Train: ELBO -9.3585e-01 (3s)\n",
      "[Epoch 24] Train: ELBO -9.2341e-01 (3s)\n",
      "[Epoch 25] Train: ELBO -9.0983e-01 (3s)\n",
      "[Epoch 26] Train: ELBO -8.9956e-01 (3s)\n",
      "[Epoch 27] Train: ELBO -8.8764e-01 (3s)\n",
      "[Epoch 28] Train: ELBO -8.7582e-01 (3s)\n",
      "[Epoch 29] Train: ELBO -8.6340e-01 (3s)\n",
      "[Epoch 30] Train: ELBO -8.5433e-01 (3s)\n",
      "[Epoch 31] Train: ELBO -8.4460e-01 (4s)\n",
      "[Epoch 32] Train: ELBO -8.3503e-01 (4s)\n",
      "[Epoch 33] Train: ELBO -8.2824e-01 (4s)\n",
      "[Epoch 34] Train: ELBO -8.1978e-01 (3s)\n",
      "[Epoch 35] Train: ELBO -8.0864e-01 (3s)\n",
      "[Epoch 36] Train: ELBO -8.0281e-01 (3s)\n",
      "[Epoch 37] Train: ELBO -7.9433e-01 (3s)\n",
      "[Epoch 38] Train: ELBO -7.8510e-01 (4s)\n",
      "[Epoch 39] Train: ELBO -7.7648e-01 (4s)\n",
      "[Epoch 40] Train: ELBO -7.6954e-01 (4s)\n",
      "[Epoch 41] Train: ELBO -7.6167e-01 (4s)\n",
      "[Epoch 42] Train: ELBO -7.5241e-01 (4s)\n",
      "[Epoch 43] Train: ELBO -7.4610e-01 (4s)\n",
      "[Epoch 44] Train: ELBO -7.3885e-01 (4s)\n",
      "[Epoch 45] Train: ELBO -7.3356e-01 (4s)\n",
      "[Epoch 46] Train: ELBO -7.2961e-01 (4s)\n",
      "[Epoch 47] Train: ELBO -7.1970e-01 (4s)\n",
      "[Epoch 48] Train: ELBO -7.1383e-01 (4s)\n",
      "[Epoch 49] Train: ELBO -7.0750e-01 (4s)\n",
      "[Epoch 50] Train: ELBO -7.0542e-01 (4s)\n",
      "[Epoch 51] Train: ELBO -6.9741e-01 (4s)\n",
      "[Epoch 52] Train: ELBO -6.9005e-01 (4s)\n",
      "[Epoch 53] Train: ELBO -6.8380e-01 (4s)\n",
      "[Epoch 54] Train: ELBO -6.7952e-01 (3s)\n",
      "[Epoch 55] Train: ELBO -6.7348e-01 (3s)\n",
      "[Epoch 56] Train: ELBO -6.6915e-01 (4s)\n",
      "[Epoch 57] Train: ELBO -6.6255e-01 (4s)\n",
      "[Epoch 58] Train: ELBO -6.6100e-01 (4s)\n",
      "[Epoch 59] Train: ELBO -6.5446e-01 (4s)\n",
      "[Epoch 60] Train: ELBO -6.4884e-01 (3s)\n",
      "[Epoch 61] Train: ELBO -6.4505e-01 (4s)\n",
      "[Epoch 62] Train: ELBO -6.4045e-01 (4s)\n",
      "[Epoch 63] Train: ELBO -6.3621e-01 (4s)\n",
      "[Epoch 64] Train: ELBO -6.3320e-01 (4s)\n",
      "[Epoch 65] Train: ELBO -6.2839e-01 (4s)\n",
      "[Epoch 66] Train: ELBO -6.2541e-01 (3s)\n",
      "[Epoch 67] Train: ELBO -6.2072e-01 (3s)\n",
      "[Epoch 68] Train: ELBO -6.1812e-01 (3s)\n",
      "[Epoch 69] Train: ELBO -6.1218e-01 (4s)\n",
      "[Epoch 70] Train: ELBO -6.0997e-01 (4s)\n",
      "[Epoch 71] Train: ELBO -6.0567e-01 (4s)\n",
      "[Epoch 72] Train: ELBO -6.0054e-01 (4s)\n",
      "[Epoch 73] Train: ELBO -5.9952e-01 (4s)\n",
      "[Epoch 74] Train: ELBO -5.9653e-01 (4s)\n",
      "[Epoch 75] Train: ELBO -5.9314e-01 (3s)\n",
      "[Epoch 76] Train: ELBO -5.9336e-01 (3s)\n",
      "[Epoch 77] Train: ELBO -5.8649e-01 (3s)\n",
      "[Epoch 78] Train: ELBO -5.8541e-01 (3s)\n",
      "[Epoch 79] Train: ELBO -5.8144e-01 (4s)\n",
      "[Epoch 80] Train: ELBO -5.8156e-01 (4s)\n",
      "[Epoch 81] Train: ELBO -5.7712e-01 (4s)\n",
      "[Epoch 82] Train: ELBO -5.7447e-01 (4s)\n",
      "[Epoch 83] Train: ELBO -5.7032e-01 (4s)\n",
      "[Epoch 84] Train: ELBO -5.6790e-01 (4s)\n",
      "[Epoch 85] Train: ELBO -5.6710e-01 (4s)\n",
      "[Epoch 86] Train: ELBO -5.6590e-01 (4s)\n",
      "[Epoch 87] Train: ELBO -5.6060e-01 (3s)\n",
      "[Epoch 88] Train: ELBO -5.5803e-01 (3s)\n",
      "[Epoch 89] Train: ELBO -5.5783e-01 (3s)\n",
      "[Epoch 90] Train: ELBO -5.6041e-01 (3s)\n",
      "[Epoch 91] Train: ELBO -5.5560e-01 (3s)\n",
      "[Epoch 92] Train: ELBO -5.5298e-01 (3s)\n",
      "[Epoch 93] Train: ELBO -5.5104e-01 (3s)\n",
      "[Epoch 94] Train: ELBO -5.4880e-01 (3s)\n",
      "[Epoch 95] Train: ELBO -5.4293e-01 (4s)\n",
      "[Epoch 96] Train: ELBO -5.3925e-01 (4s)\n",
      "[Epoch 97] Train: ELBO -5.3791e-01 (4s)\n",
      "[Epoch 98] Train: ELBO -5.3821e-01 (4s)\n",
      "[Epoch 99] Train: ELBO -5.3616e-01 (4s)\n"
     ]
    }
   ],
   "source": [
    "enc.train()\n",
    "dec.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_start = time.time()\n",
    "    epoch_elbo = 0.0\n",
    "    N = 0.0\n",
    "    for b, (images, labels) in enumerate(train_loader):\n",
    "        if images.size()[0] == BATCH_SIZE:\n",
    "            N += BATCH_SIZE\n",
    "            images = images.view(-1, NUM_PIXELS)\n",
    "            images = torch.where(images == 1.0, torch.FloatTensor([0.0]), torch.FloatTensor([1.0]))\n",
    "            if CUDA:\n",
    "                images = images.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            q = enc(images, num_samples=NUM_SAMPLES)\n",
    "            p = dec(images, q, num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE)\n",
    "            loss = -elbo(q, p)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if CUDA:\n",
    "                loss = loss.cpu()\n",
    "            epoch_elbo -= float(loss.item())\n",
    "    epoch_elbo = epoch_elbo / N\n",
    "    train_end = time.time()\n",
    "    print('[Epoch %d] Train: ELBO %.4e (%ds)' % (epoch, epoch_elbo, train_end - train_start))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(STATE, Boundary, pixels, dpi, radius, 0):\n",
    "    length_states = 51\n",
    "    for s in range(length_states):\n",
    "        np.load()\n",
    "        plt.savefig('images/%s-%s.png' % (str(seq_ind), str(s)),dpi=dpi)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/dev/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from scipy import misc\n",
    "a = misc.imread('images/0-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01202d6080>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a[:, :, -1],  cmap='gray', vmin=0.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
