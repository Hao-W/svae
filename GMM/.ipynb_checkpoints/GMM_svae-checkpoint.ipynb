{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gmm_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1cd9414df78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from util_gmm_svae import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_svae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgmm_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspiral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gmm_dataset'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import sys\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "import probtorch\n",
    "from probtorch.util import log_sum_exp\n",
    "from util_svae import *\n",
    "import numpy as np\n",
    "from spiral import *\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import sys\n",
    "from torchvision import datasets, transforms\n",
    "import pickle\n",
    "import time\n",
    "%matplotlib inline\n",
    "sys.path.append('/home/hao/Research/probtorch/')\n",
    "from probtorch.util import expand_inputs\n",
    "import probtorch\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_clusters = 5          # number of clusters in pinwheel data\n",
    "samples_per_cluster = 100  # number of samples per cluster in pinwheel\n",
    "spiral_data = make_pinwheel_data(0.3, 0.05, num_clusters, samples_per_cluster, 0.25)\n",
    "plot_data(spiral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5               # number of components in mixture model\n",
    "D = 2 # latent dimension\n",
    "B = 2\n",
    "N = num_clusters * samples_per_cluster\n",
    "Y = torch.FloatTensor(spiral_data)\n",
    "\n",
    "#############\n",
    "# model parameters\n",
    "NUM_HIDDEN = 40\n",
    "NUM_LATENTS = 2\n",
    "NUM_OBS = 2\n",
    "# training parameters\n",
    "NUM_SAMPLES = 1\n",
    "BATCH_SIZE = 500\n",
    "NUM_EPOCHS = 300\n",
    "LEARNING_RATE = 1e-4\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "RESTORE = False\n",
    "\n",
    "#############\n",
    "## prior\n",
    "alpha_0 = torch.ones(K)\n",
    "m_0 = Y.mean(0)\n",
    "beta_0 = 1.0\n",
    "nu_0 = 6.0\n",
    "W_0 =  (nu_0-B-1) * torch.mm((Y - m_0).transpose(0,1), (Y - m_0)) / (N)\n",
    "W_0 = W_0.float()\n",
    "cov = torch.from_numpy(np.cov(Y.transpose(0,1))).float()\n",
    "\n",
    "alpha_hat = alpha_0\n",
    "m_ks = MultivariateNormal(m_0, cov).sample((K,))\n",
    "beta_ks = (torch.ones(K) * beta_0)\n",
    "nu_ks = (torch.ones(K) * nu_0)\n",
    "W_ks = W_0.repeat(K, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_obs=B,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=D):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.enc_hidden = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.Tanh())\n",
    "        self.latent_mean = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        self.latent_log_var = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_latents))\n",
    "        \n",
    "    @expand_inputs\n",
    "    def forward(self, obs, log_gammas, batch_size, num_samples=None):\n",
    "        q = probtorch.Trace()\n",
    "        hidden = self.enc_hidden(obs)\n",
    "        nn_eta1 = self.latent_mean(hidden)\n",
    "        nn_eta2 = -1 * torch.exp(self.latent_log_var(hidden))\n",
    "        \n",
    "        opt_batch_eta1, opt_batch_eta2 = local_optimal(nn_eta1.cpu(), nn_eta2.cpu(), log_gammas, alpha_hat, nu_ks, W_ks, m_ks, beta_ks, D, K)\n",
    "        opt_batch_eta1 = opt_batch_eta1.float().cuda()\n",
    "        opt_batch_eta2 = opt_batch_eta2.float().cuda()\n",
    "\n",
    "        full_nn_eta2 = torch.zeros((num_samples, batch_size, D, D)).cuda()\n",
    "        full_nn_eta2[:, :, torch.arange(D).long(), torch.arange(D).long()] = nn_eta2  \n",
    "        \n",
    "        qx_eta1 = nn_eta1.squeeze(0) + opt_batch_eta1\n",
    "        qx_eta2 = full_nn_eta2.squeeze(0) + opt_batch_eta2\n",
    "        \n",
    "        qx_sigma = torch.zeros((batch_size, D, D)).cuda()\n",
    "        for n in range(batch_size):\n",
    "            qx_sigma[n] = (-1 / 2) * torch.inverse(qx_eta2[n])\n",
    "        qx_mu = torch.bmm(qx_sigma, qx_eta1.unsqueeze(-1)).permute(2, 0, 1)\n",
    "        qx_sigma = qx_sigma.unsqueeze(0)\n",
    "        q.multivariate_normal(qx_mu, qx_sigma, name='z')\n",
    "      \n",
    "        return q, qx_mu.cpu().squeeze(0), qx_sigma.cpu().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_obs=B,\n",
    "                       num_hidden=NUM_HIDDEN,\n",
    "                       num_latents=D,\n",
    "                       num_samples=NUM_SAMPLES):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dec_hidden = nn.Sequential(\n",
    "            nn.Linear(num_latents, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_obs)\n",
    "            )\n",
    "    def forward(self, obs, q=None, num_samples=None):\n",
    "        p = probtorch.Trace()\n",
    "        batch_size = obs.shape[0]\n",
    "        prior_mean = torch.zeros((NUM_SAMPLES, batch_size, D)).cuda()\n",
    "        prior_cov = torch.ones((NUM_SAMPLES, batch_size, D)).cuda()\n",
    "        ## here need to change value to samples from combined natparams,\n",
    "        ## also need to change the prior to \n",
    "        latents = p.normal(prior_mean, prior_cov, value=q['z'], name='z')   \n",
    "        obs_recon = self.dec_hidden(latents)\n",
    "        p.loss(mse_loss, obs_recon, obs, name='observations')\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(x_hat, x):\n",
    "    return torch.norm(x_hat - x, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    enc = Encoder()\n",
    "    dec = Decoder()\n",
    "    if CUDA:\n",
    "        enc.cuda()\n",
    "        dec.cuda()\n",
    "    optimizer =  torch.optim.Adam(list(enc.parameters())+list(dec.parameters()),lr=LEARNING_RATE)    \n",
    "    return enc, dec, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VBEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20\n",
    "enc, dec, optimizer = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_elbos = []\n",
    "# for i in range(iterations):\n",
    "#     Y_shuffled = shuffler(Y).float()\n",
    "#     if CUDA:\n",
    "#         Y_shuffled = Y_shuffled.cuda()\n",
    "# #     q = enc(Y_shuffled, num_samples=NUM_SAMPLES)\n",
    "#     ## VBE step\n",
    "#     log_gammas = vbE_step(alpha_hat, nu_ks, W_ks, m_ks, beta_ks, Y, N, B, K)\n",
    "#     N_ks, Y_ks, S_ks = stats(log_gammas, Y, B, K)\n",
    "#     ## VBM step\n",
    "#     alpha_hat, nu_ks, W_ks, m_ks, beta_ks, cov_ks = vbM_step(alpha_0, nu_0, W_0, m_0, beta_0, N_ks, Y_ks, S_ks, N, B, K)\n",
    "#     epoch_elbo = elbo(log_gammas, alpha_0, nu_0, W_0, m_0, beta_0, N_ks, Y_ks, S_ks, alpha_hat, nu_ks, W_ks, m_ks, beta_ks, Y, N, B, K)\n",
    "#     epoch_elbos.append(epoch_elbo)\n",
    "# #     print('Iteration:%d, ELBO:%f' % ((i+1), epoch_elbo))\n",
    "# final_covs = cov_ks.data.numpy() ## mean of inverse wishart\n",
    "# final_mus = m_ks.data.numpy() ## mean of gaussian\n",
    "# Y_np = Y.data.numpy()\n",
    "\n",
    "# batch_eta1, batch_eta2 = gaussian_global(log_gammas, nu_ks, W_ks, m_ks, Y, N, D, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_clusters(Y_np, final_mus, cov_ks, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration limit reached\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "log_gammas = torch.randn((batch_size, K))\n",
    "if CUDA:\n",
    "    Y_1 = Y.float().cuda()\n",
    "q, qx_mu, qx_sigma = enc(Y_1, log_gammas, batch_size=batch_size, num_samples=NUM_SAMPLES)  \n",
    "p = dec(Y_1, q, num_samples=NUM_SAMPLES)\n",
    "loss = - elbo_nn(qx_mu, qx_sigma, log_gammas, alpha_0, nu_0, W_0, m_0, beta_0, alpha_hat, nu_ks, W_ks, m_ks, beta_ks, batch_size, D, K, q, p, sample_dim=None, batch_dim=None, log_weights=None, size_average=True, reduce=True)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ks, qx_mu_ks, NS_ks, nk_qx_sigma_ks = stats_2(log_gammas, qx_mu, qx_sigma, D, K)\n",
    "alpha_hat, nu_ks, W_ks, m_ks, beta_ks, cov_ks = global_optimal(alpha_0, nu_0, W_0, m_0, beta_0, N_ks, qx_mu_ks, NS_ks, nk_qx_sigma_ks, batch_size, D, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
