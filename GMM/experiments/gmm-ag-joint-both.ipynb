{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.4.1 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../gmm_dataset_3c\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 3 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_LOCAL = 32\n",
    "\n",
    "MCMC_SIZE = 10\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 5 * 1e-4\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'ag-joint-both'\n",
    "DEVICE = torch.device('cuda:1')\n",
    "\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (N, K, D, MCMC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc import *\n",
    "from global_oneshot import *\n",
    "from global_enc_v1 import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_eta = Enc_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "oneshot_eta = Oneshot_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "\n",
    "if CUDA:\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_eta.cuda().to(DEVICE)\n",
    "    oneshot_eta.cuda().to(DEVICE)\n",
    "optimizer =  torch.optim.Adam(list(oneshot_eta.parameters())+list(enc_eta.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_eta, enc_eta, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\200 (132s),  loss: -12609.133,  ess: 1.055,  kl_eta_ex: 368.086,  kl_eta_in: 197.540,  kl_z_ex: 76.198,  kl_z_in: 20.801\n",
      "epoch: 1\\200 (135s),  loss: -9665.123,  ess: 1.119,  kl_eta_ex: 185.048,  kl_eta_in: 285.846,  kl_z_ex: 20.463,  kl_z_in: 9.919\n",
      "epoch: 2\\200 (133s),  loss: -9352.736,  ess: 1.127,  kl_eta_ex: 165.544,  kl_eta_in: 314.056,  kl_z_ex: 15.218,  kl_z_in: 8.083\n",
      "epoch: 3\\200 (136s),  loss: -9200.280,  ess: 1.129,  kl_eta_ex: 157.347,  kl_eta_in: 299.606,  kl_z_ex: 13.749,  kl_z_in: 7.577\n",
      "epoch: 4\\200 (134s),  loss: -9055.847,  ess: 1.123,  kl_eta_ex: 150.005,  kl_eta_in: 291.199,  kl_z_ex: 12.842,  kl_z_in: 7.299\n",
      "epoch: 5\\200 (134s),  loss: -8936.190,  ess: 1.126,  kl_eta_ex: 143.837,  kl_eta_in: 284.160,  kl_z_ex: 12.650,  kl_z_in: 7.278\n",
      "epoch: 6\\200 (135s),  loss: -8832.367,  ess: 1.120,  kl_eta_ex: 138.833,  kl_eta_in: 288.417,  kl_z_ex: 12.495,  kl_z_in: 7.164\n",
      "epoch: 7\\200 (135s),  loss: -8741.227,  ess: 1.119,  kl_eta_ex: 136.079,  kl_eta_in: 297.323,  kl_z_ex: 13.078,  kl_z_in: 7.201\n",
      "epoch: 8\\200 (136s),  loss: -8672.157,  ess: 1.115,  kl_eta_ex: 134.334,  kl_eta_in: 322.405,  kl_z_ex: 14.083,  kl_z_in: 7.276\n",
      "epoch: 9\\200 (135s),  loss: -8580.427,  ess: 1.110,  kl_eta_ex: 133.070,  kl_eta_in: 358.298,  kl_z_ex: 14.360,  kl_z_in: 7.203\n",
      "epoch: 10\\200 (136s),  loss: -8493.027,  ess: 1.117,  kl_eta_ex: 129.345,  kl_eta_in: 380.987,  kl_z_ex: 13.539,  kl_z_in: 6.742\n",
      "epoch: 11\\200 (121s),  loss: -8399.933,  ess: 1.117,  kl_eta_ex: 125.393,  kl_eta_in: 389.377,  kl_z_ex: 12.799,  kl_z_in: 6.260\n",
      "epoch: 12\\200 (126s),  loss: -8317.290,  ess: 1.125,  kl_eta_ex: 120.749,  kl_eta_in: 375.729,  kl_z_ex: 11.753,  kl_z_in: 5.649\n",
      "epoch: 13\\200 (128s),  loss: -8244.944,  ess: 1.128,  kl_eta_ex: 117.802,  kl_eta_in: 356.752,  kl_z_ex: 11.792,  kl_z_in: 5.264\n",
      "epoch: 14\\200 (129s),  loss: -8181.431,  ess: 1.134,  kl_eta_ex: 115.338,  kl_eta_in: 324.970,  kl_z_ex: 12.835,  kl_z_in: 4.926\n",
      "epoch: 15\\200 (129s),  loss: -7924.313,  ess: 1.156,  kl_eta_ex: 99.839,  kl_eta_in: 272.676,  kl_z_ex: 11.039,  kl_z_in: 4.185\n",
      "epoch: 16\\200 (136s),  loss: -7453.732,  ess: 1.212,  kl_eta_ex: 69.480,  kl_eta_in: 183.659,  kl_z_ex: 6.803,  kl_z_in: 3.297\n",
      "epoch: 17\\200 (133s),  loss: -6878.826,  ess: 1.245,  kl_eta_ex: 47.180,  kl_eta_in: 132.474,  kl_z_ex: 3.336,  kl_z_in: 2.188\n",
      "epoch: 18\\200 (113s),  loss: -6666.962,  ess: 1.230,  kl_eta_ex: 47.650,  kl_eta_in: 122.818,  kl_z_ex: 3.843,  kl_z_in: 2.445\n",
      "epoch: 19\\200 (136s),  loss: -6517.212,  ess: 1.225,  kl_eta_ex: 45.323,  kl_eta_in: 105.954,  kl_z_ex: 3.913,  kl_z_in: 2.622\n",
      "epoch: 20\\200 (134s),  loss: -6378.003,  ess: 1.238,  kl_eta_ex: 39.901,  kl_eta_in: 87.788,  kl_z_ex: 3.771,  kl_z_in: 2.593\n",
      "epoch: 21\\200 (118s),  loss: -6240.918,  ess: 1.266,  kl_eta_ex: 34.886,  kl_eta_in: 71.425,  kl_z_ex: 3.632,  kl_z_in: 2.561\n",
      "epoch: 22\\200 (127s),  loss: -6121.358,  ess: 1.293,  kl_eta_ex: 29.371,  kl_eta_in: 56.890,  kl_z_ex: 3.314,  kl_z_in: 2.429\n",
      "epoch: 23\\200 (107s),  loss: -5993.813,  ess: 1.335,  kl_eta_ex: 23.173,  kl_eta_in: 47.658,  kl_z_ex: 3.208,  kl_z_in: 2.556\n",
      "epoch: 24\\200 (131s),  loss: -5754.813,  ess: 1.426,  kl_eta_ex: 15.598,  kl_eta_in: 27.419,  kl_z_ex: 2.878,  kl_z_in: 2.114\n",
      "epoch: 25\\200 (129s),  loss: -5574.313,  ess: 1.708,  kl_eta_ex: 8.239,  kl_eta_in: 15.452,  kl_z_ex: 2.150,  kl_z_in: 1.503\n",
      "epoch: 26\\200 (129s),  loss: -5471.767,  ess: 2.050,  kl_eta_ex: 3.713,  kl_eta_in: 6.750,  kl_z_ex: 1.545,  kl_z_in: 1.028\n",
      "epoch: 27\\200 (136s),  loss: -5434.812,  ess: 2.290,  kl_eta_ex: 1.813,  kl_eta_in: 2.456,  kl_z_ex: 1.264,  kl_z_in: 0.820\n",
      "epoch: 28\\200 (132s),  loss: -5420.339,  ess: 2.502,  kl_eta_ex: 0.970,  kl_eta_in: 0.893,  kl_z_ex: 1.132,  kl_z_in: 0.718\n",
      "epoch: 29\\200 (104s),  loss: -5418.222,  ess: 2.654,  kl_eta_ex: 0.441,  kl_eta_in: 0.283,  kl_z_ex: 1.040,  kl_z_in: 0.656\n",
      "epoch: 30\\200 (128s),  loss: -5417.816,  ess: 2.737,  kl_eta_ex: 0.210,  kl_eta_in: 0.105,  kl_z_ex: 0.984,  kl_z_in: 0.630\n",
      "epoch: 31\\200 (128s),  loss: -5416.995,  ess: 2.789,  kl_eta_ex: 0.533,  kl_eta_in: 0.086,  kl_z_ex: 0.918,  kl_z_in: 0.583\n",
      "epoch: 32\\200 (136s),  loss: -5415.311,  ess: 2.847,  kl_eta_ex: 0.210,  kl_eta_in: 0.038,  kl_z_ex: 0.855,  kl_z_in: 0.557\n",
      "epoch: 33\\200 (126s),  loss: -5415.888,  ess: 2.873,  kl_eta_ex: 0.072,  kl_eta_in: 0.065,  kl_z_ex: 0.779,  kl_z_in: 0.503\n",
      "epoch: 34\\200 (135s),  loss: -5416.522,  ess: 2.904,  kl_eta_ex: 0.054,  kl_eta_in: 0.048,  kl_z_ex: 0.736,  kl_z_in: 0.475\n"
     ]
    }
   ],
   "source": [
    "from ag_ep import *\n",
    "train(models, EUBO_init_eta_joint_both, optimizer, Data, Model_Params, Train_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc_z.state_dict(), \"../weights/enc-z-%s\" % PATH)\n",
    "torch.save(enc_eta.state_dict(), \"../weights/enc-eta-%s\" % PATH)\n",
    "torch.save(oneshot_eta.state_dict(), \"../weights/oneshot-eta-%s\" % PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.arange(NUM_DATASETS)\n",
    "step = 2\n",
    "batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "obs = Data[batch_indices]\n",
    "obs = shuffler(obs).repeat(SAMPLE_SIZE, 1, 1, 1)\n",
    "if CUDA:\n",
    "    obs =obs.cuda().to(DEVICE)\n",
    "    \n",
    "q_eta, p_eta, q_nu = oneshot_eta(obs, K, D)\n",
    "obs_mu = q_eta['means'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mu[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_eta['means'].dist.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
