{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 1.1.0 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../gmm_dataset_c20k\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 3 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_LOCAL = 32\n",
    "\n",
    "MCMC_SIZE = 10\n",
    "BATCH_SIZE = 500\n",
    "NUM_EPOCHS = 250\n",
    "LEARNING_RATE = 1e-4\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'AG-hard-os-%dsteps-%dsamples' % (MCMC_SIZE, SAMPLE_SIZE)\n",
    "DEVICE = torch.device('cuda:0')\n",
    "\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (N, K, D, MCMC_SIZE, PRIOR_FLAG, ONLY_FORWARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc import *\n",
    "from global_oneshot import *\n",
    "from global_enc_v1 import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_eta = Enc_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "oneshot_eta = Oneshot_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "if CUDA:\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_eta.cuda().to(DEVICE)\n",
    "    oneshot_eta.cuda().to(DEVICE)\n",
    "optimizer =  torch.optim.Adam(list(oneshot_eta.parameters())+list(enc_eta.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_eta, enc_eta, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Enc_eta:\n\tMissing key(s) in state_dict: \"gamma.0.weight\", \"gamma.0.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-13a63e6e8f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menc_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../weights/enc-z-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menc_eta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../weights/enc-eta-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moneshot_eta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../weights/oneshot-eta-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Enc_eta:\n\tMissing key(s) in state_dict: \"gamma.0.weight\", \"gamma.0.bias\". "
     ]
    }
   ],
   "source": [
    "enc_z.load_state_dict(torch.load(\"../weights/enc-z-%s\" % PATH))\n",
    "enc_eta.load_state_dict(torch.load(\"../weights/enc-eta-%s\" % PATH))\n",
    "oneshot_eta.load_state_dict(torch.load(\"../weights/oneshot-eta-%s\" % PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MCMC_STEPS = 10 ## 12 is maximum mcmc steps\n",
    "SAMPLE_SIZE = 1\n",
    "BATCH_SIZE = 5\n",
    "Vis_Interval = 2\n",
    "##\n",
    "colors = ['#0077BB', '#009988', '#EE7733']\n",
    "gs = gridspec.GridSpec(BATCH_SIZE, 2+int(MAX_MCMC_STEPS / Vis_Interval))\n",
    "gs.update(left=0.0 , bottom=0.0, right=1.0, top=1.0, wspace=0, hspace=0)\n",
    "fig = plt.figure(figsize=(30,25))\n",
    "\n",
    "indices = torch.arange(NUM_DATASETS)\n",
    "step = 2\n",
    "batch_indices = indices[step*BATCH_SIZE : (step+1)*BATCH_SIZE]\n",
    "obs = Data[batch_indices]\n",
    "obs = shuffler(obs).repeat(SAMPLE_SIZE, 1, 1, 1)\n",
    "if CUDA:\n",
    "    obs =obs.cuda().to(DEVICE)\n",
    "    \n",
    "xs = obs[0].cpu().data.numpy()    \n",
    "for b in range(BATCH_SIZE):\n",
    "    xb = xs[b]\n",
    "    ax = fig.add_subplot(gs[b, 0])\n",
    "    ax.scatter(xb[:, 0], xb[:, 1], c='k')\n",
    "    ax.set_ylim([-12, 12])\n",
    "    ax.set_xlim([-12, 12])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if b == 0:\n",
    "        ax.set_title('Data', fontsize=30)\n",
    "        \n",
    "obs_tau, obs_mu = enc_eta.sample_prior(SAMPLE_SIZE, BATCH_SIZE)\n",
    "q_z, p_z = enc_z.forward(obs, obs_tau, obs_mu, N, K, SAMPLE_SIZE, BATCH_SIZE)\n",
    "state = q_z['zs'].value ## S * B * N * K    \n",
    "\n",
    "E_z = state.mean(0).cpu().data.numpy()\n",
    "E_mu = obs_mu.mean(0).cpu().data.numpy()\n",
    "E_tau = obs_tau.mean(0).cpu().data.numpy()\n",
    "\n",
    "\n",
    "# q_eta, p_eta, q_nu = oneshot_eta(obs, K, D)\n",
    "# obs_mu = q_eta['means'].value\n",
    "# obs_tau = q_eta['precisions'].value\n",
    "# q_z, p_z = enc_z.forward(obs, obs_tau, obs_mu, N, K, SAMPLE_SIZE, BATCH_SIZE)\n",
    "# state = q_z['zs'].value ## S * B * N * K\n",
    "# E_z = q_z['zs'].dist.probs[0].cpu().data.numpy()\n",
    "# E_mu = q_eta['means'].dist.loc[0].cpu().data.numpy()\n",
    "# E_tau = (q_eta['precisions'].dist.concentration[0] / q_eta['precisions'].dist.rate[0]).cpu().data.numpy()\n",
    "\n",
    "for b in range(BATCH_SIZE):\n",
    "    ax = fig.add_subplot(gs[b, 1])\n",
    "    xb = xs[b]\n",
    "    zb = E_z[b]\n",
    "    mu = E_mu[b].reshape(K, D)\n",
    "    sigma2 = 1. / E_tau[b]\n",
    "    assignments = zb.argmax(-1)\n",
    "    for k in range(K):\n",
    "        cov_k = np.diag(sigma2[k])\n",
    "        xk = xb[np.where(assignments == k)]\n",
    "        ax.scatter(xk[:, 0], xk[:, 1], c=colors[k], zorder=3)\n",
    "        plot_cov_ellipse(cov=cov_k, pos=mu[k], nstd=2, ax=ax, alpha=0.3, color=colors[k])\n",
    "    ax.set_ylim([-12, 12])\n",
    "    ax.set_xlim([-12, 12])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if b == 0:\n",
    "        ax.set_title(\"Step 0\", fontsize=30)\n",
    "\n",
    "for m in range(MAX_MCMC_STEPS):\n",
    "    q_eta, p_eta, q_nu = enc_eta(obs, state, K, D)\n",
    "    obs_tau, obs_mu, log_w_eta_f, log_w_eta_b  = Incremental_eta(q_eta, p_eta, obs, state, K, D, obs_tau, obs_mu)\n",
    "    symkl_detailed_balance_eta, eubo_p_q_eta, w_sym_eta, w_f_eta = detailed_balances(log_w_eta_f, log_w_eta_b)\n",
    "    obs_mu, obs_tau = resample_eta(obs_mu, obs_tau, w_f_eta, idw_flag=True) ## resample eta\n",
    "    q_z, p_z = enc_z.forward(obs, obs_tau, obs_mu, N, K, SAMPLE_SIZE, BATCH_SIZE)\n",
    "    state, log_w_z_f, log_w_z_b = Incremental_z(q_z, p_z, obs, obs_tau, obs_mu, K, D, state)\n",
    "    if (m+1) % Vis_Interval == 0:\n",
    "        E_z = q_z['zs'].dist.probs[0].cpu().data.numpy()\n",
    "        E_mu = q_eta['means'].dist.loc[0].cpu().data.numpy()\n",
    "        E_tau = (q_eta['precisions'].dist.concentration[0] / q_eta['precisions'].dist.rate[0]).cpu().data.numpy()\n",
    "        for b in range(BATCH_SIZE):\n",
    "            ax = fig.add_subplot(gs[b, 1+int((m+1)/Vis_Interval)])\n",
    "            xb = xs[b]\n",
    "            zb = E_z[b]\n",
    "            mu = E_mu[b].reshape(K, D)\n",
    "            sigma2 = 1. / E_tau[b]\n",
    "            assignments = zb.argmax(-1)\n",
    "            for k in range(K):\n",
    "                cov_k = np.diag(sigma2[k])\n",
    "                xk = xb[np.where(assignments == k)]\n",
    "                ax.scatter(xk[:, 0], xk[:, 1], c=colors[k])\n",
    "                plot_cov_ellipse(cov=cov_k, pos=mu[k], nstd=2, ax=ax, alpha=0.2, color=colors[k])\n",
    "            ax.set_ylim([-12, 12])\n",
    "            ax.set_xlim([-12, 12])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if b == 0:\n",
    "                ax.set_title('Step %d' % (m+1), fontsize=30)\n",
    "plt.savefig('../results/sample-gmm-' + PATH + '.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Params_Test = (NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (N, K, D, MCMC_SIZE)\n",
    "def test_propagation(models, objective, data, Model_Params, Train_Params):\n",
    "    \"\"\"\n",
    "    generic training function\n",
    "    \"\"\"\n",
    "#     KLs = {\"kl_eta_ex\" : [],\"kl_eta_in\" : [],\"kl_z_ex\" : [],\"kl_z_in\" : []}\n",
    "    Metrics = {\"symKL_DB_eta\" : [], \"symKL_DB_z\" : [], \"ess\" : []}\n",
    "    (NUM_DATASETS, S, B, CUDA, device, path) = Train_Params\n",
    "\n",
    "    NUM_BATCHES = int((NUM_DATASETS / B))\n",
    "\n",
    "    SubTrain_Params = (device, S, B) + Model_Params\n",
    "    indices = torch.randperm(NUM_DATASETS)\n",
    "    time_start = time.time()\n",
    "    for step in range(NUM_BATCHES):\n",
    "        batch_indices = indices[step*B : (step+1)*B]\n",
    "        obs = data[batch_indices]\n",
    "        obs = shuffler(obs).repeat(S, 1, 1, 1)\n",
    "        if CUDA:\n",
    "            obs =obs.cuda().to(device)\n",
    "        metric_step = objective(models, obs, SubTrain_Params)\n",
    "        ## gradient step\n",
    "\n",
    "        for key in Metrics.keys():\n",
    "            if Metrics[key] == None:\n",
    "                Metrics[key] = [metric_step[key].cpu().data.numpy()]\n",
    "            else:\n",
    "                Metrics[key].append(metric_step[key].cpu().data.numpy())\n",
    "                \n",
    "#         if step % 100 == 0:\n",
    "#             time_end = time.time()\n",
    "#             print('iteration:%d/%d' % (step, NUM_BATCHES))\n",
    "#             time_start = time.time()\n",
    "    return Metrics\n",
    "\n",
    "def EUBO_init_eta_prior_test(models, obs, SubTrain_Params):\n",
    "    \"\"\"\n",
    "    NO Resampling\n",
    "    Learn neural gibbs samplers for both eta and z,\n",
    "    non-reparameterized-style gradient estimation\n",
    "    initialize eta\n",
    "    \"\"\"\n",
    "    (device, sample_size, batch_size, N, K, D, mcmc_size) = SubTrain_Params\n",
    "    esss = torch.zeros(mcmc_size+1).cuda().to(device)\n",
    "    symkls_DB_eta = torch.zeros(mcmc_size+1).cuda().to(device)\n",
    "    symkls_DB_z = torch.zeros(mcmc_size+1).cuda().to(device)\n",
    "    (enc_eta, enc_z) = models\n",
    "    obs_tau, obs_mu = enc_eta.sample_prior(sample_size, batch_size)\n",
    "    q_z, p_z = enc_z.forward(obs, obs_tau, obs_mu, N, K, sample_size, batch_size)\n",
    "    log_p_z = p_z['zs'].log_prob\n",
    "    log_q_z = q_z['zs'].log_prob\n",
    "    state = q_z['zs'].value ## S * B * N * K\n",
    "    log_obs_n = Log_likelihood(obs, state, obs_tau, obs_mu, K, D, cluster_flag=False)\n",
    "    log_w_f_z = log_obs_n + log_p_z - log_q_z\n",
    "    w_f_z = F.softmax(log_w_f_z, 0).detach()\n",
    "\n",
    "    symkls_DB_eta[0] = (w_f_z * log_w_f_z).sum(0).sum(-1).mean() - log_w_f_z.sum(-1).mean()\n",
    "    symkls_DB_z[0] = symkls_DB_eta[0] ##\n",
    "    esss[0] = (1. / (w_f_z**2).sum(0)).mean()\n",
    "    for m in range(mcmc_size):\n",
    "#         state = resample_state(state, w_f_z, idw_flag=True)\n",
    "        q_eta, p_eta, q_nu = enc_eta(obs, state, K, D)\n",
    "        obs_tau, obs_mu, log_w_eta_f, log_w_eta_b  = Incremental_eta(q_eta, p_eta, obs, state, K, D, obs_tau, obs_mu)\n",
    "        symkl_detailed_balance_eta, eubo_p_q_eta, w_sym_eta, w_f_eta = detailed_balances(log_w_eta_f, log_w_eta_b)\n",
    "        obs_mu, obs_tau = resample_eta(obs_mu, obs_tau, w_f_eta, idw_flag=True) ## resample eta\n",
    "        q_z, p_z = enc_z.forward(obs, obs_tau, obs_mu, N, K, sample_size, batch_size)\n",
    "        state, log_w_z_f, log_w_z_b = Incremental_z(q_z, p_z, obs, obs_tau, obs_mu, K, D, state)\n",
    "        symkl_detailed_balance_z, eubo_p_q_z, w_sym_z, w_f_z = detailed_balances(log_w_z_f, log_w_z_b)\n",
    "        ## symmetric KLs as metrics\n",
    "        symkls_DB_eta[m+1] = symkl_detailed_balance_eta\n",
    "        symkls_DB_z[m+1] = symkl_detailed_balance_z\n",
    "        esss[m+1] = ((1. / (w_sym_eta**2).sum(0)).mean() + (1. / (w_sym_z**2).sum(0)).mean() ) / 2\n",
    "    metric_step = {\"symKL_DB_eta\" : symkls_DB_eta, \"symKL_DB_z\" : symkls_DB_z, \"ess\" : esss}\n",
    "    return metric_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0\n",
      "iteration : 1\n",
      "iteration : 2\n",
      "iteration : 3\n",
      "iteration : 4\n",
      "iteration : 5\n",
      "iteration : 6\n",
      "iteration : 7\n",
      "iteration : 8\n",
      "iteration : 9\n",
      "iteration : 10\n",
      "iteration : 11\n",
      "iteration : 12\n",
      "iteration : 13\n",
      "iteration : 14\n",
      "iteration : 15\n",
      "iteration : 16\n",
      "iteration : 17\n",
      "iteration : 18\n",
      "iteration : 19\n",
      "iteration : 20\n",
      "iteration : 21\n",
      "iteration : 22\n",
      "iteration : 23\n",
      "iteration : 24\n",
      "iteration : 25\n",
      "iteration : 26\n",
      "iteration : 27\n",
      "iteration : 28\n",
      "iteration : 29\n",
      "iteration : 30\n",
      "iteration : 31\n",
      "iteration : 32\n",
      "iteration : 33\n",
      "iteration : 34\n",
      "iteration : 35\n",
      "iteration : 36\n",
      "iteration : 37\n",
      "iteration : 38\n",
      "iteration : 39\n",
      "iteration : 40\n",
      "iteration : 41\n",
      "iteration : 42\n",
      "iteration : 43\n",
      "iteration : 44\n",
      "iteration : 45\n",
      "iteration : 46\n",
      "iteration : 47\n",
      "iteration : 48\n",
      "iteration : 49\n",
      "iteration : 50\n",
      "iteration : 51\n",
      "iteration : 52\n",
      "iteration : 53\n",
      "iteration : 54\n",
      "iteration : 55\n",
      "iteration : 56\n",
      "iteration : 57\n",
      "iteration : 58\n",
      "iteration : 59\n",
      "iteration : 60\n",
      "iteration : 61\n",
      "iteration : 62\n",
      "iteration : 63\n",
      "iteration : 64\n",
      "iteration : 65\n",
      "iteration : 66\n",
      "iteration : 67\n",
      "iteration : 68\n",
      "iteration : 69\n",
      "iteration : 70\n",
      "iteration : 71\n",
      "iteration : 72\n",
      "iteration : 73\n",
      "iteration : 74\n",
      "iteration : 75\n",
      "iteration : 76\n",
      "iteration : 77\n",
      "iteration : 78\n",
      "iteration : 79\n",
      "iteration : 80\n",
      "iteration : 81\n",
      "iteration : 82\n",
      "iteration : 83\n",
      "iteration : 84\n",
      "iteration : 85\n",
      "iteration : 86\n",
      "iteration : 87\n",
      "iteration : 88\n",
      "iteration : 89\n",
      "iteration : 90\n",
      "iteration : 91\n",
      "iteration : 92\n",
      "iteration : 93\n",
      "iteration : 94\n",
      "iteration : 95\n",
      "iteration : 96\n",
      "iteration : 97\n",
      "iteration : 98\n",
      "iteration : 99\n",
      "iteration : 100\n",
      "iteration : 101\n",
      "iteration : 102\n",
      "iteration : 103\n",
      "iteration : 104\n",
      "iteration : 105\n",
      "iteration : 106\n",
      "iteration : 107\n",
      "iteration : 108\n",
      "iteration : 109\n",
      "iteration : 110\n",
      "iteration : 111\n",
      "iteration : 112\n",
      "iteration : 113\n",
      "iteration : 114\n",
      "iteration : 115\n",
      "iteration : 116\n",
      "iteration : 117\n",
      "iteration : 118\n",
      "iteration : 119\n",
      "iteration : 120\n",
      "iteration : 121\n",
      "iteration : 122\n",
      "iteration : 123\n",
      "iteration : 124\n",
      "iteration : 125\n",
      "iteration : 126\n",
      "iteration : 127\n",
      "iteration : 128\n",
      "iteration : 129\n",
      "iteration : 130\n",
      "iteration : 131\n",
      "iteration : 132\n",
      "iteration : 133\n",
      "iteration : 134\n",
      "iteration : 135\n",
      "iteration : 136\n",
      "iteration : 137\n",
      "iteration : 138\n",
      "iteration : 139\n",
      "iteration : 140\n",
      "iteration : 141\n",
      "iteration : 142\n",
      "iteration : 143\n",
      "iteration : 144\n",
      "iteration : 145\n",
      "iteration : 146\n",
      "iteration : 147\n",
      "iteration : 148\n",
      "iteration : 149\n",
      "iteration : 150\n",
      "iteration : 151\n",
      "iteration : 152\n",
      "iteration : 153\n",
      "iteration : 154\n",
      "iteration : 155\n",
      "iteration : 156\n",
      "iteration : 157\n",
      "iteration : 158\n",
      "iteration : 159\n",
      "iteration : 160\n",
      "iteration : 161\n",
      "iteration : 162\n",
      "iteration : 163\n",
      "iteration : 164\n",
      "iteration : 165\n",
      "iteration : 166\n",
      "iteration : 167\n",
      "iteration : 168\n",
      "iteration : 169\n",
      "iteration : 170\n",
      "iteration : 171\n",
      "iteration : 172\n",
      "iteration : 173\n",
      "iteration : 174\n",
      "iteration : 175\n",
      "iteration : 176\n",
      "iteration : 177\n",
      "iteration : 178\n",
      "iteration : 179\n",
      "iteration : 180\n",
      "iteration : 181\n",
      "iteration : 182\n",
      "iteration : 183\n",
      "iteration : 184\n",
      "iteration : 185\n",
      "iteration : 186\n",
      "iteration : 187\n",
      "iteration : 188\n",
      "iteration : 189\n",
      "iteration : 190\n",
      "iteration : 191\n",
      "iteration : 192\n",
      "iteration : 193\n",
      "iteration : 194\n",
      "iteration : 195\n",
      "iteration : 196\n",
      "iteration : 197\n",
      "iteration : 198\n",
      "iteration : 199\n",
      "iteration : 200\n",
      "iteration : 201\n",
      "iteration : 202\n",
      "iteration : 203\n",
      "iteration : 204\n",
      "iteration : 205\n",
      "iteration : 206\n",
      "iteration : 207\n",
      "iteration : 208\n",
      "iteration : 209\n",
      "iteration : 210\n",
      "iteration : 211\n",
      "iteration : 212\n",
      "iteration : 213\n",
      "iteration : 214\n",
      "iteration : 215\n",
      "iteration : 216\n",
      "iteration : 217\n",
      "iteration : 218\n",
      "iteration : 219\n",
      "iteration : 220\n",
      "iteration : 221\n",
      "iteration : 222\n",
      "iteration : 223\n",
      "iteration : 224\n",
      "iteration : 225\n",
      "iteration : 226\n",
      "iteration : 227\n",
      "iteration : 228\n",
      "iteration : 229\n",
      "iteration : 230\n",
      "iteration : 231\n",
      "iteration : 232\n",
      "iteration : 233\n",
      "iteration : 234\n",
      "iteration : 235\n",
      "iteration : 236\n",
      "iteration : 237\n",
      "iteration : 238\n",
      "iteration : 239\n",
      "iteration : 240\n",
      "iteration : 241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d81bb16f86a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDB_Zs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEUBO_init_eta_prior_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel_Params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_Params_Test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mDB_ETAs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symKL_DB_eta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mDB_Zs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symKL_DB_z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-81b9f8032c2d>\u001b[0m in \u001b[0;36mtest_propagation\u001b[0;34m(models, objective, data, Model_Params, Train_Params)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmetric_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubTrain_Params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m## gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-81b9f8032c2d>\u001b[0m in \u001b[0;36mEUBO_init_eta_prior_test\u001b[0;34m(models, obs, SubTrain_Params)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcmc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#         state = resample_state(state, w_f_z, idw_flag=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_nu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_eta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mobs_tau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_w_eta_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_w_eta_b\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mIncremental_eta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_tau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0msymkl_detailed_balance_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meubo_p_q_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sym_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_f_eta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetailed_balances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_w_eta_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_w_eta_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/amortized/GMM/models/global_enc_v1.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, state, K, D)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mgammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         q_alpha, q_beta, q_mu, q_nu = Post_eta(xs, gammas,\n\u001b[0;32m---> 38\u001b[0;31m                                                  self.prior_alpha, self.prior_beta, self.prior_mu, self.prior_nu, K, D)\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReparameterized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             q.gamma(q_alpha,\n",
      "\u001b[0;32m~/Research/amortized/GMM/normal_gamma.py\u001b[0m in \u001b[0;36mPost_eta\u001b[0;34m(obs, states, prior_alpha, prior_beta, prior_mu, prior_nu, K, D)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mstat1_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## S * B * K * D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstat1_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat1_expand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mstat1_nonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstat1_nonzero\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mx_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstat1_nonzero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpost_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstat1_expand\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ESSs = []\n",
    "DB_ETAs = []\n",
    "DB_Zs = []\n",
    "for i in range(1000):\n",
    "    metrics = test_propagation(models, EUBO_init_eta_prior_test, Data, Model_Params, Train_Params_Test)\n",
    "    DB_ETAs.append(np.array(metrics['symKL_DB_eta']).mean(0))\n",
    "    DB_Zs.append(np.array(metrics['symKL_DB_z']).mean(0))\n",
    "    ESSs.append(np.array(metrics['ess']).mean(0))\n",
    "    print('iteration : %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_eta = np.array(metrics['symKL_DB_eta']).mean(0)\n",
    "DB_z = np.array(metrics['symKL_DB_z']).mean(0)\n",
    "ess =  np.array(metrics['ess']).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-511b48b5130b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ess' is not defined"
     ]
    }
   ],
   "source": [
    "ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
