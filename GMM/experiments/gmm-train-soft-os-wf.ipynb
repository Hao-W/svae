{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probtorch: 0.0+5a2c637 torch: 0.4.1 cuda: True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../../import_envs.py\n",
    "print('probtorch:', probtorch.__version__, \n",
    "      'torch:', torch.__version__, \n",
    "      'cuda:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "data_path = \"../gmm_dataset_c20k\"\n",
    "Data = torch.from_numpy(np.load(data_path + '/obs.npy')).float()\n",
    "\n",
    "NUM_DATASETS, N, D = Data.shape\n",
    "K = 3 ## number of clusters\n",
    "SAMPLE_SIZE = 10\n",
    "NUM_HIDDEN_LOCAL = 32\n",
    "\n",
    "MCMC_SIZE = 10\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 250\n",
    "LEARNING_RATE = 5 * 1e-4\n",
    "CUDA = torch.cuda.is_available()\n",
    "PATH = 'soft-os-wf'\n",
    "DEVICE = torch.device('cuda:1')\n",
    "\n",
    "Train_Params = (NUM_EPOCHS, NUM_DATASETS, SAMPLE_SIZE, BATCH_SIZE, CUDA, DEVICE, PATH)\n",
    "Model_Params = (N, K, D, MCMC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_enc import *\n",
    "from global_oneshot import *\n",
    "from global_enc_v1 import *\n",
    "## if reparameterize continuous variables\n",
    "Reparameterized = False\n",
    "# initialization\n",
    "enc_z = Enc_z(K, D, NUM_HIDDEN_LOCAL, CUDA, DEVICE)\n",
    "enc_eta = Enc_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "oneshot_eta = Oneshot_eta(K, D, CUDA, DEVICE, Reparameterized)\n",
    "\n",
    "if CUDA:\n",
    "    enc_z.cuda().to(DEVICE)\n",
    "    enc_eta.cuda().to(DEVICE)\n",
    "    oneshot_eta.cuda().to(DEVICE)\n",
    "optimizer =  torch.optim.Adam(list(oneshot_eta.parameters())+list(enc_eta.parameters())+list(enc_z.parameters()),lr=LEARNING_RATE, betas=(0.9, 0.99))\n",
    "models = (oneshot_eta, enc_eta, enc_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\\250 (148s),  symKL_DB_eta: 197.056,  symKL_DB_z: 215.668,  loss: -991.731,  ess: 3.608,  kl_eta_ex: 506.641,  kl_eta_in: 138.410,  kl_z_ex: 137.853,  kl_z_in: 24.121\n",
      "epoch: 1\\250 (147s),  symKL_DB_eta: 71.381,  symKL_DB_z: 51.237,  loss: -688.736,  ess: 4.623,  kl_eta_ex: 147.683,  kl_eta_in: 165.857,  kl_z_ex: 26.926,  kl_z_in: 9.159\n",
      "epoch: 2\\250 (147s),  symKL_DB_eta: 56.583,  symKL_DB_z: 36.728,  loss: -635.521,  ess: 4.903,  kl_eta_ex: 114.646,  kl_eta_in: 193.201,  kl_z_ex: 18.764,  kl_z_in: 6.452\n",
      "epoch: 3\\250 (146s),  symKL_DB_eta: 41.789,  symKL_DB_z: 21.026,  loss: -562.313,  ess: 5.271,  kl_eta_ex: 78.102,  kl_eta_in: 120.042,  kl_z_ex: 10.362,  kl_z_in: 3.978\n",
      "epoch: 4\\250 (147s),  symKL_DB_eta: 22.696,  symKL_DB_z: 11.780,  loss: -475.886,  ess: 5.695,  kl_eta_ex: 33.078,  kl_eta_in: 43.069,  kl_z_ex: 5.317,  kl_z_in: 2.011\n",
      "epoch: 5\\250 (148s),  symKL_DB_eta: 15.658,  symKL_DB_z: 8.016,  loss: -451.439,  ess: 5.997,  kl_eta_ex: 18.652,  kl_eta_in: 24.294,  kl_z_ex: 3.274,  kl_z_in: 1.207\n",
      "epoch: 6\\250 (149s),  symKL_DB_eta: 10.023,  symKL_DB_z: 5.178,  loss: -435.238,  ess: 6.434,  kl_eta_ex: 8.563,  kl_eta_in: 12.698,  kl_z_ex: 1.955,  kl_z_in: 0.723\n",
      "epoch: 7\\250 (147s),  symKL_DB_eta: 5.150,  symKL_DB_z: 3.579,  loss: -425.067,  ess: 7.288,  kl_eta_ex: 2.576,  kl_eta_in: 4.164,  kl_z_ex: 1.223,  kl_z_in: 0.448\n",
      "epoch: 8\\250 (147s),  symKL_DB_eta: 3.478,  symKL_DB_z: 2.678,  loss: -422.477,  ess: 7.862,  kl_eta_ex: 0.802,  kl_eta_in: 1.139,  kl_z_ex: 0.833,  kl_z_in: 0.322\n",
      "epoch: 9\\250 (147s),  symKL_DB_eta: 2.847,  symKL_DB_z: 2.306,  loss: -421.870,  ess: 8.109,  kl_eta_ex: 0.229,  kl_eta_in: 0.290,  kl_z_ex: 0.659,  kl_z_in: 0.267\n",
      "epoch: 10\\250 (145s),  symKL_DB_eta: 2.505,  symKL_DB_z: 2.020,  loss: -421.909,  ess: 8.256,  kl_eta_ex: 0.080,  kl_eta_in: 0.081,  kl_z_ex: 0.576,  kl_z_in: 0.240\n",
      "epoch: 11\\250 (134s),  symKL_DB_eta: 2.377,  symKL_DB_z: 1.997,  loss: -421.892,  ess: 8.319,  kl_eta_ex: 0.028,  kl_eta_in: 0.028,  kl_z_ex: 0.524,  kl_z_in: 0.218\n",
      "epoch: 12\\250 (134s),  symKL_DB_eta: 2.248,  symKL_DB_z: 1.893,  loss: -422.048,  ess: 8.359,  kl_eta_ex: 0.014,  kl_eta_in: 0.012,  kl_z_ex: 0.502,  kl_z_in: 0.205\n",
      "epoch: 13\\250 (134s),  symKL_DB_eta: 2.238,  symKL_DB_z: 1.832,  loss: -422.028,  ess: 8.364,  kl_eta_ex: 0.013,  kl_eta_in: 0.102,  kl_z_ex: 0.479,  kl_z_in: 0.194\n",
      "epoch: 14\\250 (133s),  symKL_DB_eta: 2.223,  symKL_DB_z: 1.764,  loss: -422.024,  ess: 8.375,  kl_eta_ex: 0.009,  kl_eta_in: 0.006,  kl_z_ex: 0.472,  kl_z_in: 0.181\n",
      "epoch: 15\\250 (134s),  symKL_DB_eta: 2.203,  symKL_DB_z: 1.736,  loss: -422.080,  ess: 8.390,  kl_eta_ex: 0.008,  kl_eta_in: 0.006,  kl_z_ex: 0.449,  kl_z_in: 0.171\n",
      "epoch: 16\\250 (134s),  symKL_DB_eta: 2.199,  symKL_DB_z: 1.604,  loss: -422.151,  ess: 8.390,  kl_eta_ex: 0.008,  kl_eta_in: 0.006,  kl_z_ex: 0.430,  kl_z_in: 0.161\n",
      "epoch: 17\\250 (139s),  symKL_DB_eta: 2.185,  symKL_DB_z: 1.482,  loss: -422.098,  ess: 8.401,  kl_eta_ex: 0.007,  kl_eta_in: 0.004,  kl_z_ex: 0.394,  kl_z_in: 0.147\n",
      "epoch: 18\\250 (148s),  symKL_DB_eta: 2.187,  symKL_DB_z: 1.447,  loss: -422.025,  ess: 8.397,  kl_eta_ex: 0.009,  kl_eta_in: 0.017,  kl_z_ex: 0.390,  kl_z_in: 0.141\n",
      "epoch: 19\\250 (148s),  symKL_DB_eta: 2.212,  symKL_DB_z: 1.415,  loss: -422.124,  ess: 8.397,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.371,  kl_z_in: 0.131\n",
      "epoch: 20\\250 (147s),  symKL_DB_eta: 2.164,  symKL_DB_z: 1.280,  loss: -422.126,  ess: 8.411,  kl_eta_ex: 0.009,  kl_eta_in: 0.011,  kl_z_ex: 0.334,  kl_z_in: 0.117\n",
      "epoch: 21\\250 (148s),  symKL_DB_eta: 2.201,  symKL_DB_z: 1.326,  loss: -422.138,  ess: 8.405,  kl_eta_ex: 0.007,  kl_eta_in: 0.004,  kl_z_ex: 0.309,  kl_z_in: 0.111\n",
      "epoch: 22\\250 (147s),  symKL_DB_eta: 2.205,  symKL_DB_z: 1.148,  loss: -422.255,  ess: 8.409,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.292,  kl_z_in: 0.105\n",
      "epoch: 23\\250 (146s),  symKL_DB_eta: 2.192,  symKL_DB_z: 1.148,  loss: -422.092,  ess: 8.411,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.280,  kl_z_in: 0.098\n",
      "epoch: 24\\250 (145s),  symKL_DB_eta: 2.154,  symKL_DB_z: 1.121,  loss: -422.235,  ess: 8.426,  kl_eta_ex: 0.007,  kl_eta_in: 0.006,  kl_z_ex: 0.267,  kl_z_in: 0.095\n",
      "epoch: 25\\250 (136s),  symKL_DB_eta: 2.170,  symKL_DB_z: 1.072,  loss: -422.307,  ess: 8.419,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.257,  kl_z_in: 0.092\n",
      "epoch: 26\\250 (147s),  symKL_DB_eta: 2.176,  symKL_DB_z: 1.041,  loss: -422.231,  ess: 8.416,  kl_eta_ex: 0.007,  kl_eta_in: 0.004,  kl_z_ex: 0.245,  kl_z_in: 0.088\n",
      "epoch: 27\\250 (148s),  symKL_DB_eta: 2.194,  symKL_DB_z: 0.938,  loss: -422.117,  ess: 8.414,  kl_eta_ex: 0.006,  kl_eta_in: 0.004,  kl_z_ex: 0.232,  kl_z_in: 0.085\n",
      "epoch: 28\\250 (148s),  symKL_DB_eta: 2.186,  symKL_DB_z: 0.933,  loss: -422.183,  ess: 8.416,  kl_eta_ex: 0.007,  kl_eta_in: 0.004,  kl_z_ex: 0.220,  kl_z_in: 0.079\n",
      "epoch: 29\\250 (148s),  symKL_DB_eta: 2.211,  symKL_DB_z: 0.894,  loss: -422.172,  ess: 8.417,  kl_eta_ex: 0.007,  kl_eta_in: 0.004,  kl_z_ex: 0.219,  kl_z_in: 0.078\n",
      "epoch: 30\\250 (148s),  symKL_DB_eta: 2.181,  symKL_DB_z: 0.905,  loss: -422.217,  ess: 8.415,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.211,  kl_z_in: 0.075\n",
      "epoch: 31\\250 (148s),  symKL_DB_eta: 2.168,  symKL_DB_z: 0.834,  loss: -422.277,  ess: 8.418,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.205,  kl_z_in: 0.073\n",
      "epoch: 32\\250 (148s),  symKL_DB_eta: 2.203,  symKL_DB_z: 0.836,  loss: -422.148,  ess: 8.416,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.197,  kl_z_in: 0.071\n",
      "epoch: 33\\250 (147s),  symKL_DB_eta: 2.197,  symKL_DB_z: 0.824,  loss: -422.131,  ess: 8.421,  kl_eta_ex: 0.006,  kl_eta_in: 0.004,  kl_z_ex: 0.194,  kl_z_in: 0.070\n",
      "epoch: 34\\250 (152s),  symKL_DB_eta: 2.191,  symKL_DB_z: 0.791,  loss: -422.165,  ess: 8.423,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.191,  kl_z_in: 0.067\n",
      "epoch: 35\\250 (141s),  symKL_DB_eta: 2.175,  symKL_DB_z: 0.760,  loss: -422.252,  ess: 8.423,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.185,  kl_z_in: 0.063\n",
      "epoch: 36\\250 (140s),  symKL_DB_eta: 2.184,  symKL_DB_z: 0.826,  loss: -422.193,  ess: 8.427,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.184,  kl_z_in: 0.065\n",
      "epoch: 37\\250 (140s),  symKL_DB_eta: 2.190,  symKL_DB_z: 0.759,  loss: -422.109,  ess: 8.420,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.175,  kl_z_in: 0.063\n",
      "epoch: 38\\250 (140s),  symKL_DB_eta: 2.192,  symKL_DB_z: 0.725,  loss: -422.209,  ess: 8.422,  kl_eta_ex: 0.006,  kl_eta_in: 0.004,  kl_z_ex: 0.167,  kl_z_in: 0.060\n",
      "epoch: 39\\250 (139s),  symKL_DB_eta: 2.173,  symKL_DB_z: 0.744,  loss: -422.216,  ess: 8.427,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.166,  kl_z_in: 0.058\n",
      "epoch: 40\\250 (140s),  symKL_DB_eta: 2.203,  symKL_DB_z: 0.703,  loss: -422.258,  ess: 8.423,  kl_eta_ex: 0.007,  kl_eta_in: 0.005,  kl_z_ex: 0.165,  kl_z_in: 0.058\n",
      "epoch: 41\\250 (139s),  symKL_DB_eta: 2.189,  symKL_DB_z: 0.760,  loss: -422.376,  ess: 8.424,  kl_eta_ex: 0.006,  kl_eta_in: 0.004,  kl_z_ex: 0.164,  kl_z_in: 0.056\n",
      "epoch: 42\\250 (136s),  symKL_DB_eta: 2.185,  symKL_DB_z: 0.665,  loss: -422.036,  ess: 8.434,  kl_eta_ex: 0.006,  kl_eta_in: 0.004,  kl_z_ex: 0.157,  kl_z_in: 0.055\n"
     ]
    }
   ],
   "source": [
    "from ag_ep import *\n",
    "train(models, EUBO_init_eta_wf, optimizer, Data, Model_Params, Train_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc_z.state_dict(), \"../weights/enc-z-%s\" % PATH)\n",
    "torch.save(enc_eta.state_dict(), \"../weights/enc-eta-%s\" % PATH)\n",
    "torch.save(oneshot_eta.state_dict(), \"../weights/oneshot-eta-%s\" % PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
